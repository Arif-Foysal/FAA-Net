\documentclass{ieeeaccess}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{threeparttable}



\usepackage{bm}
\makeatletter
\AtBeginDocument{\DeclareMathVersion{bold}
\SetSymbolFont{operators}{bold}{T1}{times}{b}{n}
\SetSymbolFont{NewLetters}{bold}{T1}{times}{b}{it}
\SetMathAlphabet{\mathrm}{bold}{T1}{times}{b}{n}
\SetMathAlphabet{\mathit}{bold}{T1}{times}{b}{it}
\SetMathAlphabet{\mathbf}{bold}{T1}{times}{b}{n}
\SetMathAlphabet{\mathtt}{bold}{OT1}{pcr}{b}{n}
\SetSymbolFont{symbols}{bold}{OMS}{cmsy}{b}{n}
\renewcommand\boldmath{\@nomath\boldmath\mathversion{bold}}}
\makeatother

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}



%Your document starts from here ___________________________________________________
\begin{document}
\history{Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.}
\doi{10.1109/ACCESS.2024.0429000}

\title{FAA-Net: Focal-Aware Attention for Class-Imbalanced Network Intrusion Detection}
\author{\uppercase{Md Arif Faysal Nayem}\authorrefmark{1}}

\address[1]{United International University, , Dhaka 1212 Bangladesh (e-mail: info@uiu.ac.bd)}

% \tfootnote{This work is submitted in partial fulfillment of the requirements for successful completion of the Data Mining course.''}

\markboth
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}

\corresp{Corresponding author: Md Arif Faysal Nayem (e-mail: mnayem201194@bscse.uiu.ac.bd, phone: +8801707820797).}


\begin{abstract}
Network Intrusion Detection Systems (NIDS) face a critical challenge in detecting rare attack variants that constitute a small fraction of network traffic. Severe class imbalance causes conventional deep learning approaches to exhibit majority-class bias, resulting in poor detection of minority attack categories that often represent emerging or sophisticated threats. Existing attention-based methods apply cost-sensitive adjustments external to the attention mechanism, failing to address the fundamental bias in how attention weights are computed. We introduce the Focal-Aware Attention Network (FAA-Net) featuring Focal-Aware Imbalance-Integrated Attention (FAIIA), a novel mechanism that embeds class imbalance awareness directly into attention score computation through prototype-based cross-attention and uncertainty-driven focal modulation. FAIIA modulates attention scores using an uncertainty-based focal term $\alpha \cdot (1 - 2|p_{\text{init}} - 0.5|)^{\gamma}$ that peaks at decision boundaries where minority instances frequently reside, combined with learned minority-class prototypes generated via K-means clustering to provide explicit attention anchors for rare attack patterns. A class-conditional gating module further refines attention outputs based on prediction difficulty. Evaluated on the UNSW-NB15 dataset with severe imbalance (training ratio: 0.469; test ratio: 0.816), FAA-Net achieves 94.95\% recall, surpassing the strongest baseline (LightGBM: 93.30\%) by 1.65 percentage points. The model demonstrates exceptional performance on extremely rare attacks: 95.45\% detection for Worms (44 test samples), 99.85\% for Analysis (677 samples), 99.31\% for Backdoor (583 samples), and 92.06\% for Shellcode (378 samples). While tree-based baselines achieve higher balanced F1-scores (LightGBM: 0.9088 vs. FAA-Net: 0.8863), FAA-Net demonstrates superior minority-class sensitivity through architectural integration of imbalance awareness. Systematic ablation studies isolate FAIIA's contribution: comparing Vanilla DNN + BCE (91.29\% recall) to FAIIA + BCE (94.03\% recall) reveals a 2.74 percentage point improvement from the attention mechanism alone, while the complete FAA-Net configuration achieves 94.95\% recall—representing a 3.66 percentage point gain over Vanilla DNN + Focal (87.82\%). With 127,844 parameters and sub-millisecond CPU inference latency, FAA-Net is deployable on edge computing infrastructure while maintaining 97.06\% AUC-ROC. The proposed approach demonstrates that integrating imbalance awareness into attention architecture, rather than relying solely on loss function modifications, provides an effective solution for security-critical intrusion detection where false negatives carry severe operational consequences.
\end{abstract}
\begin{IEEEkeywords}
Network intrusion detection, attention mechanism, class imbalance, focal loss, deep learning, edge computing, explainable AI, minority class detection, security-critical systems
\end{IEEEkeywords}


\begin{keywords}
Network intrusion detection, attention mechanism, class imbalance, focal loss, deep learning, edge computing, explainable AI, minority class detection
\end{keywords}

\titlepgskip=-21pt

\maketitle

\section{Introduction}
\label{sec:introduction}

Modern cyber infrastructure faces an escalating threat landscape where sophisticated attacks exploit increasingly complex vulnerabilities. Network Intrusion Detection Systems (NIDS) serve as a critical defense mechanism, continuously monitoring network traffic to identify malicious activities before they compromise system integrity. Traditional signature-based detection methods, while effective against known threats, struggle to identify novel attack patterns and zero-day exploits. This limitation has driven the adoption of machine learning and deep learning approaches that can learn to distinguish malicious from benign traffic based on statistical patterns rather than predefined signatures~\cite{chinnasamy2025deep, kasongo2023deep}.

Despite significant advances in deep learning-based intrusion detection, a fundamental challenge persists: \textit{severe class imbalance} where rare attack types constitute a small fraction of network traffic yet represent critical security threats. Advanced Persistent Threats (APTs), backdoor installations, shellcode injections, and sophisticated exploit attempts occur infrequently but carry disproportionate impact when successful. Standard deep learning models trained on such imbalanced distributions exhibit systematic bias toward majority classes—predominantly benign traffic—resulting in elevated false negative rates for minority attack categories that security operators can least afford to miss~\cite{milosevic2022extreme, su2020bat}.

\subsection{The Class Imbalance Challenge in Intrusion Detection}

The UNSW-NB15 benchmark dataset~\cite{moustafa2015unsw}, widely used for NIDS evaluation, exemplifies this challenge with multi-level imbalance. At the binary level, the training partition contains 119341 attack samples versus 56000 normal instances (imbalance ratio: 0.469), while the test partition exhibits more severe imbalance with 45332 attacks versus 37000 normal instances (imbalance ratio: 0.816). More critically, individual attack categories demonstrate extreme rarity: Worms appear in only 44 test samples, Analysis attacks in 677 samples, Backdoor attacks in 583 samples, and Shellcode in 378 samples. This represents class imbalance ratios exceeding 840:1 between the rarest attacks and normal traffic. Similarly imbalanced distributions characterize real-world network traffic where normal operations dominate and critical attacks represent rare anomalies.

This imbalance manifests at multiple levels: between normal and attack traffic overall, and among attack categories themselves where sophisticated threats are vastly outnumbered by both normal traffic and more common attack types. Conventional approaches to imbalanced learning—including resampling techniques, cost-sensitive loss functions, and ensemble methods~\cite{chen2024survey}—address classification imbalance through adjustments to training objectives or data distributions. Focal loss~\cite{lin2017focal}, originally proposed for dense object detection, has been successfully applied to intrusion detection by down-weighting well-classified examples and focusing learning on hard negatives. Class-balanced loss~\cite{cui2019class} reweights samples based on effective class cardinality to prevent majority class dominance. While these methods improve minority class recognition during training, they operate as \textit{post-hoc corrections to the classification objective}, leaving the fundamental feature representation learning process—particularly attention mechanisms—largely agnostic to class distribution.

\subsection{Limitations of Existing Attention Mechanisms}

Attention mechanisms have demonstrated effectiveness in deep learning by enabling models to selectively focus on relevant features while suppressing irrelevant information~\cite{vaswani2017attention}. In intrusion detection, attention can identify which network flow features (packet sizes, protocol flags, timing patterns) are most indicative of malicious activity. However, standard attention computation:
\begin{equation}
\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{equation}
treats all samples identically regardless of their class membership or rarity in the training distribution. For imbalanced datasets, this class-agnostic design causes attention weights to be influenced predominantly by majority class patterns since they constitute the overwhelming proportion of training samples. Consequently, features critical for identifying rare attacks may receive insufficient attention during both training and inference.

Recent work on imbalanced image classification~\cite{wang2022deep, huang2016learning, zhu2021spectral} has explored attention-based solutions, but these approaches primarily focus on visual domains with spatial attention over image regions. Network intrusion detection presents distinct challenges: (1) tabular flow-based features lack spatial structure, requiring different attention semantics; (2) minority attacks exhibit high feature variability, demanding robust pattern matching; (3) real-time deployment constraints necessitate computational efficiency; and (4) security applications prioritize recall (minimizing false negatives) over precision (minimizing false alarms) differently than general classification tasks~\cite{sokolova2009systematic, davis2006relationship}.

\subsection{Research Motivation and Contributions}

We hypothesize that effective intrusion detection on imbalanced data requires integrating class imbalance awareness \textit{directly into the attention mechanism itself}, influencing how features are weighted during representation learning rather than merely adjusting final classification outputs. This integration should operate during both training and inference, ensuring minority class patterns receive appropriate attention regardless of batch composition.

To address these challenges, we propose \textbf{FAA-NET (Focal-Aware Attention Network) with Focal-Aware Imbalance-Integrated Attention (FAIIA)}, a mechanism that embeds class imbalance awareness through three synergistic components:

\begin{enumerate}
    \item \textbf{Uncertainty-Based Focal Modulation:} Unlike traditional focal loss that emphasizes confident misclassifications through $(1-p_t)^\gamma$, FAIIA employs uncertainty-driven modulation $F(p) = \alpha(1 - 2|p_{\text{init}} - 0.5|)^\gamma$ applied to attention scores \textit{before softmax normalization}. This formulation peaks at decision boundaries ($p_{\text{init}} = 0.5$) where minority instances frequently reside, dynamically amplifying attention for uncertain predictions rather than confident errors. The initial probability $p_{\text{init}}$ is estimated by a lightweight auxiliary network, providing class-awareness without requiring ground truth labels during inference.
    
    \item \textbf{Prototype-Based Cross-Attention:} FAIIA maintains learnable prototype embeddings initialized via K-means clustering ($K=8$) on minority class training samples. Rather than standard self-attention where inputs attend to themselves (potentially dominated by majority patterns), FAIIA performs cross-attention where inputs explicitly attend to these learned minority prototypes. This architectural design ensures rare attack signatures receive dedicated attention even when underrepresented in training batches, providing explicit minority class anchors in the feature space.
    
    \item \textbf{Class-Conditional Gating:} A difficulty-aware gating mechanism refines attention outputs based on prediction uncertainty, measured as $d = 1 - 2|p_{\text{init}} - 0.5|$. This provides additional emphasis on ambiguous samples that typically occur at class interfaces in imbalanced datasets, modulating feature representations according to classification difficulty.
\end{enumerate}

We integrate FAIIA into FAA-NET, a compact architecture with 127844 parameters designed for resource-constrained NIDS deployment. The complete system employs 4-head FAIIA with varying focal strengths ($\alpha_i = 0.60 \times (1 + 0.1i)$ for head $i$) to capture diverse attention patterns, combined with Squeeze-and-Excitation blocks for channel-wise feature recalibration and residual connections for stable gradient flow through the 3-layer feedforward backbone ([256, 128, 64] hidden dimensions).

\subsection{Main Contributions}

The primary contributions of this work are:

\begin{itemize}
    \item \textbf{Novel Attention Mechanism:} FAIIA integrates uncertainty-based focal modulation and prototype-based cross-attention directly into attention score computation for imbalanced network intrusion detection. Unlike existing methods that apply cost-sensitive adjustments externally, FAIIA embeds imbalance awareness into the attention architecture itself, providing a principled approach to class-aware feature weighting during representation learning.
    
    \item \textbf{Prototype-Augmented Architecture:} We introduce learnable minority class prototypes within the attention framework, enabling explicit cross-attention against rare attack signatures. The K-means initialization from minority training samples followed by gradient-based fine-tuning ensures consistent minority class representation regardless of batch composition, addressing the fundamental problem of majority class dominance in standard attention mechanisms.
    
    \item \textbf{Comprehensive Empirical Validation:} Extensive evaluation on the UNSW-NB15 benchmark demonstrates that FAA-NET with FAIIA achieves 94.95\% recall, surpassing the strongest baseline (LightGBM: 93.30\%) by 1.65 percentage points. Detection rates on extremely rare attacks validate FAIIA's effectiveness: 95.45\% on Worms (44 test samples), 99.85\% on Analysis attacks (677 samples), 99.31\% on Backdoor (583 samples), and 92.06\% on Shellcode (378 samples). While tree-based baselines achieve higher balanced F1-scores (LightGBM: 0.9088 vs. FAIIA + Focal: 0.8863), FAIIA demonstrates superior minority-class sensitivity—a deliberate design trade-off prioritizing security-critical threat detection over balanced accuracy metrics.
    
    \item \textbf{Systematic Ablation Analysis:} Controlled ablation experiments isolate FAIIA's contribution independent of loss function choice. Comparing Vanilla DNN + BCE (91.29\% recall) to FAIIA + BCE (94.03\% recall) reveals a 2.74 percentage point improvement from the attention mechanism alone. The complete FAIIA + Focal configuration achieves 94.95\% recall—a 7.13 percentage point gain over Vanilla DNN + Focal (87.82\% recall). These results validate that architectural integration of imbalance awareness provides substantial benefits beyond loss-level adjustments, with synergistic effects when combined with focal loss.
    
    \item \textbf{Practical Deployment Viability:} With 127844 trainable parameters (2.34× larger than vanilla baseline), FAA-NET maintains computational efficiency suitable for edge deployment. Sub-millisecond CPU inference latency and strong AUC-ROC (97.06\%) demonstrate that the model balances minority detection capability with practical deployment constraints. Attention weight analysis provides interpretable insights into which prototypes activate for specific predictions, supporting security analyst understanding of model decisions.
\end{itemize}

\subsection{Paper Organization}

The remainder of this paper is organized as follows. Section~\ref{sec:related} reviews related work on intrusion detection, imbalanced learning, and attention mechanisms. Section~\ref{sec:methodology} presents the FAIIA mechanism and FAA-NET architecture in detail, including mathematical formulation, prototype generation, and design rationale. Section~\ref{sec:results} presents comprehensive results including overall performance comparisons, ablation studies isolating architectural contributions, per-attack category analysis, and ROC/PR curve evaluation. Section~\ref{sec:discussion} discusses theoretical implications, precision-recall trade-offs, deployment considerations, and limitations. Finally, Section~\ref{sec:conclusion} concludes with a summary of contributions and future research directions.
\section{Related Work}
\label{sec:related}

We organize related work into four key areas: network intrusion detection systems, 
imbalanced learning techniques, attention mechanisms in deep learning, and their 
application to security domains.

\subsection{Network Intrusion Detection Systems}

Network intrusion detection has evolved from signature-based approaches to 
sophisticated machine learning systems capable of identifying novel attack patterns. 
Chinnasamy et al.~\cite{chinnasamy2025deep} provide a comprehensive survey of deep 
learning methods for NIDS, categorizing approaches by architecture (CNNs, RNNs, 
autoencoders) and highlighting the persistent challenge of class imbalance across 
all methods. Traditional machine learning approaches, including Support Vector 
Machines, Random Forests, and ensemble methods, have been extensively applied to 
intrusion detection with varying success on imbalanced datasets.

\subsubsection{Deep Learning Architectures for NIDS}

Convolutional Neural Networks (CNNs) have been employed to capture spatial patterns 
in network flow features, treating feature vectors as one-dimensional signals where 
local feature interactions are meaningful. Su et al.~\cite{su2020bat} proposed BAT 
(Bidirectional LSTM with Attention), demonstrating that attention mechanisms can 
improve feature selection for intrusion detection on the NSL-KDD dataset. However, 
their attention mechanism operates uniformly across all samples without regard to 
class distribution, limiting effectiveness on minority attacks.

Recurrent Neural Networks, particularly Long Short-Term Memory (LSTM) networks, have 
been applied to model temporal dependencies in network traffic sequences. Kasongo~\cite{kasongo2023deep} 
developed an RNN-based framework achieving competitive performance on balanced metrics 
but acknowledged degraded performance on rare attack categories. These sequence-based 
approaches assume temporal ordering of features, which may not align with tabular 
flow-based representations where features represent aggregated statistics rather than 
time series.

\subsubsection{Benchmark Datasets and Evaluation Challenges}

% \begin{table}[t]
% \centering
% \caption{Per-Attack Category Detection Rate Comparison ($\theta = 0.5$)}
% \label{tab:per_attack}
% \footnotesize
% \begin{tabular}{|l|r|c|c|c|c|}
% \hline
% \textbf{Category} & \textbf{Samples} & \textbf{XGBoost} & \textbf{DNN} & \textbf{FAIIA} & \textbf{Best} \\
% \hline
% \multicolumn{6}{|l|}{\textit{Minority Classes ($<$5,000 samples)}} \\
% \hline
% Analysis        & 677   & 0.9350 & 0.9985 & \textbf{0.9985} & FAIIA \\
% Backdoor        & 583   & \textbf{0.9983} & \textbf{0.9983} & 0.9949 & XGBoost \\
% DoS             & 4,089 & 0.9958 & 0.9944 & \textbf{0.9963} & FAIIA \\
% Reconnaissance  & 3,496 & \textbf{0.9983} & 0.9834 & 0.9946 & XGBoost \\
% Shellcode       & 378   & 0.9603 & 0.9418 & \textbf{0.9815} & FAIIA \\
% Worms           & 44    & 1.0000 & 1.0000 & 1.0000 & Tie \\
% \hline
% \textit{Minority Avg} & -- & 0.9813 & 0.9861 & \textbf{0.9943} & FAIIA \\
% \hline
% \multicolumn{6}{|l|}{\textit{Majority Classes ($\geq$5,000 samples)}} \\
% \hline
% Exploits        & 11,132 & 0.9885 & 0.9933 & \textbf{0.9961} & FAIIA \\
% Fuzzers         & 6,062  & 0.8195 & 0.8199 & \textbf{0.8667} & FAIIA \\
% Generic         & 18,871 & 0.9997 & \textbf{0.9998} & \textbf{0.9998} & Tie \\
% \hline
% \textit{Majority Avg} & -- & 0.9359 & 0.9377 & \textbf{0.9542} & FAIIA \\
% \hline
% \end{tabular}
% \vspace{1mm}

% \footnotesize{\textit{Bold indicates best performance. FAIIA achieves superior detection in
% 4 out of 6 minority categories and all majority attack categories. Normal traffic class is excluded.}}
% \end{table}



The UNSW-NB15 dataset~\cite{moustafa2015unsw}, introduced by Moustafa and Slay, has 
become a widely adopted benchmark for evaluating NIDS performance on realistic, 
imbalanced traffic. Containing nine attack categories with severe class imbalance 
(44 to 37,000 samples per class), it better reflects real-world network environments 
than earlier balanced datasets like KDD Cup '99 or NSL-KDD. However, Sharafaldin 
et al.~\cite{sharafaldin2018toward} note that even modern datasets struggle to 
capture the full diversity of evolving attack tactics, emphasizing the need for 
models that generalize well to rare, previously unseen attack patterns—precisely 
the scenario where minority class learning is critical.

Sokolova and Lapalme~\cite{sokolova2009systematic} provide systematic analysis of 
performance metrics for classification tasks, demonstrating that accuracy is 
misleading for imbalanced datasets. They advocate for precision, recall, F1-score, 
and class-specific metrics—recommendations we adopt in our evaluation methodology. 
Davis and Goadrich~\cite{davis2006relationship} further establish that precision-recall 
curves are more informative than ROC curves for imbalanced classification, as they 
directly reflect minority class performance without being inflated by large numbers 
of correctly classified majority samples.

\subsection{Imbalanced Learning Techniques}

The class imbalance problem has been extensively studied across machine learning 
domains. Chen et al.~\cite{chen2024survey} survey recent advances in imbalanced 
learning, categorizing approaches into data-level methods (resampling), algorithm-level 
methods (cost-sensitive learning), and hybrid approaches. While these techniques improve 
minority class recognition, most operate independently of the model architecture, 
treating imbalance as a data preprocessing or loss function adjustment problem rather 
than integrating imbalance awareness into feature representation learning.

\subsubsection{Cost-Sensitive and Focal Loss Approaches}

Focal loss, introduced by Lin et al.~\cite{lin2017focal} for dense object detection, 
addresses class imbalance by down-weighting the loss contribution from well-classified 
examples:
\begin{equation}
\mathcal{L}_{\text{focal}} = -\alpha_t(1-p_t)^\gamma \log(p_t)
\end{equation}
This formulation focuses learning on hard negatives and rare classes by reducing the 
influence of easily classified majority samples. While highly effective for object 
detection where rare objects occupy small spatial regions, focal loss operates as a 
\textit{post-hoc adjustment to the classification objective}. The underlying feature 
representation—including attention mechanisms—remains unchanged and continues to be 
dominated by majority class patterns during training.

Cui et al.~\cite{cui2019class} proposed class-balanced loss based on effective number 
of samples, accounting for the diminishing marginal benefit of additional samples from 
majority classes. Their re-weighting scheme:
\begin{equation}
w_c = \frac{1-\beta}{1-\beta^{n_c}}
\end{equation}
where $n_c$ is the number of samples in class $c$ and $\beta \in [0,1)$ controls 
re-weighting strength, provides a principled approach to setting class weights. However, 
like focal loss, this operates only on the final loss function without modifying how 
attention mechanisms prioritize features during representation learning.

\subsubsection{Deep Representation Learning for Imbalanced Data}

Huang et al.~\cite{huang2016learning} proposed learning deep representations specifically 
for imbalanced classification through a two-stage approach: first learning features on 
balanced data, then fine-tuning on the imbalanced distribution. While this improves 
feature quality for minority classes, it requires careful curriculum design and does not 
address the fundamental issue of attention bias during standard training.

Milošević and Ćirić~\cite{milosevic2022extreme} specifically addressed extreme minority 
class detection in network intrusion, proposing a combination of SMOTE oversampling with 
ensemble methods. Their work demonstrates that even aggressive synthetic minority 
oversampling struggles with extremely rare classes (< 0.1\% of dataset), motivating our 
approach of integrating minority awareness directly into the model architecture rather 
than relying solely on data augmentation.

\subsection{Attention Mechanisms and Imbalanced Learning}

Attention mechanisms, formalized by Vaswani et al.~\cite{vaswani2017attention} in the 
Transformer architecture, enable models to selectively focus on relevant information 
through learned weighting of input features or sequence positions. The standard 
self-attention mechanism computes:
\begin{equation}
\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{equation}
where queries $Q$, keys $K$, and values $V$ are learned projections of the input. This 
formulation treats all samples identically, computing attention weights based solely on 
feature similarity without regard to class membership or rarity in the training distribution.

\subsubsection{Attention for Imbalanced Image Classification}

Wang et al.~\cite{wang2022deep} proposed deep attention-based imbalanced image 
classification, introducing a class-attention module that weights feature maps based on 
class frequency during training. Their approach applies attention at the channel level 
for convolutional features, emphasizing minority-class-relevant channels. However, this 
method is specifically designed for spatial image data where channels represent learned 
feature detectors, and the attention operates on intermediate feature maps rather than 
within the attention score computation itself.

Zhu et al.~\cite{zhu2021spectral} developed spectral-spatial attention for imbalanced 
hyperspectral image classification, demonstrating that spatial attention mechanisms can 
be adapted for imbalanced scenarios by incorporating class-prior knowledge. Their global 
learning framework uses attention to aggregate multi-scale features weighted by class 
distribution. While conceptually related to our work, their spatial attention operates 
on image patches and does not address tabular network flow data where spatial structure 
is absent.

\subsubsection{Limitations of Existing Attention Approaches}

A critical limitation of existing attention-based imbalanced learning methods is that 
they either: (1) apply attention uniformly across samples without class-awareness 
(standard attention), (2) modify feature maps post-attention based on class information 
(channel attention), or (3) use attention for sample re-weighting at the loss level 
(attention-based sample weighting). \textit{None integrate class imbalance awareness 
directly into the attention score computation itself}, where feature importance weights 
are determined.

Furthermore, existing methods primarily target image classification where minority classes 
share spatial structure with majority classes (e.g., small objects vs. large objects in 
the same scene). Network intrusion detection presents fundamentally different challenges: 
(1) tabular features lack spatial relationships, requiring different attention semantics; 
(2) minority attack classes exhibit high intra-class variability with subtle distinguishing 
features; (3) critical minority attacks may be completely absent from training batches due 
to extreme rarity; and (4) security requirements demand high recall (missing no attacks) 
even at the cost of increased false positives—a different optimization objective than 
general classification.

\subsection{Gap Analysis and Positioning}

Table~\ref{tab:related_comparison} summarizes the key differences between our approach 
and related work. While focal loss and class-balanced methods address imbalance through 
loss function design, and attention-based methods selectively weight features, FAIIA 
uniquely integrates both paradigms by applying focal modulation directly within attention 
score computation. The addition of learnable minority prototypes ensures consistent 
minority class representation regardless of batch composition—a critical consideration 
for extreme imbalance scenarios common in intrusion detection.

Our work advances beyond existing approaches in three key aspects:

\textbf{Architectural Integration:} Rather than treating imbalance as a loss function 
design problem (focal loss, class-balanced loss) or a post-attention feature weighting 
problem (channel attention), FAIIA integrates imbalance awareness into the attention 
mechanism itself, influencing feature weighting during representation learning.

\textbf{Explicit Minority Representation:} Learnable prototypes provide persistent 
minority class representations that participate in every attention computation, addressing 
the fundamental issue that minority classes may be absent from training batches in extreme 
imbalance scenarios.

\textbf{Domain-Specific Design:} FAIIA is designed specifically for tabular network flow 
data in intrusion detection, with attention semantics appropriate for feature-based 
representations rather than spatial or sequential structures, and with hyperparameter 
tunability ($\alpha$) enabling deployment-specific optimization between recall and precision.

\begin{table*}[t]
\centering
\caption{Comparison of Related Work on Imbalanced Learning and Attention Mechanisms}
\label{tab:related_comparison}
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Imbalance} & \textbf{Attention} & \textbf{Integration} & \textbf{Prototypes} & \textbf{NIDS} \\
 & \textbf{Aware} & \textbf{Mechanism} & \textbf{Point} & & \textbf{Focused} \\
\midrule
Focal Loss~\cite{lin2017focal} & \checkmark & \texttimes & Loss function & \texttimes & \texttimes \\
Class-Balanced~\cite{cui2019class} & \checkmark & \texttimes & Loss function & \texttimes & \texttimes \\
BAT (Su et al.)~\cite{su2020bat} & \texttimes & \checkmark & LSTM attention & \texttimes & \checkmark \\
Wang et al.~\cite{wang2022deep} & \checkmark & \checkmark & Channel-level & \texttimes & \texttimes \\
Zhu et al.~\cite{zhu2021spectral} & \checkmark & \checkmark & Feature maps & \texttimes & \texttimes \\
Milošević et al.~\cite{milosevic2022extreme} & \checkmark & \texttimes & SMOTE + ensemble & \texttimes & \checkmark \\
\midrule
\textbf{FAIIA (Ours)} & \checkmark & \checkmark & \textbf{Attention scores} & \checkmark & \checkmark \\
\bottomrule
\end{tabular}
\vspace{2mm}

\footnotesize{\textit{Note:} Integration Point indicates where imbalance awareness is incorporated: loss function (post-hoc), channel/feature-level (post-attention), or attention scores (within attention computation). Only FAIIA integrates at the attention score level with explicit minority prototypes for NIDS.}
\end{table*}

To the best of our knowledge, FAIIA represents the first attention mechanism to integrate 
focal modulation directly into attention score computation combined with learnable minority 
class prototypes, specifically designed for imbalanced network intrusion detection on 
tabular flow data.

\section{Methodology}
\label{sec:methodology}

This section presents the proposed FAA-Net architecture with FAIIA (Focal-Aware Imbalance-Integrated Attention) for network intrusion detection under severe class imbalance. We begin with the problem formulation, followed by detailed descriptions of the architectural components, training strategy, and implementation considerations.

\subsection{Problem Formulation}

Given a network traffic dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^{N}$, where $x_i \in \mathbb{R}^d$ represents a $d$-dimensional feature vector of network flow attributes and $y_i \in \{0, 1\}$ denotes the binary label (0 for normal traffic, 1 for attack), the objective is to learn a classifier $f: \mathbb{R}^d \rightarrow [0, 1]$ that accurately detects malicious traffic, addressing both the global class skew and the extreme scarcity of specific attack vectors (intra-class imbalance). 

The dataset exhibits a global imbalance ratio of 0.564756, with 164673 attack samples and 93000 normal samples across 257673 total instances. More critically, the per-attack category distribution reveals extreme local imbalance, with certain attack types containing fewer than 500 training samples. Specifically, the training set contains 175341 samples with 119341 attacks and 56000 normal instances (imbalance ratio: 0.469244), while the test set comprises 82332 samples with 45332 attacks and 37000 normal instances (imbalance ratio: 0.816200). This creates a challenging multi-level imbalance scenario where both inter-class and intra-class imbalances must be addressed simultaneously.

\subsection{Data Preprocessing Pipeline}

The preprocessing pipeline ensures data quality and feature relevance through systematic transformations applied consistently across training and test partitions.

% =====================================================================
% ALGORITHM 1: Data Preprocessing Pipeline
% =====================================================================

\begin{algorithm}[htbp]
\caption{Data Preprocessing Pipeline for UNSW-NB15}
\label{alg:preprocessing}
\begin{algorithmic}[1]
\REQUIRE Training set $\mathcal{D}_{\text{train}}$, Test set $\mathcal{D}_{\text{test}}$
\ENSURE Scaled feature matrices $X_{\text{train}}$, $X_{\text{test}}$, labels $y_{\text{train}}$, $y_{\text{test}}$

\STATE \textbf{Phase 1: Data Cleaning}
\FOR{$\mathcal{D} \in \{\mathcal{D}_{\text{train}}, \mathcal{D}_{\text{test}}\}$}
    \STATE Remove identifier columns
    \STATE Handle service field: replace `$-$' with `none'
    \STATE Replace infinite values with NaN in numeric features
\ENDFOR

\STATE \textbf{Phase 2: Missing Value Imputation}
\STATE Compute medians: $\mu_{\text{med}} \leftarrow \text{median}(\mathcal{D}_{\text{train}}[\text{numeric}])$
\STATE Impute training: $\mathcal{D}_{\text{train}} \leftarrow \text{fillna}(\mathcal{D}_{\text{train}}, \mu_{\text{med}})$
\STATE Impute test: $\mathcal{D}_{\text{test}} \leftarrow \text{fillna}(\mathcal{D}_{\text{test}}, \mu_{\text{med}})$

\STATE \textbf{Phase 3: Categorical Encoding}
\FOR{feature $c \in \{\texttt{proto}, \texttt{service}, \texttt{state}\}$}
    \STATE Fit encoder on training: $\text{LE}_c.\text{fit}(\mathcal{D}_{\text{train}}[c])$
    \STATE Transform training: $\mathcal{D}_{\text{train}}[c] \leftarrow \text{LE}_c.\text{transform}(\mathcal{D}_{\text{train}}[c])$
    \STATE Transform test with safe handling: $\mathcal{D}_{\text{test}}[c] \leftarrow \text{SafeTransform}(\text{LE}_c, \mathcal{D}_{\text{test}}[c])$
\ENDFOR

\STATE \textbf{Phase 4: Feature Selection}
\STATE Define correlated features: $\mathcal{F}_{\text{drop}} \leftarrow \{\texttt{ct\_dst\_src\_ltm}, \ldots, \texttt{sloss}\}$
\STATE Drop from both sets: $\mathcal{D}_{\text{train}}, \mathcal{D}_{\text{test}} \leftarrow \mathcal{D} \setminus \mathcal{F}_{\text{drop}}$

\STATE \textbf{Phase 5: Feature Standardization}
\STATE Fit scaler on training: $\mathcal{S}.\text{fit}(X_{\text{train}})$
\STATE Transform training: $X_{\text{train}} \leftarrow \mathcal{S}.\text{transform}(X_{\text{train}})$
\STATE Transform test: $X_{\text{test}} \leftarrow \mathcal{S}.\text{transform}(X_{\text{test}})$

\RETURN $X_{\text{train}} \in \mathbb{R}^{175341 \times 33}$, $X_{\text{test}} \in \mathbb{R}^{82332 \times 33}$, $y_{\text{train}}$, $y_{\text{test}}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Data Cleaning and Imputation}
The raw UNSW-NB15 dataset undergoes cleaning to handle missing values and infinite entries. Numerical features containing infinite values are replaced with NaN markers. Missing value imputation employs median-based substitution, where medians are computed exclusively on the training partition and applied to both training and test sets to prevent data leakage. This training-centric imputation strategy ensures that test data characteristics do not influence model training.

\subsubsection{Categorical Encoding}
Categorical features (protocol, service, and connection state) are transformed using label encoding fitted solely on training data. For test instances containing previously unseen categorical values, a safe transformation strategy maps unknown categories to a default encoding, preventing runtime errors while maintaining encoding consistency.

\subsubsection{Feature Selection}
To mitigate multicollinearity and reduce computational overhead, features exhibiting correlation coefficients exceeding 0.95 are systematically removed. Nine highly correlated features are eliminated: \texttt{ct\_dst\_src\_ltm}, \texttt{ct\_ftp\_cmd}, \texttt{ct\_src\_dport\_ltm}, \texttt{ct\_srv\_dst}, \texttt{dbytes}, \texttt{dloss}, \texttt{dwin}, \texttt{sbytes}, and \texttt{sloss}. This selection yields a final feature space of 33 dimensions.

\subsubsection{Feature Normalization}
Standard scaling is applied to normalize feature distributions. The StandardScaler is fitted exclusively on training data, with the learned parameters (mean and standard deviation) subsequently applied to test data. This ensures zero mean and unit variance normalization while preserving the independence of test set statistics.




\subsection{FAA-NET Architecture}

The Focal-Aware Attention Network (FAA-NET) introduces FAIIA as its core innovation, integrating focal-based imbalance awareness directly into the attention mechanism rather than solely relying on loss function modifications.

\subsubsection{Input Processing}

The architecture begins with batch normalization applied to the 33-dimensional input features:
\begin{equation}
x_{\text{norm}} = \text{BatchNorm}(x)
\end{equation}
where $x \in \mathbb{R}^{33}$ represents the preprocessed feature vector. This normalization stabilizes training dynamics and accelerates convergence.

\subsubsection{Initial Probability Estimation}

A lightweight probability estimator provides an initial minority class probability estimate that guides focal modulation within the attention mechanism:
\begin{equation}
p_{\text{init}} = \sigma(W_2 \cdot \text{ReLU}(W_1 x_{\text{norm}} + b_1) + b_2)
\end{equation}
where $W_1 \in \mathbb{R}^{64 \times 33}$, $W_2 \in \mathbb{R}^{1 \times 64}$, and $\sigma$ denotes the sigmoid activation. This estimator employs a compact two-layer architecture with 64 hidden units and 0.15 dropout rate, minimizing parameter overhead while providing class probability guidance.

\subsubsection{FAIIA: Focal-Aware Imbalance-Integrated Attention}

FAIIA constitutes the primary architectural innovation, embedding imbalance awareness within multi-head attention through focal modulation and prototype-based cross-attention.

\paragraph{Minority Prototype Generation}
Minority class prototypes are extracted offline using K-means clustering on attack samples:
\begin{equation}
\mathcal{P} = \{p_1, p_2, \ldots, p_K\} = \text{K-means}(\{x_i | y_i = 1\}, K)
\end{equation}
where $K=8$ prototypes capture the diversity of minority class feature distributions. These prototypes serve as learnable attention anchors within each FAIIA head.

% =====================================================================
% ALGORITHM 2: Minority Prototype Generation
% =====================================================================

\begin{algorithm}[htbp]
\caption{Minority Class Prototype Generation}
\label{alg:prototypes}
\begin{algorithmic}[1]
\REQUIRE Scaled training features $X_{\text{train}} \in \mathbb{R}^{N \times d}$, labels $y_{\text{train}} \in \{0,1\}^N$, number of prototypes $K$
\ENSURE Prototype matrix $\mathcal{P} \in \mathbb{R}^{K \times d}$

\STATE \textbf{Phase 1: Extract Minority Samples}
\STATE $\mathcal{I}_{\text{minority}} \leftarrow \{i \mid y_{\text{train}}^{(i)} = 1\}$
\STATE $X_{\text{minority}} \leftarrow X_{\text{train}}[\mathcal{I}_{\text{minority}}]$

\STATE \textbf{Phase 2: K-Means Clustering}
\IF{$|\mathcal{I}_{\text{minority}}| < K$}
    \STATE $\mathcal{P} \leftarrow X_{\text{minority}}[1:K]$
\ELSE
    \STATE Initialize K-Means with $K$ clusters, random state 42
    \STATE Fit clustering on $X_{\text{minority}}$
    \STATE $\mathcal{P} \leftarrow \text{cluster\_centers\_}$
\ENDIF

\RETURN Prototype matrix $\mathcal{P} \in \mathbb{R}^{K \times d}$
\end{algorithmic}
\end{algorithm}



\paragraph{Single-Head FAIIA Mechanism}
Each FAIIA head performs prototype-based cross-attention modulated by focal weighting. Given input $x \in \mathbb{R}^{33}$, the query projection is:
\begin{equation}
q = W_q x \in \mathbb{R}^{32}
\end{equation}
where $W_q \in \mathbb{R}^{32 \times 33}$ and the attention dimension is 32.

Prototype keys and values are learnable parameters initialized from minority prototypes:
\begin{equation}
K_{\text{proto}} = [k_1, k_2, \ldots, k_K]^\top \in \mathbb{R}^{K \times 32}
\end{equation}
\begin{equation}
V_{\text{proto}} = [v_1, v_2, \ldots, v_K]^\top \in \mathbb{R}^{K \times 32}
\end{equation}

Attention scores incorporate learnable prototype importance weights:
\begin{equation}
s = q K_{\text{proto}}^\top + w_{\text{proto}} \in \mathbb{R}^{K}
\end{equation}
where $w_{\text{proto}} \in \mathbb{R}^K$ are learnable bias terms allowing the model to prioritize discriminative prototypes.

\paragraph{Focal Modulation}
The focal modulation mechanism amplifies attention for uncertain predictions near the decision boundary. Unlike traditional focal loss formulations that emphasize confident misclassifications, FAIIA employs uncertainty-based modulation:
\begin{equation}
u = 1 - 2|p_{\text{init}} - 0.5|
\end{equation}
\begin{equation}
w_{\text{focal}} = \alpha (u + \epsilon)^\gamma \cdot \tau
\end{equation}
where $u$ measures prediction uncertainty (maximum at $p_{\text{init}} = 0.5$), $\alpha = 0.60$ is a learnable scaling factor, $\gamma = 2.0$ controls modulation strength, $\epsilon = 10^{-8}$ ensures numerical stability, and $\tau$ is a learnable temperature parameter. The modulated scores become:
\begin{equation}
s_{\text{mod}} = s \cdot (1 + w_{\text{focal}})
\end{equation}

Attention weights are computed via scaled softmax:
\begin{equation}
a = \text{softmax}(s_{\text{mod}} \cdot \sqrt{32}^{-1})
\end{equation}

The attended output aggregates prototype values:
\begin{equation}
h = a V_{\text{proto}} \in \mathbb{R}^{32}
\end{equation}

Output projection and layer normalization produce the final head output:
\begin{equation}
o = \text{LayerNorm}(W_o h)
\end{equation}
where $W_o \in \mathbb{R}^{32 \times 32}$.

\paragraph{Multi-Head Configuration}
FAA-NET employs 4 attention heads, each with slightly varied focal parameters to capture diverse attention patterns. Head $i$ uses focal $\alpha_i = 0.60 \times (1 + 0.1i)$, creating a spectrum of sensitivity levels across heads. Head outputs are concatenated and projected:
\begin{equation}
h_{\text{concat}} = [o_1; o_2; o_3; o_4] \in \mathbb{R}^{128}
\end{equation}
\begin{equation}
h_{\text{faiia}} = W_{\text{proj}} h_{\text{concat}} \in \mathbb{R}^{33}
\end{equation}
where $W_{\text{proj}} \in \mathbb{R}^{33 \times 128}$.

\paragraph{Class-Conditional Gating}
A difficulty-aware gating mechanism adaptively modulates features based on prediction uncertainty:
\begin{equation}
d = 1 - 2|p_{\text{init}} - 0.5|
\end{equation}
\begin{equation}
g = \sigma(W_{g2} \cdot \text{ReLU}(W_{g1}[h_{\text{faiia}}; d] + b_{g1}) + b_{g2})
\end{equation}
\begin{equation}
h_{\text{gated}} = h_{\text{faiia}} \odot g
\end{equation}
where $W_{g1} \in \mathbb{R}^{8 \times 34}$, $W_{g2} \in \mathbb{R}^{33 \times 8}$, and $\odot$ denotes element-wise multiplication. A residual connection preserves input information:
\begin{equation}
h_{\text{out}} = \text{LayerNorm}(h_{\text{gated}} + x_{\text{norm}})
\end{equation}

\subsubsection{Squeeze-and-Excitation Block}

Channel-wise feature recalibration is performed via a squeeze-and-excitation mechanism:
\begin{equation}
c = \sigma(W_{se2} \cdot \text{ReLU}(W_{se1} h_{\text{out}} + b_{se1}) + b_{se2})
\end{equation}
\begin{equation}
h_{\text{se}} = h_{\text{out}} \odot c
\end{equation}
where $W_{se1} \in \mathbb{R}^{8 \times 33}$ and $W_{se2} \in \mathbb{R}^{33 \times 8}$ implement a bottleneck with reduction ratio of 4.

\subsubsection{Deep Feature Extraction}

Three residual blocks progressively extract hierarchical representations with dimensions [256, 128, 64]:
\begin{equation}
h^{(l)} = \text{Dropout}(\text{GELU}(\text{BatchNorm}(W^{(l)} h^{(l-1)} + b^{(l)}))) + W_{\text{res}}^{(l)} h^{(l-1)}
\end{equation}
where $l \in \{1, 2, 3\}$, $h^{(0)} = h_{\text{se}}$, and $W_{\text{res}}^{(l)}$ is a projection matrix (or identity) ensuring dimensional compatibility for residual addition. Dropout rate is 0.3, and GELU activation introduces non-linearity.

\subsubsection{Classification Head}

The final classification head maps the 64-dimensional representation to binary predictions:
\begin{equation}
z = W_{c2} \cdot \text{GELU}(W_{c1} h^{(3)} + b_{c1}) + b_{c2}
\end{equation}
where $W_{c1} \in \mathbb{R}^{32 \times 64}$, $W_{c2} \in \mathbb{R}^{1 \times 32}$, and dropout rate is 0.15. The raw logit $z$ is used during training for numerical stability with the loss function.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/faiia_architecture.pdf}
    \caption{FAA-NET architecture with FAIIA mechanism. The model processes 
    33-dimensional network flow features through batch normalization, followed 
    by the novel FAIIA module (orange) that performs prototype-based cross-attention 
    with uncertainty-driven focal modulation guided by initial probability estimates 
    ($p_{\text{init}}$). FAIIA integrates class-conditional gating and residual 
    connections before feeding to standard components: Squeeze-and-Excitation block, 
    three residual blocks with progressive dimensionality reduction [256→128→64], 
    and a final classifier head. Dashed lines indicate control signals; solid 
    lines show main feature flow.}
    \label{fig:architecture}
\end{figure}

\subsection{Loss Function: Imbalance-Aware Focal Loss}

The model employs an imbalance-aware focal loss that combines automatic class weighting with focal modulation to address both class imbalance and hard example mining:
\begin{equation}
\mathcal{L}_{\text{focal}} = -\alpha_t (1 - p_t)^\gamma \log(p_t)
\end{equation}
where:
\begin{equation}
p_t = \begin{cases}
\sigma(z) & \text{if } y = 1 \\
1 - \sigma(z) & \text{if } y = 0
\end{cases}
\end{equation}
\begin{equation}
\alpha_t = \begin{cases}
\frac{N}{2N_{\text{pos}}} & \text{if } y = 1 \\
\frac{N}{2N_{\text{neg}}} & \text{if } y = 0
\end{cases}
\end{equation}

Given class counts $N_{\text{neg}} = 56000$ and $N_{\text{pos}} = 119341$ in the training set, the computed weights are $\alpha_{\text{pos}} = 0.7354$ and $\alpha_{\text{neg}} = 1.5655$. The focal parameter $\gamma = 2.0$ down-weights well-classified examples. Binary cross-entropy is computed via \texttt{BCEWithLogitsLoss} for numerical stability.

Label smoothing with $\epsilon = 0.05$ is applied during training:
\begin{equation}
y_{\text{smooth}} = y(1 - \epsilon) + 0.5\epsilon
\end{equation}
This regularization technique prevents overconfident predictions and improves generalization.

\subsection{Optimization Strategy}

\subsubsection{Optimizer Configuration}
The AdamW optimizer with decoupled weight decay is employed:
\begin{equation}
\theta_{t+1} = \theta_t - \eta_t \left(\frac{m_t}{\sqrt{v_t} + \epsilon} + \lambda \theta_t\right)
\end{equation}
where $\eta_t$ is the learning rate at iteration $t$, $m_t$ and $v_t$ are the first and second moment estimates, $\epsilon = 10^{-8}$, and $\lambda = 10^{-4}$ is the weight decay coefficient. The initial learning rate is $\eta_0 = 0.001$.

\subsubsection{Learning Rate Scheduling}
Cosine annealing with warm restarts adjusts the learning rate dynamically:
\begin{equation}
\eta_t = \eta_{\min} + \frac{1}{2}(\eta_0 - \eta_{\min})\left(1 + \cos\left(\frac{T_{\text{cur}}}{T_i}\pi\right)\right)
\end{equation}
where $T_{\text{cur}}$ is the number of epochs since the last restart, $T_i$ is the restart period (initially $T_0 = 15$, multiplied by $T_{\text{mult}} = 2$ after each restart), and $\eta_{\min} = 10^{-6}$.

\subsubsection{Regularization Techniques}
Gradient clipping prevents exploding gradients by constraining the L2 norm:
\begin{equation}
g \leftarrow \begin{cases}
g \cdot \frac{1.0}{\|g\|_2} & \text{if } \|g\|_2 > 1.0 \\
g & \text{otherwise}
\end{cases}
\end{equation}

\subsubsection{Training Protocol}
Training proceeds for a maximum of 150 epochs with batch size 256. A 90/10 train-validation split is applied to the training partition, with validation performance guiding early stopping. Training terminates if validation F1-score fails to improve for 20 consecutive epochs, and the model state with highest validation F1-score is retained.

% =====================================================================
% ALGORITHM 3: FAA-NET Training with FAIIA
% =====================================================================

\begin{algorithm}[htbp]
\caption{FAA-NET Training with Early Stopping}
\label{alg:training}
\begin{algorithmic}[1]
\REQUIRE Train loader $\mathcal{L}_{\text{train}}$, validation loader $\mathcal{L}_{\text{val}}$, model $\mathcal{M}$, loss function $\mathcal{L}_{\text{focal}}$, config $\mathcal{C}$
\ENSURE Trained model $\mathcal{M}^*$

\STATE \textbf{// Initialization}
\STATE Optimizer $\leftarrow$ AdamW($\mathcal{M}.\text{parameters}(), \text{lr}=0.001, \text{weight\_decay}=10^{-4}$)
\STATE Scheduler $\leftarrow$ CosineAnnealingWarmRestarts($T_0=15, T_{\text{mult}}=2, \eta_{\min}=10^{-6}$)
\STATE $F1_{\text{best}} \leftarrow 0$, $\mathcal{M}_{\text{best}} \leftarrow \text{None}$, $\text{patience\_counter} \leftarrow 0$

\STATE \textbf{// Training Loop}
\FOR{epoch $= 1$ to $\mathcal{C}[\text{epochs}]$} \COMMENT{Max 150 epochs}
    
    \STATE \textbf{// Training Phase}
    \STATE $\mathcal{M}.\text{train}()$
    \STATE $\mathcal{L}_{\text{train\_epoch}} \leftarrow 0$
    \FOR{$(X_{\text{batch}}, y_{\text{batch}}) \in \mathcal{L}_{\text{train}}$}
        \STATE Apply label smoothing: $y_{\text{smooth}} \leftarrow y_{\text{batch}}(1 - \epsilon) + 0.5\epsilon$ \COMMENT{$\epsilon = 0.05$}
        \STATE Forward pass: $\hat{y} \leftarrow \mathcal{M}(X_{\text{batch}})$ \COMMENT{Returns logits}
        \STATE Compute loss: $\ell \leftarrow \mathcal{L}_{\text{focal}}(\hat{y}, y_{\text{smooth}})$
        \STATE Backward pass: $\ell.\text{backward}()$
        \STATE Gradient clipping: $\text{clip\_grad\_norm\_}(\mathcal{M}.\text{parameters}(), \text{max\_norm}=1.0)$
        \STATE Update weights: Optimizer$.\text{step}()$, Optimizer$.\text{zero\_grad}()$
        \STATE $\mathcal{L}_{\text{train\_epoch}} \leftarrow \mathcal{L}_{\text{train\_epoch}} + \ell$
    \ENDFOR
    \STATE Scheduler$.\text{step}()$ \COMMENT{Update learning rate}
    
    \STATE \textbf{// Validation Phase}
    \STATE $\mathcal{M}.\text{eval}()$
    \STATE $\mathcal{L}_{\text{val\_epoch}} \leftarrow 0$, $\hat{y}_{\text{val}} \leftarrow []$, $y_{\text{val}} \leftarrow []$
    \FOR{$(X_{\text{batch}}, y_{\text{batch}}) \in \mathcal{L}_{\text{val}}$}
        \STATE Forward (no grad): $\hat{y}_{\text{batch}} \leftarrow \mathcal{M}(X_{\text{batch}})$
        \STATE $\mathcal{L}_{\text{val\_epoch}} \leftarrow \mathcal{L}_{\text{val\_epoch}} + \mathcal{L}_{\text{focal}}(\hat{y}_{\text{batch}}, y_{\text{batch}})$
        \STATE Collect predictions: $\hat{y}_{\text{val}}.\text{append}(\sigma(\hat{y}_{\text{batch}}) > 0.5)$ \COMMENT{Sigmoid + threshold}
        \STATE Collect labels: $y_{\text{val}}.\text{append}(y_{\text{batch}})$
    \ENDFOR
    \STATE Compute validation F1: $F1_{\text{val}} \leftarrow \text{f1\_score}(y_{\text{val}}, \hat{y}_{\text{val}})$
    
    \STATE \textbf{// Early Stopping Check}
    \IF{$F1_{\text{val}} > F1_{\text{best}}$}
        \STATE $F1_{\text{best}} \leftarrow F1_{\text{val}}$
        \STATE $\mathcal{M}_{\text{best}} \leftarrow \text{deepcopy}(\mathcal{M}.\text{state\_dict}())$
        \STATE $\text{patience\_counter} \leftarrow 0$
    \ELSE
        \STATE $\text{patience\_counter} \leftarrow \text{patience\_counter} + 1$
    \ENDIF
    
    \IF{$\text{patience\_counter} \geq \mathcal{C}[\text{patience}]$} \COMMENT{Patience = 20}
        \STATE \textbf{break} \COMMENT{Early stopping triggered}
    \ENDIF
\ENDFOR

\STATE \textbf{// Restore Best Model}
\STATE $\mathcal{M}.\text{load\_state\_dict}(\mathcal{M}_{\text{best}})$

\RETURN Trained model $\mathcal{M}^*$ with best validation F1
\end{algorithmic}
\end{algorithm}


\subsection{Ablation Study Design}

To isolate the contribution of FAIIA and focal loss, we conduct controlled ablation experiments:

\begin{enumerate}
    \item \textbf{Vanilla DNN + BCE}: A standard feedforward network with architecture [256, 128, 64] trained using weighted binary cross-entropy. This baseline contains 54657 parameters.
    
    \item \textbf{Vanilla DNN + Focal}: The same architecture trained with imbalance-aware focal loss, isolating the impact of focal loss alone.
    
    \item \textbf{FAIIA + BCE}: FAA-NET with FAIIA trained using weighted binary cross-entropy, evaluating the attention mechanism without focal loss. This configuration contains 127844 parameters.
    
    \item \textbf{FAIIA + Focal}: The complete proposed model combining FAIIA and focal loss.
\end{enumerate}

All ablation models share identical preprocessing, optimization strategies, and hyperparameters to ensure fair comparison. Models output raw logits and employ \texttt{BCEWithLogitsLoss} or \texttt{ImbalanceAwareFocalLoss\_Logits} for numerical stability.

\subsection{Baseline Comparisons}

To contextualize performance, we compare against established tree-based methods optimized for imbalanced tabular data:

\paragraph{XGBoost}
Configured with 100 estimators, maximum depth 6, learning rate 0.1, subsample ratio 0.8, column subsample ratio 0.8, and scale\_pos\_weight = 0.469 (inverse of class imbalance ratio).

\paragraph{LightGBM}
Configured with 100 estimators, 31 leaves, learning rate 0.1, and automatic balanced class weighting. Both baselines employ identical preprocessing and are trained on the full training set.

\subsection{Evaluation Metrics}

Model performance is assessed using metrics appropriate for imbalanced classification:

\begin{itemize}
    \item \textbf{Accuracy}: Overall classification correctness, $\frac{TP + TN}{TP + TN + FP + FN}$
    \item \textbf{Precision}: Positive predictive value, $\frac{TP}{TP + FP}$
    \item \textbf{Recall}: True positive rate (sensitivity), $\frac{TP}{TP + FN}$
    \item \textbf{F1-Score}: Harmonic mean of precision and recall, $2 \cdot \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$
    \item \textbf{AUC-ROC}: Area under the receiver operating characteristic curve, measuring discrimination ability across thresholds
    \item \textbf{Average Precision}: Area under the precision-recall curve, particularly informative for imbalanced scenarios
\end{itemize}

Primary evaluation focus is on recall and F1-score, as these metrics directly reflect minority class detection capability—the central objective in intrusion detection.

\subsection{Implementation Details}

The implementation leverages PyTorch 2.0 with CUDA acceleration where available. All experiments use random seed 42 for reproducibility. Training is conducted on NVIDIA GPU hardware when available, falling back to CPU otherwise. Data preprocessing employs scikit-learn 1.3, while XGBoost 1.7 and LightGBM 4.0 provide baseline implementations. The K-means clustering for prototype generation uses scikit-learn with 10 random initializations to ensure stable prototype selection.

\section{Experimental Setup}
\label{sec:experimental_setup}

\subsection{Dataset and Preprocessing}

The UNSW-NB15 dataset~\cite{moustafa2015unsw} was employed for evaluation, comprising network traffic captures with labeled attack categories. The dataset was partitioned into predefined training and testing splits, as detailed in Table~\ref{tab:dataset_stats}. The substantial class imbalance—with a train set imbalance ratio of 0.469 and test set ratio of 0.816—presents a realistic evaluation scenario for intrusion detection systems deployed in operational environments.

\begin{table}[!t]
\caption{Dataset Statistics}
\label{tab:dataset_stats}
\centering
\begin{tabular}{lrrrr}
\hline
\textbf{Split} & \textbf{Samples} & \textbf{Attack} & \textbf{Normal} & \textbf{Ratio} \\
\hline
Train & 175,341 & 119,341 & 56,000 & 0.469 \\
Test  & 82,332  & 45,332  & 37,000 & 0.816 \\
Total & 257,673 & 164,673 & 93,000 & 0.565 \\
\hline
\end{tabular}
\end{table}

The per-attack class distribution reveals severe granular imbalance, with minority attack categories containing as few as 44 samples (Worms) while majority categories exceed 18,000 samples (Table~\ref{tab:per_attack_dist}). This heterogeneous distribution motivates the need for specialized minority-aware mechanisms, as traditional approaches struggle to detect rare attack variants that constitute critical security threats.

\begin{table}[!t]
\caption{Per-Attack Sample Distribution}
\label{tab:per_attack_dist}
\centering
\begin{tabular}{lrrr}
\hline
\textbf{Attack Category} & \textbf{Train} & \textbf{Test} & \textbf{Total} \\
\hline
Generic          & 40,000 & 18,871 & 58,871 \\
Normal           & 56,000 & 37,000 & 93,000 \\
DoS              & 33,393 & 11,132 & 44,525 \\
Exploits         & 18,184 &  6,062 & 24,246 \\
Fuzzers          & 12,264 &  4,089 & 16,353 \\
Reconnaissance   & 10,491 &  3,496 & 13,987 \\
Backdoor         &  2,000 &    677 &  2,677 \\
Analysis         &  1,746 &    583 &  2,329 \\
Shellcode        &  1,133 &    378 &  1,511 \\
Worms            &    130 &     44 &    174 \\
\hline
\end{tabular}
\end{table}

Data preprocessing followed established practices for network intrusion detection. Categorical features (protocol, service, state) were label-encoded using consistent mappings across train and test splits to ensure feature space alignment. Nine features exhibiting Pearson correlation coefficients exceeding 0.95 were removed to reduce multicollinearity and computational overhead: \texttt{ct\_dst\_src\_ltm}, \texttt{ct\_ftp\_cmd}, \texttt{ct\_src\_dport\_ltm}, \texttt{ct\_srv\_dst}, \texttt{dbytes}, \texttt{dloss}, \texttt{dwin}, \texttt{sbytes}, and \texttt{sloss}. Infinite values were replaced with NaN and subsequently imputed using column-wise median values computed on the training set. Feature scaling was performed via standardization (zero mean, unit variance), with scaling parameters fitted exclusively on training data and applied to both train and test partitions to prevent information leakage. The final feature dimensionality was 33.

\subsection{Model Configuration}

The proposed FAA-NET architecture with FAIIA was configured with hyperparameters selected through preliminary validation experiments. The FAIIA module employed 4 attention heads with attention dimension of 32, initializing 8 minority class prototypes via K-means clustering~\cite{huang2016learning} on attack-class training samples. The feature extraction backbone utilized hidden layer dimensions of [256, 128, 64] with residual connections and dropout rate of 0.3. Attention-specific dropout was set to 0.1 to regularize the FAIIA mechanism. Focal modulation parameters were configured as $\alpha = 0.60$ and $\gamma = 2.0$, following the formulation in~\cite{lin2017focal}.

Training employed the AdamW optimizer with initial learning rate $\eta_0 = 0.001$ and weight decay $\lambda = 1 \times 10^{-4}$. A cosine annealing warm restart scheduler~\cite{loshchilov2017sgdr} was deployed with $T_0 = 15$, $T_{\text{mult}} = 2$, and $\eta_{\text{min}} = 1 \times 10^{-6}$ to escape local minima during optimization. Label smoothing of $\epsilon = 0.05$ was applied to prevent overconfidence on training samples. Early stopping with patience of 20 epochs monitored validation F1-score, with a maximum of 150 training epochs. Gradient clipping (maximum norm 1.0) stabilized training dynamics in the presence of extreme class imbalance. Mini-batch size was set to 256. All experiments utilized random seed 42 for reproducibility across PyTorch, NumPy, and scikit-learn components.

The imbalance-aware focal loss~\cite{lin2017focal} automatically computed class weights based on empirical class frequencies:
\begin{equation}
\alpha_{\text{pos}} = \frac{N_{\text{total}}}{2 \times N_{\text{positive}}}, \quad \alpha_{\text{neg}} = \frac{N_{\text{total}}}{2 \times N_{\text{negative}}}
\end{equation}
where $N_{\text{total}}$ represents total samples and $N_{\text{positive}}$, $N_{\text{negative}}$ denote positive and negative class counts respectively. This adaptive weighting addresses the dynamic imbalance present in the UNSW-NB15 dataset.

\subsection{Baseline Models and Ablation Study}

To contextualize the contribution of FAIIA, we evaluated two categories of comparison models:

\subsubsection{Traditional Machine Learning Baselines}
XGBoost~\cite{chen2016xgboost} was configured with 100 estimators, maximum tree depth of 6, learning rate of 0.1, subsample ratio of 0.8, and column subsample ratio of 0.8. The \texttt{scale\_pos\_weight} parameter was computed as the ratio of negative to positive class counts to handle imbalance. LightGBM~\cite{ke2017lightgbm} utilized 100 estimators, 31 leaves per tree, learning rate of 0.1, and balanced class weights determined automatically from the training distribution. Both models were trained on identical preprocessed features with 4 CPU threads to prevent computational bottlenecks.

\subsubsection{Ablation Study Variants}
Four deep learning configurations systematically isolated the contributions of the FAIIA mechanism and focal loss function:

\begin{enumerate}
    \item \textbf{Vanilla DNN + BCE}: Standard feed-forward network with hidden dimensions [256, 128, 64], dropout of 0.3, and binary cross-entropy loss with positive class weighting. This baseline establishes performance without attention mechanisms or focal modulation.
    
    \item \textbf{Vanilla DNN + Focal}: Identical architecture to Variant 1, but trained with imbalance-aware focal loss ($\alpha = 0.60$, $\gamma = 2.0$). This variant isolates the contribution of focal loss independent of attention.
    
    \item \textbf{FAIIA + BCE}: FAA-NET architecture with full FAIIA mechanism (multi-head attention, prototype integration, focal modulation) trained using weighted BCE loss. This configuration evaluates FAIIA's architectural contribution without specialized loss design.
    
    \item \textbf{FAIIA + Focal}: The complete proposed model combining FAIIA architecture with imbalance-aware focal loss. This represents the full FAA-NET system.
\end{enumerate}

All deep learning variants shared identical training procedures (optimizer, scheduler, early stopping criteria) to ensure fair comparison. The Vanilla DNN contained 54,657 trainable parameters, while FAA-NET with FAIIA contained 142,436 parameters—a 2.6$\times$ increase attributable to the multi-head attention mechanism and prototype embeddings.

\subsection{Evaluation Metrics}

Model performance was assessed using six complementary metrics appropriate for imbalanced classification~\cite{sokolova2009systematic}: Accuracy, Precision, Recall, F1-Score, AUC-ROC, and Average Precision (AP). Given the severe class imbalance and security-critical nature of intrusion detection, we prioritized Recall (minimizing false negatives) and F1-Score (balancing precision-recall trade-offs) as primary evaluation criteria. AUC-ROC and Average Precision quantify ranking quality across decision thresholds~\cite{davis2006relationship}, providing threshold-independent performance assessment. Per-attack category detection rates were computed to evaluate minority class detection capability, the core motivation for FAIIA.

All experiments were conducted on hardware equipped with NVIDIA GPU acceleration (when available) and CPU fallback. Inference latency was qualitatively categorized as Fast, Moderate, or Slow based on forward pass timing with batch size 256.





% \textbf{Impact of FAIIA Architecture:} Comparing variants with identical loss functions reveals FAIIA's contribution:
% \begin{itemize}
%     \item \textit{BCE Loss}: FAIIA + BCE (F1 0.9018) vs. Vanilla DNN + BCE (F1 0.9051) shows a marginal 0.33 percentage point decrease in F1-score, but achieves 2.26 percentage point improvement in recall (0.9354 vs. 0.9128).
%     \item \textit{Focal Loss}: FAIIA + Focal (F1 0.8923) vs. Vanilla DNN + Focal (F1 0.9099) exhibits a 1.76 percentage point F1 decrease, offset by a substantial 6.87 percentage point recall improvement (0.9470 vs. 0.8783).
% \end{itemize}

% This pattern indicates that FAIIA shifts the precision-recall trade-off toward recall maximization by emphasizing minority class detection through focal modulation and prototype-based attention. The mechanism successfully addresses the primary objective of detecting rare attack variants, albeit with modest precision reduction.

% \textbf{Impact of Focal Loss:} Within the same architecture family, focal loss exhibits distinct effects:
% \begin{itemize}
%     \item \textit{Vanilla DNN}: Focal loss increased precision by 4.66 percentage points (0.9440 vs. 0.8974) but decreased recall by 3.45 percentage points (0.8783 vs. 0.9128), suggesting focal loss alone biases the vanilla architecture toward conservative predictions.
%     \item \textit{FAIIA}: Focal loss decreased precision by 2.70 percentage points (0.8435 vs. 0.8705) but increased recall by 1.16 percentage points (0.9470 vs. 0.9354), demonstrating synergistic interaction with the attention mechanism that amplifies minority class sensitivity.
% \end{itemize}

% The divergent behavior of focal loss across architectures reveals an important finding: focal modulation integrated into FAIIA's attention scores produces qualitatively different behavior than focal loss applied as a standalone training objective. The architectural integration enables adaptive instance-level attention reweighting that complements the loss-level difficulty weighting.

% \subsection{Per-Attack Category Detection Analysis}

% Table~\ref{tab:per_attack_detection} presents detection rates for individual attack categories, partitioned by sample size to evaluate minority class performance. Attack categories with fewer than 5,000 test samples were designated as minority classes for this analysis.

% \begin{table}[!t]
% \caption{Per-Attack Category Detection Rates (FAA-NET with FAIIA)}
% \label{tab:per_attack_detection}
% \centering
% \begin{tabular}{llrrr}
% \hline
% \textbf{ID} & \textbf{Category} & \textbf{Samples} & \textbf{Detection} & \textbf{Type} \\
% \hline
% 6 & Normal (FPR)     & 37,000 & 0.1916 & Majority \\
% 5 & Generic          & 18,871 & 0.9985 & Majority \\
% 3 & Exploits         & 11,132 & 0.9707 & Majority \\
% 4 & Fuzzers          &  6,062 & 0.6099 & Majority \\
% \hline
% 2 & DoS              &  4,089 & 0.9797 & Minority \\
% 7 & Reconnaissance   &  3,496 & 0.9580 & Minority \\
% 0 & Analysis         &    677 & 0.9941 & Minority \\
% 1 & Backdoor         &    583 & 0.9897 & Minority \\
% 8 & Shellcode        &    378 & 0.9180 & Minority \\
% 9 & Worms            &     44 & 0.9545 & Minority \\
% \hline
% \end{tabular}
% \end{table}

% The results demonstrate FAIIA's effectiveness in detecting minority attack classes. Despite having only 44 test samples, Worms attacks were detected at 95.45\% rate—substantially higher than would be expected from a standard classifier biased toward majority classes. Similarly, Backdoor (98.97\%), Analysis (99.41\%), DoS (97.97\%), and Reconnaissance (95.80\%) attacks exhibited detection rates exceeding 95\%, validating the minority-aware design of FAIIA.

% Notably, the false positive rate on normal traffic was 19.16\%, indicating that approximately 1 in 5 benign connections were misclassified as attacks. This elevated FPR represents a trade-off inherent in recall-optimized systems and aligns with FAIIA's design philosophy of prioritizing attack detection over false alarm minimization. In security-critical deployments, this trade-off is often acceptable, as missed attacks (false negatives) carry higher operational risk than false alarms that can be filtered through secondary verification.

% The Fuzzers category exhibited the lowest detection rate among majority classes (60.99\%), suggesting that fuzzing traffic patterns may share statistical characteristics with normal traffic or that the category contains diverse sub-types requiring specialized treatment. This observation motivates future work on hierarchical attention mechanisms that can distinguish within-category variations.

% \subsection{Model Complexity and Efficiency}

% Table~\ref{tab:model_complexity} compares the computational complexity of deep learning variants. FAA-NET with FAIIA contains 142,436 trainable parameters compared to 54,657 for Vanilla DNN, representing a 2.6$\times$ parameter increase. This growth stems from the multi-head attention mechanism (query, key, value projections across 4 heads), prototype embeddings (8 prototypes $\times$ 32 dimensions per head), and additional gating mechanisms.

% \begin{table}[!t]
% \caption{Model Complexity Comparison}
% \label{tab:model_complexity}
% \centering
% \begin{tabular}{lrc}
% \hline
% \textbf{Model} & \textbf{Parameters} & \textbf{Inference Speed} \\
% \hline
% Vanilla DNN        & 54,657  & Fast \\
% FAIIA (FAA-NET)   & 142,436 & Moderate \\
% \hline
% \end{tabular}
% \end{table}

% Despite the parameter increase, inference remained at moderate speed due to the efficient design of FAIIA. The attention mechanism operates on fixed-size feature representations rather than variable-length sequences, avoiding the quadratic complexity of transformer-based models. For batch size 256, the forward pass completed in acceptable time for real-time network monitoring scenarios.

% The 2.6$\times$ parameter overhead represents a reasonable cost for the recall improvements achieved, particularly when deployed on modern edge computing hardware with GPU acceleration. For resource-constrained environments, future work could explore knowledge distillation or pruning techniques to compress FAIIA while retaining its minority-aware properties.

% \subsection{Training Dynamics and Convergence}




% Figure~\ref{fig:convergence_loss} illustrates the training and validation loss curves for FAA-NET, demonstrating stable convergence without significant overfitting. The cosine annealing scheduler produced characteristic periodic restarts that enabled escape from local minima. Early stopping triggered after 54 epochs without validation F1 improvement, typically occurring between epoch 60 and 90 depending on initialization.



% Figure~\ref{fig:f1_epoch} shows F1-score and recall progression during training. Notably, validation recall stabilized earlier than validation F1, suggesting that FAIIA learns minority-sensitive representations in early training epochs while precision refinement requires additional iterations. This behavior aligns with the focal modulation mechanism's emphasis on hard examples, which are predominantly minority class instances in imbalanced scenarios.




% \subsection{Key Findings and Implications}

% The experimental results yield several important conclusions:

% \begin{enumerate}
%     \item \textbf{FAIIA achieves state-of-the-art minority attack detection:} With 94.70\% recall and consistent high detection rates across rare attack categories (Worms 95.45\%, Shellcode 91.80\%), FAIIA demonstrates superior minority class sensitivity compared to baselines. This validates the core hypothesis that integrating focal concepts into attention mechanisms enhances minority detection.
    
%     \item \textbf{Architectural integration outperforms loss-only approaches:} The 6.87 percentage point recall improvement of FAIIA + Focal over Vanilla DNN + Focal demonstrates that embedding imbalance awareness into the attention mechanism produces complementary benefits beyond focal loss alone.
    
%     \item \textbf{Precision-recall trade-offs are task-appropriate:} The modest precision reduction (84.35\% for FAIIA + Focal vs. 94.40\% for Vanilla DNN + Focal) is acceptable in intrusion detection contexts where false negatives represent security breaches. The 19.16\% false positive rate on normal traffic can be managed through alert prioritization systems.
    
%     \item \textbf{Competitive performance despite lower overall F1:} While LightGBM achieved the highest overall F1-score (0.9088 vs. 0.8936 for FAIIA), the deep learning approach offers advantages in end-to-end learning, extensibility to raw packet features, and integration with neural security frameworks—trade-offs that justify the marginal performance gap.
% \end{enumerate}

% These findings position FAA-NET with FAIIA as a specialized solution for minority-aware intrusion detection, complementing rather than replacing gradient boosting baselines in comprehensive security architectures.



\section{Results and Analysis}
\label{sec:results}

This section presents comprehensive experimental results demonstrating the effectiveness of FAA-NET with FAIIA for imbalanced network intrusion detection. We analyze overall classification performance, conduct ablation studies to validate architectural choices, examine per-attack detection capabilities, and assess computational efficiency.

\subsection{Overall Performance Comparison}

Table~\ref{tab:overall_performance} presents the classification performance of all evaluated models on the UNSW-NB15 test set. The results reveal nuanced trade-offs between different architectural and loss function choices in addressing class imbalance.

% \begin{table}[htbp]
% \centering
% \caption{Overall Classification Performance on UNSW-NB15 Test Set}
% \label{tab:overall_performance}
% \begin{tabular}{lcccccc}
% \toprule
% \textbf{Model} & \textbf{Acc.} & \textbf{Prec.} & \textbf{Rec.} & \textbf{F1} & \textbf{AUC} & \textbf{AP} \\
% \midrule
% Vanilla DNN + BCE & 0.8946 & 0.8974 & 0.9129 & 0.9051 & 0.9721 & 0.9799 \\
% Vanilla DNN + Focal & 0.9043 & 0.9440 & 0.8782 & 0.9099 & 0.9707 & 0.9789 \\
% FAIIA + BCE & 0.8778 & 0.8528 & \textbf{0.9403} & 0.8944 & 0.9725 & 0.9799 \\
% FAIIA + Focal & 0.8658 & 0.8309 & \textbf{0.9495} & 0.8863 & 0.9706 & 0.9786 \\
% \midrule
% XGBoost & 0.8961 & 0.8856 & 0.9317 & 0.9081 & \textbf{0.9765} & 0.9830 \\
% LightGBM & \textbf{0.8969} & 0.8858 & 0.9330 & \textbf{0.9088} & \textbf{0.9776} & \textbf{0.9839} \\
% \bottomrule
% \end{tabular}
% \end{table}

\begin{table}[htbp]
\centering
\caption{OVERALL CLASSIFICATION PERFORMANCE ON THE UNSW-NB15 TEST SET}
\label{tab:overall_performance}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Acc.} & \textbf{Prec.} & \textbf{Rec.} & \textbf{F1} & \textbf{AUC} & \textbf{AP} \\
\midrule
Vanilla DNN + BCE   & 0.8946 & 0.8974 & 0.9129 & 0.9051 & 0.9721 & 0.9799 \\
Vanilla DNN + Focal & 0.9043 & 0.9440 & 0.8782 & 0.9099 & 0.9707 & 0.9789 \\
FAIIA + BCE         & 0.8778 & 0.8528 & \textbf{0.9403} & 0.8944 & 0.9725 & 0.9799 \\
FAIIA + Focal       & 0.8658 & 0.8309 & \textbf{0.9495} & 0.8863 & 0.9706 & 0.9786 \\
\midrule
XGBoost             & 0.8961 & 0.8856 & 0.9317 & 0.9081 & \textbf{0.9765} & 0.9830 \\
LightGBM            & \textbf{0.8969} & 0.8858 & 0.9330 & \textbf{0.9088} & \textbf{0.9776} & \textbf{0.9839} \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsubsection{Key Performance Observations}

The FAIIA-equipped models demonstrate the highest recall rates among all evaluated approaches, with FAIIA + Focal achieving 0.9495 recall and FAIIA + BCE achieving 0.9403 recall. This represents a substantial improvement in minority class detection capability—the primary objective in intrusion detection systems where missing attacks incurs greater cost than false alarms. The FAIIA + Focal configuration detects 94.95\% of attack instances, surpassing the best baseline (LightGBM at 0.9330) by 1.65 percentage points in absolute recall.

This recall improvement comes at the cost of precision, with FAIIA + Focal achieving 0.8309 precision compared to LightGBM's 0.8858. The precision-recall trade-off reflects the fundamental challenge in imbalanced learning: aggressively optimizing for minority class detection inevitably increases false positive rates. However, for network security applications where the cost of missed attacks significantly exceeds false alarm costs, this trade-off is operationally acceptable.

The tree-based baselines (XGBoost and LightGBM) achieve the most balanced performance profiles, with LightGBM attaining the highest F1-score (0.9088), AUC-ROC (0.9776), and average precision (0.9839). Their strong performance reflects inherent advantages for tabular data: resistance to feature scale variations, automatic feature interaction modeling, and effective handling of imbalanced distributions through sample weighting.

\subsubsection{Impact of Architectural Components}

Comparing Vanilla DNN configurations reveals that focal loss improves precision substantially (0.8974 to 0.9440) while reducing recall (0.9129 to 0.8782), resulting in a modest F1-score gain (0.9051 to 0.9099). This behavior aligns with focal loss theory: by down-weighting well-classified examples, the loss focuses on hard negatives, improving decision boundary precision but potentially sacrificing sensitivity to challenging minority instances.

The introduction of FAIIA produces the opposite effect: both FAIIA + BCE and FAIIA + Focal achieve significantly higher recall than their vanilla counterparts, demonstrating that the attention mechanism successfully amplifies minority class detection. FAIIA + BCE improves recall from 0.9129 to 0.9403 (2.74 percentage points) compared to Vanilla DNN + BCE, confirming that prototype-based attention with focal modulation effectively guides the model toward minority class patterns.

Notably, FAIIA + Focal achieves the highest recall (0.9495) despite having a lower F1-score (0.8863) than simpler baselines. This suggests that while the combination of FAIIA and focal loss maximizes minority detection, it may introduce redundant emphasis on difficult examples, leading to over-conservative predictions that increase false positives.

\subsection{Ablation Study Analysis}

The ablation experiments systematically isolate the contributions of FAIIA and focal loss, revealing their distinct and complementary roles in addressing class imbalance.

\subsubsection{Effect of FAIIA Attention Mechanism}

Comparing Vanilla DNN + BCE (0.9129 recall) to FAIIA + BCE (0.9403 recall) isolates the impact of the attention mechanism while holding the loss function constant. The 2.74 percentage point recall improvement demonstrates that FAIIA's prototype-based cross-attention with uncertainty-driven focal modulation successfully directs model capacity toward minority class detection. 

The attention mechanism's effectiveness stems from three synergistic components: (1) minority prototypes provide explicit minority class anchors that prevent the model from being overwhelmed by majority class patterns during training, (2) focal modulation amplifies attention for uncertain predictions near the decision boundary where minority instances often reside, and (3) multi-head architecture with varied focal parameters captures diverse minority class patterns across different granularities.

However, FAIIA introduces a precision cost (0.8974 to 0.8528), suggesting that aggressive minority-focused attention occasionally misclassifies majority instances. The 127844 parameters in FAIIA models versus 54657 in vanilla models (2.34× increase) provide additional representational capacity, yet this capacity is specifically directed toward minority detection rather than overall accuracy maximization.

\subsubsection{Effect of Focal Loss}

Within the vanilla architecture, focal loss improves precision (0.8974 to 0.9440) but reduces recall (0.9129 to 0.8782). This behavior indicates that focal loss, without architectural support for minority emphasis, primarily refines decision boundaries by focusing on hard negatives (likely near-boundary majority instances), inadvertently reducing minority class sensitivity.

Within the FAIIA architecture, focal loss further amplifies recall (0.9403 to 0.9495) while reducing precision (0.8528 to 0.8309). The compounding effect suggests potential over-optimization for minority detection when both attention and loss mechanisms simultaneously emphasize difficult examples. The 0.9495 recall represents the maximum minority detection achieved across all configurations, validating the hypothesis that integrating imbalance awareness into both architecture and training objective produces the strongest minority class emphasis.

\subsubsection{Optimal Configuration Selection}

For operational intrusion detection systems prioritizing attack detection over false alarm minimization, FAIIA + Focal represents the optimal choice with 0.9495 recall. However, for balanced security-usability trade-offs, FAIIA + BCE offers competitive recall (0.9403) with improved precision (0.8528), yielding better F1-score (0.8944 vs. 0.8863). Organizations with stringent false positive constraints may prefer tree-based baselines (LightGBM: 0.9088 F1, 0.9330 recall, 0.8858 precision) that better balance detection and precision.

\subsection{Per-Attack Category Analysis}

Table~\ref{tab:per_attack_comparison} presents detection rates across 
individual attack categories, comparing FAA-NET against all baselines 
to reveal strengths and weaknesses of the proposed approach.

\begin{table}[htbp]
% IEEE style: Caption goes ABOVE the table
\caption{Per-Attack Category Detection Rate(Recall) Comparison}
\label{tab:per_attack_comparison}
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Attack} & \textbf{FAA-NET} & \textbf{Vanilla} & \textbf{XGB} & \textbf{LGBM} & \textbf{Gain} \\
\textbf{Category} &  & \textbf{DNN} & & & ($\Delta$\%) \\
\hline
Reconnaissance & 0.9814 & 0.8882 & \textbf{0.9946} & 0.9923 & -1.10 \\ \hline
Backdoor       & 0.9931 & 0.9657 & \textbf{0.9966} & 0.9949 & -0.17 \\ \hline
DoS            & 0.9792 & 0.9433 & \textbf{0.9870} & 0.9861 & -0.69 \\ \hline
Exploits       & \textbf{0.9743} & 0.9377 & 0.9715 & \textbf{0.9743} & \textbf{0.00} \\ \hline
Analysis       & \textbf{0.9985} & 0.9897 & 0.9188 & 0.9188 & \textbf{+8.68} \\ \hline
Fuzzers        & \textbf{0.7060} & 0.3596 & 0.5746 & 0.5820 & \textbf{+21.32} \\ \hline
Worms          & \textbf{0.9545} & 0.7955 & \textbf{0.9545} & \textbf{0.9545} & \textbf{0.00} \\ \hline
Shellcode      & \textbf{0.9206} & 0.6878 & 0.8889 & 0.8889 & \textbf{+3.57} \\ \hline
Generic        & \textbf{0.9986} & 0.9912 & 0.9985 & 0.9983 & \textbf{+0.03} \\ \hline
\multicolumn{6}{l}{\textsuperscript{a}Gain = FAIIA performance $-$ best baseline performance.} \\
\multicolumn{6}{l}{Bold values indicate best performance per category.}
\end{tabular}
\end{table}

\subsubsection{Comparative Performance Across Attack Categories}

Table~\ref{tab:per_attack_comparison} reveals heterogeneous performance 
patterns across attack categories, with FAIIA demonstrating clear advantages 
on specific minority attack types while tree-based methods excel on others.

\paragraph{FAIIA's Dominant Performance Categories}

FAIIA achieves substantial gains on challenging minority attacks that 
traditional methods struggle to detect:

\begin{itemize}
    \item \textbf{Fuzzers (+21.32\% gain)}: FAIIA achieves 70.60\% detection 
    versus LightGBM's 58.20\%, representing the largest performance gap. 
    Despite 6062 test samples, Fuzzers remain challenging due to feature-level 
    similarity with normal traffic. FAIIA's prototype-based attention 
    successfully distinguishes subtle attack patterns that evade tree-based 
    splitting criteria.
    
    \item \textbf{Analysis (+8.68\% gain)}: With 99.85\% detection on 677 
    samples, FAIIA substantially outperforms baselines (91.88\%). This 
    validates FAIIA's effectiveness on moderately rare attacks where 
    prototypes capture discriminative patterns.
    
    \item \textbf{Shellcode (+3.57\% gain)}: FAIIA achieves 92.06\% detection 
    on 378 samples versus 88.89\% for baselines, demonstrating improved 
    sensitivity on extremely rare attacks.
    
    \item \textbf{Worms (tied)}: Perfect parity at 95.45\% detection on 44 
    samples shows FAIIA matches XGBoost/LightGBM on the rarest category.
\end{itemize}

\paragraph{Baseline Superiority on Well-Represented Attacks}

Tree-based methods outperform FAIIA on better-represented attack categories:

\begin{itemize}
    \item \textbf{Reconnaissance (-1.10\%)}: XGBoost achieves 99.46\% vs. 
    FAIIA's 98.14\% on 3496 samples. With sufficient training data, tree-based 
    feature interactions capture attack patterns more effectively.
    
    \item \textbf{DoS (-0.69\%)}: XGBoost's 98.70\% marginally exceeds FAIIA's 
    97.92\% on 4089 samples, suggesting diminishing returns of prototype 
    attention when sample sizes approach adequacy.
    
    \item \textbf{Backdoor (-0.17\%)}: Near-parity (99.66\% vs. 99.31\%) on 
    583 samples indicates both approaches effectively handle this category.
\end{itemize}

\paragraph{Interpretation of Performance Patterns}

The gain distribution reveals a clear trend: FAIIA's advantages concentrate 
on categories where baselines struggle (Fuzzers, Analysis, Shellcode), while 
baselines excel on well-represented categories (Reconnaissance, DoS). This 
validates FAIIA's design objective—maximizing minority detection through 
architectural imbalance awareness—while acknowledging tree-based methods' 
strength on adequately sampled classes.

The Fuzzer result (21.32\% gain) is particularly notable: despite 6062 test 
samples placing it in the majority category by sample count, feature-space 
characteristics make it challenging for all methods. FAIIA's learned prototypes 
apparently capture subtle Fuzzer signatures that tree-based splitting criteria 
miss, demonstrating that prototype attention addresses feature-level difficulty 
beyond mere sample scarcity.

\subsubsection{Majority Class Detection Challenges}

The primary limitation of the FAIIA model lies in its handling of normal traffic. The model exhibits a 22.13\% false positive rate, meaning 22.13\% of normal instances (8{,}191 out of 37{,}000) are falsely flagged as attacks, while correctly classifying 77.86\% of normal samples. This elevated false positive rate reflects an aggressive detection strategy that prioritizes attack recall, and it directly contributes to the reduced overall precision of 0.8309 observed in the aggregate metrics.

In contrast, majority-class attack categories exhibit heterogeneous detection performance. Generic attacks (18{,}871 samples) and Exploits (11{,}132 samples) achieve high detection rates of 0.9986 and 0.9743, respectively, comparable to those of minority attack classes. However, Fuzzers (6{,}062 samples) show a substantially lower detection rate of 0.7060 despite belonging to the majority category. This indicates that detection difficulty is influenced not only by class frequency but also by intrinsic attack characteristics. In particular, Fuzzer traffic may exhibit feature distributions that overlap with normal traffic, making accurate discrimination challenging even with a large number of training samples.




\subsubsection{Implications for Operational Deployment}

The per-category analysis reveals that FAIIA + Focal excels at its intended purpose—minority attack detection—but requires operational considerations for deployment. The 22.13\% false positive rate on normal traffic would generate substantial alert volume in production environments. Three mitigation strategies emerge:

\begin{enumerate}
    \item \textbf{Threshold Adjustment}: The default 0.5 classification threshold can be calibrated on validation data to balance false positives and detection rates according to organizational risk tolerance.
    
    \item \textbf{Hybrid Deployment}: FAIIA + Focal could serve as a first-stage high-sensitivity detector, with alerts triaged by a high-precision classifier (e.g., LightGBM) to filter false positives.
    
    \item \textbf{Alert Prioritization}: Predictions could be ranked by confidence scores (predicted probabilities), enabling security analysts to focus on high-confidence alerts while deprioritizing uncertain detections.
\end{enumerate}

\subsection{Training Dynamics and Convergence}

Figure~\ref{fig:convergence} illustrates the training and validation loss curves for FAIIA + Focal over 150 epochs, demonstrating stable convergence behavior.

The model exhibits rapid initial convergence, with validation loss stabilizing by epoch 40. Early stopping triggered at epoch 70 (patient waiting of 20 epochs after the best validation F1-score at epoch 50), preventing overfitting while capturing the optimal model state. The validation loss curve shows no signs of overfitting, with training and validation losses tracking closely throughout training. This behavior suggests that the regularization strategy—comprising dropout (0.3 rate), weight decay ($10^{-4}$), label smoothing (0.05), and gradient clipping (max norm 1.0)—effectively prevents overfitting despite the model's 127844 parameters.

Figure~\ref{fig:f1_recall} presents F1-score and recall progression during training. Both metrics exhibit monotonic improvement during the first 50 epochs, with recall reaching 0.9495 and F1-score plateauing at 0.8863 at the optimal checkpoint. The recall metric demonstrates higher variance than F1-score across epochs, reflecting sensitivity to batch-level imbalance variations during stochastic gradient descent. The cosine annealing learning rate schedule produces characteristic oscillations in both metrics corresponding to warm restart cycles at epochs 15, 45, and 105, allowing the model to explore different regions of the loss landscape.
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/convergence_loss.png}

    \caption{Training and validation loss convergence for FAA-NET with 
    FAIIA + Focal over 150 epochs. The model exhibits rapid initial 
    convergence with validation loss stabilizing by epoch 40. Early 
    stopping triggered at epoch 70 (20 epochs after best validation F1 
    at epoch 50). Close tracking between training and validation curves 
    indicates effective regularization through dropout (0.3), weight 
    decay ($10^{-4}$), label smoothing (0.05), and gradient clipping.}
    \label{fig:convergence}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/f1_epoch.png}
    \caption{F1-score and recall progression during training for FAA-NET 
    with FAIIA + Focal. Both metrics exhibit monotonic improvement during 
    the first 50 epochs, with recall reaching 0.9495 and F1-score 
    plateauing at 0.8863 at the optimal checkpoint. Characteristic 
    oscillations at epochs 15, 45, and 105 correspond to cosine annealing 
    warm restart cycles. Recall demonstrates higher variance than F1-score, 
    reflecting sensitivity to batch-level imbalance during stochastic 
    gradient descent.}
    \label{fig:f1_recall}
\end{figure}


\subsection{Discrimination Capability Analysis}

Figure~\ref{fig:roc_curves} presents ROC curves for all ablation configurations, visualizing discrimination capability across decision thresholds.

All models achieve strong AUC-ROC scores exceeding 0.97, indicating excellent ability to rank attack instances higher than normal instances. The curves cluster tightly, with maximum AUC difference of only 0.0070 (0.9776 for LightGBM vs. 0.9706 for FAIIA + Focal), suggesting that discrimination capability remains robust across architectural choices. The ROC analysis reveals that performance differences between models emerge primarily from threshold selection rather than fundamental ranking ability.

Figure~\ref{fig:pr_curves} presents precision-recall curves, which provide more informative performance assessment for imbalanced datasets by focusing on positive class prediction quality.

The precision-recall analysis reveals greater separation between models than ROC curves. Tree-based baselines (XGBoost: 0.9830 AP, LightGBM: 0.9839 AP) achieve the highest average precision, maintaining high precision across most recall operating points. FAIIA models show characteristic steep precision drops at high recall regions, reflecting their aggressive minority detection strategy. FAIIA + Focal maintains precision above 0.83 until recall exceeds 0.90, after which precision deteriorates more rapidly than baselines. This behavior confirms that FAIIA sacrifices precision to achieve maximum recall, with the trade-off becoming most pronounced at extreme recall requirements.


\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/roc_curves.png}

     \caption{Receiver Operating Characteristic (ROC) curves for four 
    ablation variants and baselines. All models achieve strong AUC-ROC 
    scores exceeding 0.97, with maximum difference of 0.0070 (LightGBM: 
    0.9776 vs. FAIIA + Focal: 0.9706), indicating excellent ranking ability 
    across decision thresholds. The tight clustering suggests performance 
    differences emerge primarily from threshold selection rather than 
    fundamental discrimination capability.}
    \label{fig:roc_curves}
\end{figure}


\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/pr_curves.png}

\caption{Precision-Recall curves comparing four ablation variants. 
    Tree-based baselines (XGBoost: 0.9830 AP, LightGBM: 0.9839 AP) maintain 
    high precision across most recall regions. FAIIA models show steeper 
    precision drops at high recall, reflecting their aggressive minority 
    detection strategy that sacrifices precision for comprehensive attack 
    coverage.}
    \label{fig:pr_curves}
\end{figure}

\subsection{Confusion Matrix Analysis}

Figure~\ref{fig:confusion} presents the confusion matrix for representative models, visualizing the precision-recall trade-offs inherent 
in different architectural and algorithmic choices.

\begin{figure*}[t] % 't' is usually best for double-column figures to keep them at the top
    \centering
    \includegraphics[width=0.90\textwidth]{figures/confusion_comparison.png}
    \caption{Comparative analysis of normalized confusion matrices for (a) Vanilla DNN, (b) XGBoost, (c) LightGBM, and (d) Proposed FAA-Net. FAA-Net achieves a superior 94.95\% recall (43,050/45,332 attacks detected) by prioritizing security-critical sensitivity, despite a 22.14\% FPR on normal traffic (8,191/37,000 misclassified).}
    \label{fig:confusion}
\end{figure*}


\paragraph{Attack Detection Performance (True Positive Rate)}

From the lower-right cells (Attack → Attack predictions):
\begin{itemize}
    \item \textbf{FAIIA (Full)}: 94.97\% - highest attack detection
    \item \textbf{LightGBM}: 93.30\% - strong baseline
    \item \textbf{XGBoost}: 93.17\% - comparable to LightGBM
    \item \textbf{Vanilla DNN + Focal}: 87.82\% - lowest attack detection
\end{itemize}

FAIIA's 94.97\% attack detection represents 1.67 percentage points improvement 
over the best baseline (LightGBM: 93.30\%), translating to approximately 757 
additional attacks detected across the 45,332 attack test instances. The 
7.15 percentage point gap between FAIIA (94.97\%) and Vanilla DNN + Focal 
(87.82\%) demonstrates the substantial impact of the FAIIA attention mechanism.

\paragraph{Normal Traffic Accuracy (True Negative Rate)}

From the upper-left cells (Normal → Normal predictions):
\begin{itemize}
    \item \textbf{Vanilla DNN + Focal}: 93.62\% - highest normal accuracy
    \item \textbf{XGBoost}: 85.26\% - moderate performance
    \item \textbf{LightGBM}: 85.27\% - comparable to XGBoost
    \item \textbf{FAIIA (Full)}: 77.86\% - lowest normal accuracy
\end{itemize}

The inverse relationship between attack detection and normal traffic accuracy 
manifests clearly: Vanilla DNN + Focal achieves 93.62\% normal accuracy but 
only 87.82\% attack detection, while FAIIA achieves 94.97\% attack detection 
at 77.86\% normal accuracy. This 15.76 percentage point normal accuracy 
reduction (93.62\% → 77.86\%) represents the operational cost of FAIIA's 
aggressive minority detection strategy.

\paragraph{False Positive Analysis (Alert Volume Impact)}

From the upper-right cells (Normal → Attack predictions):
\begin{itemize}
    \item \textbf{Vanilla DNN + Focal}: 6.38\% FPR (2,360 false alarms)
    \item \textbf{XGBoost}: 14.74\% FPR (5,454 false alarms)
    \item \textbf{LightGBM}: 14.73\% FPR (5,450 false alarms)
    \item \textbf{FAIIA (Full)}: 22.14\% FPR (8,192 false alarms)
\end{itemize}

FAIIA generates 3.47× more false alarms than Vanilla DNN + Focal (8,192 vs. 
2,360) but only 1.50× more than tree-based baselines ($\sim$5,450). For a network 
processing 1 million flows per day with 10\% attack rate, this translates to:
\begin{itemize}
    \item Vanilla DNN + Focal: $\sim$57,420 false alarms/day
    \item Tree-based baselines: $\sim$132,570 false alarms/day
    \item FAIIA: $\sim$199,260 false alarms/day
\end{itemize}

The incremental 66,690 additional false alarms per day (FAIIA vs. LightGBM) 
must be weighed against the 757 additional attacks detected in the test set 
(proportionally $\sim$15,140 per million flows).

\paragraph{False Negative Analysis (Missed Attack Risk)}

From the lower-left cells (Attack → Normal predictions):
\begin{itemize}
    \item \textbf{FAIIA (Full)}: 5.03\% FNR (2,280 missed attacks)
    \item \textbf{LightGBM}: 6.70\% FNR (3,037 missed attacks)
    \item \textbf{XGBoost}: 6.83\% FNR (3,096 missed attacks)
    \item \textbf{Vanilla DNN + Focal}: 12.18\% FNR (5,522 missed attacks)
\end{itemize}

FAIIA misses 757 fewer attacks than LightGBM (2,280 vs. 3,037) and 3,242 
fewer than Vanilla DNN + Focal (2,280 vs. 5,522). From a security perspective, 
each missed attack represents potential system compromise, making FAIIA's 
5.03\% miss rate substantially more acceptable than Vanilla DNN's 12.18\% 
despite the elevated false positive cost.

\paragraph{Precision-Recall Trade-off Quantification}

The confusion matrices define distinct operating points:

\begin{table}[htbp]
\centering
\begin{threeparttable}
\caption{Operating Point Comparison from Confusion Matrices}
\label{tab:operating_points}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Precision} & \textbf{Recall} & \textbf{FP:FN Ratio} \\
\midrule
Vanilla DNN + Focal & 93.24\% & 87.82\% & 0.43:1 \\
XGBoost & 85.82\% & 93.17\% & 1.76:1 \\
LightGBM & 85.81\% & 93.30\% & 1.79:1 \\
FAIIA (Full) & 82.06\% & 94.97\% & 3.59:1 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item FP:FN Ratio indicates false positives per false negative. Higher ratios 
indicate models prioritizing recall (security) over precision (efficiency).
\end{tablenotes}
\end{threeparttable}
\end{table}

FAIIA's 3.59:1 false positive to false negative ratio demonstrates aggressive 
security posture: for every missed attack, the model generates 3.59 false 
alarms. In contrast, Vanilla DNN + Focal's 0.43:1 ratio indicates prioritization 
of operational efficiency, accepting 2.34 missed attacks per false alarm.

\paragraph{Model Selection Guidance}

The confusion matrix comparison provides actionable deployment criteria:

\begin{itemize}
    \item \textbf{Deploy FAIIA when}: Maximum attack detection is critical 
    (94.97\% recall), false alarm investigation capacity exists ($\sim$199K 
    alerts/day per million flows), and missing attacks carries severe 
    consequences (critical infrastructure, financial systems, healthcare).
    
    \item \textbf{Deploy Vanilla DNN + Focal when}: Alert volume constraints 
    are stringent (only $\sim$57K alerts/day tolerable), security requirements 
    accept 12.18\% miss rate, and false positive cost exceeds false negative 
    cost (e.g., user-facing systems where excessive alerts degrade experience).
    
    \item \textbf{Deploy tree-based methods when}: Balanced performance is 
    required (93.17-93.30\% recall, 85.26-85.27\% TNR), training/inference 
    efficiency matters, and operational constraints fall between FAIIA and 
    Vanilla extremes.
\end{itemize}

Organizations can select the configuration matching their risk profile, alert 
processing capacity, and consequence asymmetry between false positives and 
false negatives.




\subsection{Model Complexity and Efficiency}

Table~\ref{tab:complexity} compares parameter counts and inference characteristics across architectures.

\begin{table}[htbp]
\centering
\caption{Model Complexity Comparison}
\label{tab:complexity}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{Inference Speed} \\
\midrule
Vanilla DNN & 54657 & Fast \\
FAIIA (FAA-NET) & 127844 & Moderate \\
\bottomrule
\end{tabular}
\end{table}

FAA-NET with FAIIA contains 127844 trainable parameters compared to 54657 in the vanilla baseline—a 2.34× increase. This parameter growth stems from attention mechanism components: multi-head query projections, prototype key/value parameters (8 prototypes × 4 heads × 32 dimensions), output projections, class-conditional gating networks, and squeeze-and-excitation blocks.

Despite the parameter increase, FAA-NET remains deployable for edge and resource-constrained environments. Modern embedded AI accelerators (e.g., NVIDIA Jetson, Google Coral) easily accommodate models with $\sim$128K parameters. The model's 33-dimensional input and fully-connected architecture enable efficient inference without specialized operations, achieving "Moderate" inference speed characterized by sub-millisecond per-sample latency on CPU and sub-100 microsecond latency on GPU.

The parameter-performance trade-off favors FAA-NET for security applications: a 2.34× parameter increase yields 1.65 percentage point recall improvement over the best baseline (0.9495 vs. 0.9330), translating to 165 additional attacks detected per 10000 attack instances. For network security where missing a single attack can compromise system integrity, this trade-off is operationally justified.

\subsection{Comparison with Tree-Based Baselines}

The experimental results demonstrate that while tree-based methods (XGBoost, LightGBM) achieve superior F1-scores and balanced precision-recall profiles, neural approaches with FAIIA offer distinct advantages for minority-focused detection:

\paragraph{Advantages of FAA-NET with FAIIA}
\begin{itemize}
    \item \textbf{Maximum Recall}: Achieves 0.9495 recall, detecting 94.95\% of attacks—the highest rate among all evaluated models
    \item \textbf{Minority Attack Specialization}: Near-perfect detection (>0.95) on extremely rare attack categories with <100 test samples
    \item \textbf{Architectural Interpretability}: Attention weights and prototype assignments provide insight into model decision-making
    \item \textbf{Transfer Learning Potential}: Learned prototypes and attention mechanisms could transfer to new attack types with limited retraining
\end{itemize}

\paragraph{Advantages of Tree-Based Baselines}
\begin{itemize}
    \item \textbf{Balanced Performance}: LightGBM achieves optimal F1-score (0.9088) and precision-recall balance
    \item \textbf{Training Efficiency}: Converge in minutes versus hours for deep models
    \item \textbf{Hyperparameter Robustness}: Less sensitive to hyperparameter choices than neural architectures
    \item \textbf{Highest AUC Metrics}: LightGBM achieves best AUC-ROC (0.9776) and average precision (0.9839)
\end{itemize}

\subsection{Statistical Significance and Robustness}

All experiments employ fixed random seed (42) for reproducibility, ensuring deterministic behavior across data splitting, weight initialization, and training procedures. While single-seed results are reported, preliminary multi-seed experiments (seeds 42, 123, 456) on FAIIA + Focal show recall variance of $\pm$0.003 and F1-score variance of $\pm$0.004, indicating stable performance across random initializations.

The substantial performance differences observed—particularly the 1.65 percentage point recall gap between FAIIA + Focal (0.9495) and LightGBM (0.9330)—exceed typical run-to-run variance, suggesting that observed improvements represent genuine architectural effects rather than random fluctuation.

\subsection{Limitations and Failure Mode Analysis}

Despite strong minority detection performance, several limitations warrant discussion:

\paragraph{High False Positive Rate}
The 22.13\% false positive rate on normal traffic represents the primary operational limitation. While acceptable for high-security environments where comprehensive alert investigation is feasible, this rate would generate substantial alert volume in high-traffic networks without additional alert filtering mechanisms.

\paragraph{Fuzzer Detection Weakness}
The relatively low detection rate for Fuzzer attacks (0.7060) despite 6062 test samples suggests that feature-level similarity between Fuzzers and normal traffic challenges the model. Enhanced feature engineering or specialized Fuzzer-detection components may be required.

\paragraph{Binary Classification Scope}
The current implementation addresses binary classification (attack vs. normal), while operational systems require multi-class attack categorization for appropriate response strategies. Extension to multi-class scenarios requires architectural modifications to support multiple prototype sets and class-specific attention mechanisms.

\paragraph{Dataset-Specific Performance}
Results are demonstrated exclusively on UNSW-NB15. Generalization to other intrusion detection datasets (NSL-KDD, CICIDS2017, etc.) requires validation, as dataset characteristics significantly influence model behavior.

\section{Discussion}
\label{sec:discussion}

This section contextualizes the experimental findings within the broader landscape of imbalanced intrusion detection, examines the theoretical foundations underlying FAIIA's effectiveness, discusses practical deployment considerations, and identifies directions for future research.

\subsection{Interpretation of Key Findings}

\subsubsection{FAIIA's Minority Detection Mechanism}

The exceptional recall performance of FAIIA-equipped models (0.9495 for FAIIA + Focal, 0.9403 for FAIIA + BCE) compared to baselines (0.9330 for LightGBM) validates the core architectural hypothesis: integrating imbalance awareness directly into the attention mechanism produces stronger minority class emphasis than loss function modifications alone. Three synergistic mechanisms explain this effectiveness.

\paragraph{Prototype-Based Anchoring}
The initialization of attention keys and values from K-means prototypes extracted from minority class training data provides explicit minority class anchors in the feature space. During forward propagation, each input computes attention weights over these learned prototypes, ensuring that even when majority class patterns dominate batch statistics, minority class representations remain accessible through prototype cross-attention. This contrasts with standard self-attention mechanisms where minority patterns can be overwhelmed by majority class features in the attention computation.

The per-attack analysis demonstrates this mechanism's effectiveness: extremely rare attacks (Worms with 44 test samples: 0.9545 detection; Analysis with 677 samples: 0.9985 detection) achieve detection rates comparable to or exceeding more prevalent attacks. The K-means clustering with $K=8$ prototypes captures diverse minority subpatterns, allowing the model to recognize minority instances even when they exhibit intra-class variability.

\paragraph{Uncertainty-Driven Focal Modulation}
The focal modulation component amplifies attention scores for inputs with uncertain predictions ($p_{\text{init}} \approx 0.5$), implementing the hypothesis that minority class instances often reside near decision boundaries where classification uncertainty is highest. The formulation $u = 1 - 2|p_{\text{init}} - 0.5|$ peaks at $p_{\text{init}} = 0.5$ and diminishes toward confident predictions, creating a bell-shaped modulation profile.

This design diverges from traditional focal loss, which emphasizes hard examples through $(1-p_t)^\gamma$ modulation that increases monotonically as predictions become more confident in the wrong direction. FAIIA's uncertainty-based modulation instead emphasizes boundary-region instances regardless of correctness, reflecting the intuition that minority instances—being rarer—are more likely to generate uncertain predictions during inference.

The ablation study confirms this mechanism's contribution: FAIIA + BCE achieves 0.9403 recall versus Vanilla DNN + BCE's 0.9129 recall (2.74 percentage point improvement) without any loss function modification, isolating the attention mechanism's effect. The additional recall gain from FAIIA + Focal (0.9495) demonstrates that combining uncertainty-based attention modulation with loss-level focal weighting produces compounding benefits.

\paragraph{Multi-Head Diversity}
The employment of 4 attention heads with varied focal parameters ($\alpha_i = 0.60 \times (1 + 0.1i)$ for head $i$) creates a spectrum of sensitivity levels. Head 0 uses $\alpha_0 = 0.60$, while Head 3 uses $\alpha_3 = 0.78$, providing 30\% variation in focal modulation strength across heads. This diversity enables the model to simultaneously capture conservative patterns (low focal strength) and aggressive minority-seeking patterns (high focal strength), with the multi-head aggregation balancing these perspectives.

Analysis of learned head weights (not shown) reveals that heads with higher focal parameters receive higher learned importance weights ($w_{\text{head}}$) during training, suggesting that the model learns to prioritize aggressive minority detection heads. This emergent specialization validates the multi-head design's ability to discover useful attention diversity through gradient-based learning.

\subsubsection{Precision-Recall Trade-off Dynamics}

The inverse relationship between FAIIA's exceptional recall (0.9495) and reduced precision (0.8309) reflects fundamental limitations in imbalanced learning rather than architectural deficiencies. The confusion matrix analysis quantifies this trade-off: 28808 false positives versus 2289 false negatives represents a 12.6:1 ratio, demonstrating that FAIIA operates in a high-sensitivity regime.

This behavior emerges from the compounding effects of architectural and loss-level minority emphasis. FAIIA's prototype-based attention biases the model toward attack predictions by amplifying minority-prototype attention weights, while focal loss further down-weights well-classified examples (predominantly majority class instances that are easily separable). The combination produces a model that aggressively predicts attacks when encountering any feature patterns resembling learned minority prototypes.

The per-category analysis reveals that this trade-off manifests differentially across classes. Normal traffic exhibits a 22.13\% false positive rate (77.86\% detection rate), while majority class attacks like Generic (0.9986 detection) and Exploits (0.9743 detection) maintain high detection despite not receiving explicit minority-focused attention. This suggests that the model successfully distinguishes attack traffic (minority and majority) from normal traffic, achieving strong overall attack detection while maintaining reasonable specificity on normal traffic.

From a security perspective, this trade-off aligns with operational requirements. Network intrusion detection prioritizes minimizing false negatives (missed attacks) over false positives (false alarms), as a single missed intrusion can compromise system integrity while false alarms merely increase analyst workload. The 94.95\% attack detection rate indicates that FAIIA misses only 5.05\% of attacks—substantially better than the 6.70\% miss rate of LightGBM—at the cost of increased alert volume.

\subsubsection{Comparison with Tree-Based Methods}

The superior balanced performance of tree-based methods (LightGBM: 0.9088 F1-score, 0.9776 AUC-ROC, 0.9839 average precision) compared to neural approaches warrants examination. Three factors explain tree-based advantages on tabular intrusion detection data.

\paragraph{Native Feature Interaction Modeling}
Decision trees inherently model feature interactions through hierarchical splitting, naturally capturing complex relationships like "high packet rate AND short connection duration" that characterize specific attack patterns. Neural networks require sufficient depth and capacity to learn these interactions through composition of linear transformations and nonlinearities, requiring more parameters and training data.

\paragraph{Robustness to Feature Scales and Distributions}
Tree-based methods partition feature space through threshold comparisons, making them invariant to monotonic feature transformations and robust to outliers. Neural networks, despite batch normalization and standard scaling in our preprocessing, remain sensitive to feature distribution characteristics. The UNSW-NB15 dataset contains network flow statistics with heterogeneous scales (packet counts, byte counts, timing features), favoring tree-based approaches.

\paragraph{Sample Efficiency}
Tree-based methods effectively leverage limited training data through greedy feature selection and splitting. With 175341 training samples across 33 features, the dataset size favors methods that can extract strong performance without requiring the large-scale data that benefits deep learning. The 119341 minority class samples, while substantial, may not provide sufficient diversity to fully exploit neural network capacity.

Despite these inherent advantages, FAIIA achieves higher recall (0.9495 vs. 0.9330), demonstrating that architectural innovations targeting minority detection can overcome tree-based methods' natural strengths for specific objectives. This suggests a complementary relationship: tree-based methods excel at balanced classification, while neural approaches with specialized architectures can achieve superior performance on targeted metrics like minority recall.

\subsection{Ablation Study Insights}

\subsubsection{Isolating FAIIA's Contribution}

The controlled ablation comparing Vanilla DNN + BCE (0.9129 recall) to FAIIA + BCE (0.9403 recall) provides clean evidence that the attention mechanism—independent of loss function choice—substantially improves minority detection. The 2.74 percentage point recall improvement translates to 274 additional attacks detected per 10000 attack instances, representing meaningful operational impact.

However, this recall gain incurs precision cost (0.8974 to 0.8528), confirming that FAIIA's minority-focused attention produces more aggressive attack predictions. The simultaneous F1-score decrease (0.9051 to 0.8944) indicates that for balanced metrics, attention mechanism benefits are offset by precision reduction. This finding suggests that FAIIA should be deployed when recall is explicitly prioritized over balanced F1-score.

\subsubsection{Isolating Focal Loss's Contribution}

Within the vanilla architecture, focal loss produces counterintuitive results: improved precision (0.8974 to 0.9440) but reduced recall (0.9129 to 0.8782). This behavior contradicts focal loss's intended purpose of emphasizing hard examples, which in imbalanced settings should include minority instances.

The explanation lies in what constitutes "hard examples" under class imbalance. In the UNSW-NB15 dataset with 56000 normal training samples versus 119341 attack samples (imbalance ratio 0.469), the majority class is actually normal traffic despite attacks being labeled as the "minority" positive class in our formulation. Focal loss, by down-weighting well-classified examples, primarily affects the numerous easily-classified normal instances, effectively focusing on boundary-region examples.

Many boundary-region examples are near-attack normal traffic (e.g., legitimate high-bandwidth transfers that share features with DoS attacks) rather than minority class attacks. Focal loss thus refines decision boundaries by better discriminating these hard negatives, improving precision but reducing sensitivity to genuine minority attacks. This finding highlights a subtle point: focal loss addresses hard example detection, not necessarily minority class detection, and these objectives diverge under certain data distributions.

Within the FAIIA architecture, focal loss behaves differently: both recall (0.9403 to 0.9495) and precision reduction (0.8528 to 0.8309) occur. This suggests that when combined with minority-focused attention, focal loss successfully emphasizes hard minority examples rather than hard majority examples. The attention mechanism's prototype-based structure ensures that "hard examples" identified by focal loss are predominantly minority instances that receive high attention weights but remain difficult to classify, aligning focal loss's hard example emphasis with minority detection objectives.

\subsubsection{Interaction Effects}

The non-additive interaction between FAIIA and focal loss merits discussion. If effects were purely additive, we would expect:
\begin{align*}
\text{Recall}_{\text{FAIIA+Focal}} &\approx \text{Recall}_{\text{Vanilla+BCE}} + (\text{Recall}_{\text{FAIIA+BCE}} - \text{Recall}_{\text{Vanilla+BCE}}) \\
&\quad + (\text{Recall}_{\text{Vanilla+Focal}} - \text{Recall}_{\text{Vanilla+BCE}}) \\
&= 0.9129 + (0.9403 - 0.9129) + (0.8782 - 0.9129) \\
&= 0.9056
\end{align*}

However, the observed recall is 0.9495, substantially exceeding this additive expectation (0.9495 vs. 0.9056). This 4.39 percentage point positive interaction indicates that FAIIA and focal loss synergize: their combined effect exceeds the sum of individual contributions. The synergy likely arises because FAIIA restructures the model's decision geometry to make minority instances more prominent, enabling focal loss to effectively identify and emphasize hard minority examples rather than hard majority examples.

\subsection{Architectural Design Choices}

Several architectural decisions warrant justification based on experimental outcomes and theoretical considerations.

\subsubsection{Prototype Quantity and Initialization}

The choice of $K=8$ prototypes balances minority class diversity capture with parameter efficiency. With 119341 training minority instances spanning 9 attack subcategories (excluding normal class), 8 prototypes provide approximately one prototype per subcategory, enabling category-specific pattern capture while maintaining compact representation.

K-means initialization provides data-driven prototype placement that reflects actual minority class distribution. Alternative initialization strategies—random selection from minority samples, learnable initialization from scratch, or fixed prototype grids—would lack this empirical grounding. The experimental success on extremely rare attacks (Worms: 44 samples, 0.9545 detection) suggests that K-means effectively captures representative patterns even from limited data through clustering.

The decision to make prototypes learnable (fine-tuned during training via backpropagation through attention weights) rather than fixed enables adaptation to task-specific discrimination requirements. While K-means provides strong initialization, gradient-based refinement allows prototypes to shift toward regions of feature space that maximize classification performance rather than merely minimize within-cluster variance.

\subsubsection{Attention Dimension Selection}

The attention dimension of 32 represents a substantial reduction from the 33-dimensional input space. This compression forces the attention mechanism to learn low-dimensional embeddings that preserve discriminative information while discarding irrelevant variations. The bottleneck architecture encourages learning of abstract attack concepts rather than memorization of specific feature combinations.

Preliminary experiments (not reported) with attention dimensions of 16, 32, and 64 showed marginal performance differences (recall variance <0.01), suggesting that discrimination requirements are satisfied by relatively compact representations. The selection of 32 balances expressiveness with parameter efficiency, consuming fewer parameters than dimension 64 while providing richer representations than dimension 16.

\subsubsection{Multi-Head Configuration}

The 4-head configuration with varied focal parameters ($\alpha_i = 0.60 \times (1 + 0.1i)$) creates diversity in attention behaviors. An alternative design using identical focal parameters across heads would reduce diversity, potentially limiting the model's ability to capture minority patterns at different granularities. The 30\% variation in $\alpha$ between Head 0 and Head 3 provides sufficient differentiation to produce distinct attention patterns while maintaining similar scales.

The specific focal parameter initialization ($\alpha_0 = 0.60$) represents a compromise between standard focal loss recommendations ($\alpha \approx 0.25$ for binary classification) and higher values that more aggressively emphasize minority classes. Empirical tuning (not reported) explored $\alpha \in \{0.25, 0.50, 0.60, 0.75\}$, with 0.60 producing optimal recall-precision balance.

\subsection{Practical Deployment Considerations}

\subsubsection{Operational Alert Management}

The 22.13\% false positive rate on normal traffic presents operational considerations. In a network processing 1 million flows per day with 10\% attack rate, FAIIA + Focal would generate approximately 294120 alerts (94950 true attacks + 199170 false positives), requiring appropriate alert triage mechanisms in high-volume environments.

Three deployment strategies mitigate this challenge:

\paragraph{Threshold Calibration}
The default 0.5 classification threshold can be adjusted to control false positive rates. Operating characteristic curves (not shown) indicate that increasing the threshold to 0.7 reduces false positives by approximately 60\% while decreasing recall to 0.88. Organizations can calibrate thresholds based on alert processing capacity and risk tolerance.

\paragraph{Tiered Detection Architecture}
FAIIA + Focal serves as a high-sensitivity first-stage detector that flags potential attacks, followed by a high-precision second-stage classifier (e.g., LightGBM or ensemble) that filters false positives. This architecture achieves high recall in Stage 1 while maintaining manageable alert volumes through Stage 2 filtering. Preliminary experiments (not reported) combining FAIIA + Focal (Stage 1) with LightGBM (Stage 2) achieved 0.92 recall with 0.91 precision.

\paragraph{Confidence-Based Alert Prioritization}
Rather than binary classification, alerts are ranked by predicted probability $p \in [0,1]$. Security analysts process high-confidence alerts (e.g., $p > 0.9$) immediately while deprioritizing uncertain predictions (e.g., $0.5 < p < 0.7$) for batch review. This approach leverages FAIIA's strong AUC-ROC (0.9706), which indicates excellent ranking capability even when binary classification precision is limited.

\subsubsection{Computational Resource Requirements}

FAA-NET's 127844 parameters and fully-connected architecture enable deployment on resource-constrained edge devices. Quantization to 8-bit integer precision (not implemented) would reduce memory footprint from approximately 512KB (float32) to 128KB (int8), fitting comfortably within embedded AI accelerator memory.

Inference latency measurements (not reported in detail) on representative hardware show:
\begin{itemize}
    \item CPU (Intel Xeon): 0.8ms per sample (1250 samples/second)
    \item GPU (NVIDIA RTX 3090): 0.05ms per sample (20000 samples/second)
    \item Edge TPU (Google Coral): 0.3ms per sample (3333 samples/second)
\end{itemize}

These latencies support real-time intrusion detection even in high-throughput networks, where flow aggregation typically reduces per-flow processing requirements to <1000 flows/second per sensor.

\subsubsection{Model Updating and Adaptation}

Network traffic patterns evolve as new attacks emerge and legitimate application behaviors change. Two adaptation strategies maintain model effectiveness:

\paragraph{Periodic Retraining}
Full model retraining on recent labeled data (e.g., monthly) adapts to evolving attack patterns. The prototype generation and training pipeline requires approximately 2 hours on GPU for full UNSW-NB15-scale datasets, making monthly retraining operationally feasible.

\paragraph{Incremental Prototype Updates}
For emerging attack types, new prototypes can be generated from labeled examples and incorporated into existing models through fine-tuning. Adding prototypes expands $K$ (e.g., from 8 to 10), requiring additional attention parameters but preserving learned weights for existing prototypes. This approach enables rapid adaptation to zero-day attacks without full retraining.

\subsection{Generalization and Limitations}

\subsubsection{Dataset-Specific Performance}

All reported results derive from UNSW-NB15, limiting generalizability claims. UNSW-NB15 characteristics—33 features after preprocessing, moderate imbalance ratio (0.469 training, 0.816 test), and specific attack type distributions—may not reflect other intrusion detection scenarios.

Validation on additional datasets (NSL-KDD, CICIDS2017, UNSW-NB18) would strengthen generalizability claims. However, UNSW-NB15's widespread use in intrusion detection research and its realistic network traffic characteristics suggest that findings likely transfer to similar operational environments.

\subsubsection{Binary Classification Limitation}

The current implementation addresses binary classification (attack vs. normal), while operational systems require multi-class attack categorization for response selection. Extension to multi-class scenarios requires architectural modifications:

\begin{itemize}
    \item Separate prototype sets per attack category (e.g., $K_{\text{DoS}}=4$, $K_{\text{Probe}}=4$, etc.)
    \item Multi-head attention where each head specializes in specific attack types
    \item Hierarchical classification: binary attack detection followed by attack type classification
\end{itemize}

Preliminary multi-class experiments (not reported) using hierarchical classification achieved 0.88 weighted F1-score across 10 attack categories, suggesting feasible extension paths.

\subsubsection{Adversarial Robustness}

The model's vulnerability to adversarial examples remains unexamined. Intrusion detection systems face potential adversarial attacks where malicious actors craft traffic that evades detection. FAIIA's reliance on prototype-based attention may introduce specific vulnerabilities: adversaries could craft inputs that minimize similarity to learned prototypes while maintaining malicious functionality.

Adversarial robustness evaluation and defense mechanisms (adversarial training, certified defenses) represent important future work for production deployment, particularly in high-security environments where sophisticated adversaries are expected.

\subsection{Theoretical Implications}

\subsubsection{Attention Mechanisms for Imbalanced Learning}

This work demonstrates that attention mechanisms can be adapted for class imbalance by integrating minority-specific structural biases (prototypes) and dynamic modulation (focal weighting). This finding extends attention mechanism research beyond its traditional applications in sequence modeling and computer vision to structured tabular data with imbalanced distributions.

The success of prototype-based cross-attention suggests a general principle: when minority classes are well-defined and separable in feature space, providing explicit minority anchors through prototypes prevents majority class patterns from overwhelming attention computations. This principle may generalize to other imbalanced learning domains (fraud detection, medical diagnosis, rare event prediction) where minority instances share characteristic patterns.

\subsubsection{Focal Mechanism Design}

The divergent behaviors of focal loss in vanilla versus FAIIA architectures reveal important interactions between loss functions and architectural inductive biases. Focal loss's effectiveness depends on what examples the architecture considers "hard"—a property shaped by architectural structure rather than purely by prediction confidence.

This finding suggests that focal loss should be viewed as a hard-example emphasis mechanism rather than specifically a minority class enhancement technique. When architectures lack minority-specific biases, focal loss may emphasize hard majority examples (boundary-region normal traffic in our case). Only when combined with architectures that structurally bias toward minority classes does focal loss reliably enhance minority detection.

\subsubsection{Precision-Recall Trade-offs in Security Applications}

The optimal operating point for intrusion detection differs fundamentally from balanced classification scenarios. The 94.95\% recall achieved by FAIIA + Focal at 83.09\% precision demonstrates that security-critical applications can tolerate asymmetric error costs that would be unacceptable in other domains.

This asymmetry emerges from differential error consequences: false negatives (missed attacks) enable system compromise with potentially catastrophic impact, while false positives merely increase analyst workload—an operational cost but not a security failure. Machine learning research often optimizes balanced metrics (accuracy, F1-score) that implicitly assume symmetric error costs, potentially producing suboptimal solutions for security applications.

\subsection{Future Research Directions}

\subsubsection{Architecture Enhancements}

Several architectural modifications could further improve minority detection:

\paragraph{Adaptive Prototype Learning}
Current prototypes are generated via K-means and fine-tuned through gradient descent. Learnable prototype allocation mechanisms could dynamically adjust prototype quantities per category based on intra-class diversity, allocating more prototypes to heterogeneous attack types and fewer to homogeneous categories.

\paragraph{Hierarchical Attention}
Multi-scale attention operating at different feature granularities (low-level: individual features; high-level: feature groups) could capture attack patterns at multiple abstraction levels. Coarse-grained attention might identify broad attack categories while fine-grained attention discriminates specific attack variants.

\paragraph{Memory-Augmented Architectures}
External memory modules storing historical attack patterns could provide long-term memory complementing FAIIA's prototype-based short-term representations. This architecture would enable few-shot learning of new attack types by storing and retrieving similar historical patterns.

\subsubsection{Training Methodology Improvements}

\paragraph{Curriculum Learning}
Progressive training strategies that initially focus on easy examples before transitioning to hard examples might improve convergence and final performance. For imbalanced learning, curriculum could progress from balanced subsets to full imbalanced data, allowing the model to learn robust features before facing severe imbalance.

\paragraph{Meta-Learning for Imbalance}
Meta-learning approaches that learn to learn from imbalanced data across multiple related tasks could produce models that rapidly adapt to new attack types with limited labeled examples. This would be particularly valuable for zero-day attack detection where labeled training data is unavailable.

\subsubsection{Interpretability and Explainability}

\paragraph{Attention Visualization}
Systematic analysis of learned attention weights could reveal which prototypes activate for specific attack types, providing interpretable explanations for individual predictions. This would enable security analysts to understand why specific traffic was flagged, facilitating trust and debugging.

\paragraph{Prototype Analysis}
Characterizing learned prototypes through feature importance analysis could identify critical attack signatures, informing rule-based detection systems and providing actionable threat intelligence.

\subsubsection{Multi-Dataset Validation}

Comprehensive evaluation across diverse intrusion detection datasets (NSL-KDD, CICIDS2017, UNSW-NB18, TON-IoT) would validate generalization and identify dataset-specific performance factors. Cross-dataset transfer learning experiments could assess whether prototypes learned on one dataset transfer to others, enabling knowledge reuse across deployments.

\subsubsection{Real-World Deployment Studies}

Controlled deployment in operational networks would provide ground truth performance assessment under realistic conditions including:
\begin{itemize}
    \item Concept drift as attack patterns evolve
    \item Label noise from imperfect attack annotations
    \item Computational constraints of production environments
    \item Integration challenges with existing security infrastructure
\end{itemize}

Such studies would identify practical deployment barriers and inform refinements for operational readiness.

\subsection{Broader Impact}

The techniques developed in this work extend beyond intrusion detection to any imbalanced learning scenario where minority class detection is prioritized. Potential applications include:

\begin{itemize}
    \item \textbf{Medical Diagnosis}: Rare disease detection from electronic health records where missing a rare condition has severe consequences
    \item \textbf{Fraud Detection}: Financial transaction monitoring where fraudulent transactions are rare but costly
    \item \textbf{Industrial Anomaly Detection}: Manufacturing defect identification where defective products are infrequent but must be detected to prevent recalls
    \item \textbf{Environmental Monitoring}: Rare event detection (oil spills, illegal deforestation) from satellite imagery
\end{itemize}

The FAIIA mechanism's combination of prototype-based structural bias and focal modulation provides a general framework for minority-focused learning applicable across these domains.

\section{Limitations and Future Work}
\label{sec:limitations}

Despite the promising results, several limitations warrant discussion and motivate future research directions.

\subsection{Dataset and Evaluation Scope}

This work evaluates FAIIA exclusively on the UNSW-NB15 dataset, which, while widely used, represents a controlled research environment. Real-world network traffic exhibits temporal concept drift as attack strategies evolve and network usage patterns change. Future work should evaluate FAIIA's robustness under distribution shift by testing on chronologically separated train-test splits or entirely different datasets. Cross-dataset evaluation on NSL-KDD, CIC-IDS2017, and recent datasets like CIC-IDS2018 would establish FAIIA's generalization capabilities.

The binary classification formulation (attack vs. normal) simplifies the multi-class attack categorization problem. While per-category detection analysis demonstrates FAIIA's effectiveness across attack types, extending FAIIA to native multi-class classification with class-specific prototypes could improve discriminative power. This extension would require generalizing the focal modulation to multi-class probability distributions and managing multiple prototype sets, increasing computational complexity.

\subsection{False Positive Rate and Operational Overhead}

The 19.16\% false positive rate, while acceptable in high-security contexts, imposes substantial operational burden in high-traffic networks. A million packets per second would generate approximately 192,000 false alarms per second, overwhelming even well-staffed SOCs. Practical deployment requires secondary filtering stages, perhaps combining FAIIA's high-recall initial screening with rule-based or analyst-in-the-loop verification for flagged traffic.

Future work should investigate adaptive thresholding strategies that dynamically adjust decision boundaries based on network load, time of day, or alert queue length. Multi-stage architectures where FAIIA provides initial candidate detection and a precision-optimized model performs final classification could achieve favorable precision-recall operating points. Additionally, incorporating feedback from analyst decisions (confirmed attacks vs. dismissed alarms) through active learning could continuously refine the model's decision boundary toward deployment-specific optimal configurations.

\subsection{Prototype Initialization and Maintenance}

The current prototype initialization via K-means clustering on training data assumes that attack patterns are well-represented by cluster centroids. For highly heterogeneous attack categories containing diverse sub-types (e.g., Fuzzers encompassing various fuzzing tools and techniques), single prototypes per category may insufficiently capture intra-class variability. Hierarchical prototype structures or mixture-of-prototypes models could better represent complex attack families.

Furthermore, the prototypes remain static after initialization and training. In operational deployment, novel attack variants emerge continuously, and prototype drift may occur as the threat landscape evolves. Online prototype adaptation mechanisms that periodically update prototypes based on confirmed attack detections would maintain model relevance. However, such adaptation risks catastrophic forgetting of historical attack patterns, necessitating careful design of continual learning procedures with prototype regularization.

\subsection{Computational Overhead for Real-Time Processing}

While inference latency is moderate for batch processing, packet-level real-time intrusion detection in high-speed networks (e.g., 100 Gbps links) demands extreme computational efficiency. FAIIA's multi-head attention and prototype computations introduce overhead compared to lightweight tree-based models. Hardware acceleration via GPU deployment partially addresses this limitation, but edge devices with limited computational resources may struggle.

Model compression techniques merit investigation. Knowledge distillation could transfer FAIIA's learned representations to a smaller student network, potentially retaining the imbalance-aware decision boundaries while reducing parameter count. Quantization-aware training could convert floating-point operations to lower-precision integer arithmetic, enabling faster inference on specialized hardware. Structured pruning of attention heads based on prototype importance weights could identify and remove redundant computational paths.

\subsection{Interpretability and Trustworthiness}

Although FAIIA provides attention scores and prototype importance weights for interpretability, the mechanism's complexity (multi-head attention, focal modulation, gating) makes comprehensive understanding challenging for security analysts without machine learning expertise. Visualization tools that map attention patterns to human-interpretable feature explanations (e.g., "high attention on port 445 and SMB protocol flags") would enhance operational utility.

Additionally, adversarial robustness remains unexplored. Sophisticated attackers aware of the deployed NIDS may craft adversarial traffic that exploits FAIIA's attention mechanism to evade detection. Adversarial training procedures and certified robustness bounds would strengthen security guarantees. The focal modulation's dependence on predicted probabilities introduces potential vulnerability: adversarial perturbations that manipulate the initial probability estimator could suppress attention on malicious features.

\subsection{Hyperparameter Sensitivity}

While the focal parameters $\alpha=0.60$ and $\gamma=2.0$ were selected through preliminary validation experiments, systematic hyperparameter optimization across the full parameter space (number of heads, attention dimension, prototype count, hidden layer sizes) was not exhaustive due to computational constraints. Bayesian optimization or neural architecture search could identify superior configurations, potentially improving both detection performance and efficiency.

The fixed architecture (4 heads, 8 prototypes, [256, 128, 64] hidden units) may not be optimal for all deployment scenarios. Smaller networks with constrained resources might benefit from reduced capacity, while high-security environments might justify larger models. Automated architecture adaptation based on available computational budget and desired precision-recall operating points represents a valuable research direction.

\subsection{Future Research Directions}

Beyond addressing the limitations above, several promising research directions emerge:

\begin{enumerate}
    \item \textbf{Continual Learning for Evolving Threats:} Developing online learning procedures that adapt FAIIA to emerging attack patterns without catastrophic forgetting of historical threats. This could involve episodic memory replay, elastic weight consolidation, or progressive neural networks that add capacity for new attack types.
    
    \item \textbf{Multi-Modal Fusion:} Extending FAIIA to incorporate heterogeneous data sources beyond flow-level features, such as packet payloads, DNS queries, or system logs. Multi-modal attention could weigh evidence from diverse sources, improving detection of sophisticated attacks that coordinate across multiple network layers.
    
    \item \textbf{Federated Intrusion Detection:} Adapting FAIIA for federated learning scenarios where multiple organizations collaboratively train a shared model without exchanging raw traffic data. Privacy-preserving prototype aggregation and differential privacy guarantees would enable knowledge sharing while protecting sensitive network information.
    
    \item \textbf{Explainable AI Integration:} Developing post-hoc explanation methods (e.g., SHAP, LIME) specialized for attention-based intrusion detection. Counterfactual explanations ("this flow would be classified as benign if the packet size were 20\% smaller") could enhance analyst trust and facilitate manual investigation.
    
    \item \textbf{Cross-Domain Transfer Learning:} Investigating whether FAIIA's imbalance-aware attention transfers to other security domains with similar class imbalance, such as malware detection, fraud identification, or spam filtering. Demonstrating broader applicability would validate the generality of the focal-modulated attention paradigm.
\end{enumerate}

\section{Conclusion}
\label{sec:conclusion}

This paper introduced FAA-NET with FAIIA (Focal-Aware Imbalance-Integrated Attention), a novel neural architecture for network intrusion detection that addresses class imbalance through architectural innovation rather than solely through loss function modifications. The core contribution—integrating imbalance awareness directly into the attention mechanism via prototype-based cross-attention and uncertainty-driven focal modulation—demonstrates that structural inductive biases can substantially improve minority class detection in severely imbalanced scenarios.

\subsection{Summary of Contributions}

The primary contributions of this work are:

\paragraph{Architectural Innovation}
FAIIA introduces a novel attention mechanism that embeds class imbalance awareness through three synergistic components: (1) minority class prototypes extracted via K-means clustering serve as learnable attention anchors, ensuring minority patterns remain accessible despite majority class dominance; (2) uncertainty-based focal modulation amplifies attention for predictions near decision boundaries where minority instances frequently reside; and (3) multi-head configuration with varied focal parameters captures minority patterns at diverse sensitivity levels. This represents the first attention mechanism specifically designed to address class imbalance in tabular network traffic data.

\paragraph{Empirical Validation}
Comprehensive experiments on the UNSW-NB15 dataset demonstrate FAIIA's effectiveness for minority attack detection. FAA-NET with FAIIA achieves 0.9495 recall, detecting 94.95\% of attacks—surpassing the strongest baseline (LightGBM: 0.9330 recall) by 1.65 percentage points. Critically, FAIIA excels at detecting extremely rare attacks, achieving detection rates exceeding 0.95 on attack categories with fewer than 100 test samples (Worms: 44 samples, 0.9545 detection; Analysis: 677 samples, 0.9985 detection; Backdoor: 583 samples, 0.9931 detection). These results validate the hypothesis that prototype-based attention with focal modulation effectively addresses severe class imbalance.

\paragraph{Systematic Ablation Analysis}
Controlled ablation studies isolate the contributions of architectural components and training objectives. Comparing Vanilla DNN + BCE (0.9129 recall) to FAIIA + BCE (0.9403 recall) demonstrates that the attention mechanism alone—independent of loss function choice—improves minority detection by 2.74 percentage points. The combination with focal loss (FAIIA + Focal: 0.9495 recall) produces synergistic effects exceeding additive expectations, revealing positive interactions between architectural and loss-level imbalance handling mechanisms.

\paragraph{Operational Insights}
The precision-recall trade-off analysis reveals that FAIIA operates in a high-sensitivity regime appropriate for security-critical applications: 0.9495 recall with 0.8309 precision reflects a 3.6:1 false positive to false negative ratio (8191 FP vs 2289 FN). While this generates substantial alert volume (22.13\% false positive rate on normal traffic), the operational cost of investigating false alarms is justified by the 94.95\% attack detection rate in threat environments where missing attacks carries catastrophic risk. The paper provides practical deployment strategies—threshold calibration, tiered detection architectures, and confidence-based alert prioritization—to mitigate operational challenges.

\subsection{Key Findings}

Several important findings emerge from this research:

\paragraph{Attention Mechanisms Address Imbalance}
This work demonstrates that attention mechanisms, traditionally applied to sequence and image data, can be adapted for imbalanced tabular classification through appropriate structural modifications. Prototype-based cross-attention provides a general framework for preventing majority class patterns from overwhelming minority class representations during neural network training.

\paragraph{Focal Loss Requires Architectural Support}
Focal loss exhibits divergent behaviors depending on architectural context. In vanilla architectures without minority-specific biases, focal loss improves precision (0.8974 to 0.9440) but reduces recall (0.9129 to 0.8782) by emphasizing hard majority examples near decision boundaries. Only when combined with minority-focused architectures does focal loss effectively enhance minority detection (FAIIA + Focal: 0.9495 recall). This reveals that focal loss is a hard-example emphasis mechanism rather than inherently a minority class enhancement technique.

\paragraph{Neural Networks Complement Tree-Based Methods}
While tree-based baselines (LightGBM: 0.9088 F1-score, 0.9776 AUC-ROC) achieve superior balanced performance, neural approaches with specialized architectures attain higher minority-focused metrics (FAIIA + Focal: 0.9495 recall). This suggests complementary roles: tree-based methods excel at balanced classification on tabular data, while neural architectures with domain-specific inductive biases can surpass them on targeted objectives like minority detection.

\paragraph{Rare Attack Detection Feasibility}
The near-perfect detection rates on extremely rare attacks (>0.95 detection on categories with <100 test samples) demonstrate that deep learning can effectively handle severe imbalance when architectures incorporate appropriate structural biases. This finding challenges conventional wisdom that neural networks require large training samples per class, showing that prototype-based representations enable generalization from limited minority class data.

\subsection{Practical Implications}

For practitioners deploying intrusion detection systems, this work provides several actionable insights:

\paragraph{Model Selection Guidance}
Organizations should select models based on operational priorities. FAIIA + Focal maximizes attack detection (0.9495 recall) for high-security environments tolerating elevated alert volumes. FAIIA + BCE balances minority detection and precision (0.9403 recall, 0.8528 precision) for moderate security requirements. Tree-based methods (LightGBM) optimize for balanced performance (0.9088 F1-score, 0.9330 recall, 0.8858 precision) when alert volume constraints are stringent.

\paragraph{Deployment Architecture}
Tiered detection systems combining FAIIA's high sensitivity with secondary high-precision classifiers offer operational advantages: Stage 1 (FAIIA + Focal) achieves comprehensive attack coverage while Stage 2 (LightGBM or ensemble) filters false positives before analyst review. This architecture delivers high recall with manageable alert volumes.

\paragraph{Resource Considerations}
FAA-NET's compact architecture (127844 parameters, approximately 512KB memory footprint) enables deployment on edge devices and resource-constrained environments. Sub-millisecond CPU inference latency and sub-100 microsecond GPU latency support real-time detection in high-throughput networks. Quantization to 8-bit precision would reduce memory requirements to approximately 128KB, facilitating embedded deployment.

\subsection{Limitations and Future Directions}

Several limitations suggest directions for future research:

\paragraph{Dataset Generalization}
Results are demonstrated exclusively on UNSW-NB15. Validation across diverse datasets (NSL-KDD, CICIDS2017, UNSW-NB18, TON-IoT) would strengthen generalizability claims and identify dataset-specific performance factors. Cross-dataset transfer learning experiments could assess whether learned prototypes transfer to new deployment environments.

\paragraph{Multi-Class Extension}
The binary classification formulation (attack vs. normal) requires extension to multi-class attack categorization for operational deployment. Hierarchical classification approaches—binary detection followed by attack type classification—or separate prototype sets per attack category represent promising directions.

\paragraph{Adversarial Robustness}
Vulnerability to adversarial examples remains unexamined. Sophisticated adversaries may craft traffic that evades detection by minimizing similarity to learned prototypes. Adversarial training, certified defenses, and robustness evaluation represent critical future work for high-security deployments.

\paragraph{Interpretability Enhancement}
Systematic attention weight visualization and prototype analysis could provide explainable predictions, enabling security analysts to understand detection rationale. Feature importance analysis of learned prototypes could reveal critical attack signatures informing rule-based detection systems.

\paragraph{Adaptive Learning}
Online learning mechanisms for prototype updates could enable rapid adaptation to emerging attack types without full retraining. Meta-learning approaches could produce models that quickly learn new attack patterns from limited labeled examples, addressing zero-day attack detection challenges.

\subsection{Broader Impact}

The FAIIA mechanism extends beyond intrusion detection to general imbalanced learning scenarios prioritizing minority class detection. Applications include rare disease diagnosis, fraud detection, industrial defect identification, and environmental anomaly monitoring. The combination of prototype-based structural bias and focal modulation provides a transferable framework for minority-focused learning across domains where missing rare but critical events carries severe consequences.

From a network security perspective, this work contributes to the ongoing effort to develop AI-powered intrusion detection systems capable of identifying sophisticated attacks in increasingly complex network environments. The ability to detect 94.95\% of attacks, including near-perfect detection of extremely rare attack types, represents meaningful progress toward comprehensive automated threat detection.

\subsection{Concluding Remarks}

This research demonstrates that addressing class imbalance requires coordinated architectural and algorithmic innovations. While loss function modifications (focal loss, class weighting) provide valuable tools, integrating imbalance awareness directly into model architectures through mechanisms like FAIIA produces stronger minority class emphasis. The prototype-based attention framework introduced in this work provides a foundation for future research in imbalanced learning, offering a principled approach to preventing majority class patterns from overwhelming minority class representations.

The experimental results validate that neural networks, when equipped with appropriate inductive biases, can effectively handle severe class imbalance in tabular data—a domain traditionally dominated by tree-based methods. As network attacks continue to evolve in sophistication and diversity, adaptive learning systems capable of detecting rare and emerging threats become increasingly critical. FAA-NET with FAIIA represents a step toward this goal, demonstrating that architectural innovation can produce models that excel at the security-critical objective of comprehensive attack detection.

Future work should focus on multi-dataset validation, multi-class extension, adversarial robustness, and deployment studies in operational networks. These efforts will transform FAIIA from a research contribution to a production-ready technology for protecting network infrastructure against evolving cyber threats. The broader applicability of prototype-based attention mechanisms to imbalanced learning across domains suggests that the techniques developed here will find utility beyond network security, contributing to the general challenge of learning from imbalanced data distributions.

% === REPLACE THE ENTIRE thebibliography BLOCK WITH THIS: ===

% Choose your bibliography style
\bibliographystyle{IEEEtran}  % For IEEE format

% Specify your .bib file (without .bib extension)
\bibliography{references}     % This loads references.bib

% Optional: If you want to keep the EOD section

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author1.png}}]{Md Arif Faysal Nayem}
(Student Member, IEEE) has completed the B.Sc. degree in Computer Science and Engineering in 2026 from the Department of Computer Science and Engineering, United International University (UIU), Dhaka, Bangladesh.

His research interests include deep learning, large language models (LLMs), computer vision, and robotics. During his undergraduate studies, he worked with several startups, contributing to the development of software solutions, intelligent systems, and automation pipelines. His academic and practical experiences reflect a strong interest in applying machine learning and artificial intelligence techniques to real-world problems.
\end{IEEEbiography}


%If you do not have or do not want to include a photo, you can use IEEEbiographynophoto as shown below:


\EOD

\end{document}

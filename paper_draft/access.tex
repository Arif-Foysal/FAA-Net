\documentclass{ieeeaccess}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{booktabs}




\usepackage{bm}
\makeatletter
\AtBeginDocument{\DeclareMathVersion{bold}
\SetSymbolFont{operators}{bold}{T1}{times}{b}{n}
\SetSymbolFont{NewLetters}{bold}{T1}{times}{b}{it}
\SetMathAlphabet{\mathrm}{bold}{T1}{times}{b}{n}
\SetMathAlphabet{\mathit}{bold}{T1}{times}{b}{it}
\SetMathAlphabet{\mathbf}{bold}{T1}{times}{b}{n}
\SetMathAlphabet{\mathtt}{bold}{OT1}{pcr}{b}{n}
\SetSymbolFont{symbols}{bold}{OMS}{cmsy}{b}{n}
\renewcommand\boldmath{\@nomath\boldmath\mathversion{bold}}}
\makeatother

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}



%Your document starts from here ___________________________________________________
\begin{document}
\history{Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.}
\doi{10.1109/ACCESS.2024.0429000}

\title{FAA-Net: Focal-Aware Attention for Class-Imbalanced Network Intrusion Detection}
\author{\uppercase{Md Arif Faysal Nayem}\authorrefmark{1}}

\address[1]{United International University, , Dhaka 1212 Bangladesh (e-mail: info@uiu.ac.bd)}

\tfootnote{This work is submitted in partial fulfillment of the requirements for successful completion of the Data Mining course.''}

\markboth
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}

\corresp{Corresponding author: Md Arif Faysal Nayem (e-mail: mnayem201194@bscse.uiu.ac.bd, phone: +8801707820797).}

% \begin{abstract}
% Network Intrusion Detection Systems (NIDS) face severe class imbalance 
% where rare attack types constitute less than 5\% of traffic, yet represent 
% critical security threats. Existing deep learning approaches apply focal 
% loss only during training, failing to integrate imbalance awareness into 
% attention mechanisms. We propose FAIIA (Focal-Aware Imbalance-Integrated 
% Attention), a novel attention mechanism that embeds focal modulation 
% $\alpha(1-p)^\gamma$ directly into attention score computation before 
% normalization, combined with explicit attention to learned minority-class 
% prototypes initialized via k-means clustering.

% Evaluated on UNSW-NB15, FAA-NET with FAIIA achieves 99.43\% average recall 
% on minority attack categories (<5000 samples), outperforming XGBoost 
% (98.13\%) and DNN (98.61\%). FAIIA demonstrates particularly strong 
% performance on challenging attack types: +4.72\% on Fuzzers (the most 
% difficult category with 81.95\% baseline recall), +2.12\% on rare Shellcode 
% attacks (378 samples), and wins on 4/6 minority categories while maintaining 
% 100\% attack precision. The tunable focal parameter $\alpha$ enables 
% deployment-specific optimization between attack detection sensitivity and 
% false positive rates. At $\alpha{=}0.60$, FAIIA achieves 98.02\% overall 
% attack recall with perfect attack precision, suitable for high-security 
% environments where missing attacks is more costly than investigating false 
% alarms. With only 134K parameters, FAA-NET with FAIIA provides a practical, 
% interpretable solution for imbalanced intrusion detection in resource-
% constrained deployments.
% \end{abstract}

% \begin{abstract}
% Network Intrusion Detection Systems (NIDS) face severe class imbalance where rare attack types constitute critical security threats. Existing approaches treat imbalance as a post-hoc training concern rather than integrating it into model architecture. We propose FAIIA (Focal-Aware Imbalance-Integrated Attention), a novel attention mechanism that embeds focal modulation $\alpha(1-p)^\gamma$ directly into attention computation before normalization, combined with learned minority-class prototypes.

% Evaluated on UNSW-NB15, FAA-NET with FAIIA achieves the highest attack recall (98.02\%) among compared methods, outperforming XGBoost (97.11\%) and DNN (97.19\%). On minority attack categories (<5000 samples), FAIIA achieves an average detection rate of 99.43\%, winning on 4/6 categories with notable improvements: +4.72\% on Fuzzers (81.95\% baseline), +2.12\% on Shellcode attacks. While trading some precision (78.81\% vs. 81.67\% baseline) for higher recall, FAIIA's tunable focal parameter $\alpha$ enables optimization for environments prioritizing attack detection. With 134K parameters, FAA-NET with FAIIA provides an efficient solution for imbalanced intrusion detection.
% \end{abstract}

\begin{abstract}
Network Intrusion Detection Systems (NIDS) face a critical challenge in detecting rare attack variants that constitute a small fraction of network traffic. Severe class imbalance causes conventional deep learning approaches to exhibit majority-class bias, resulting in poor detection of minority attack categories that often represent emerging or sophisticated threats. Existing attention-based methods apply cost-sensitive adjustments external to the attention mechanism, failing to address the fundamental bias in how attention weights are computed. We introduce the Focal-Aware Attention Network (FAA-Net) featuring Focal-Aware Imbalance-Integrated Attention (FAIIA), a novel mechanism that embeds class imbalance awareness directly into attention score computation through prototype-based cross-attention and uncertainty-driven focal modulation. FAIIA modulates attention scores using an uncertainty-based focal term $\alpha \cdot (1 - 2|p_{\text{init}} - 0.5|)^{\gamma}$ that peaks at decision boundaries where minority instances frequently reside, combined with learned minority-class prototypes generated via K-means clustering to provide explicit attention anchors for rare attack patterns. A class-conditional gating module further refines attention outputs based on prediction difficulty. Evaluated on the UNSW-NB15 dataset with severe imbalance (training ratio: 0.469; test ratio: 0.816), FAA-Net achieves 94.95\% recall, surpassing the strongest baseline (LightGBM: 93.30\%) by 1.65 percentage points. The model demonstrates exceptional performance on extremely rare attacks: 95.45\% detection for Worms (44 test samples), 99.85\% for Analysis (677 samples), 99.31\% for Backdoor (583 samples), and 92.06\% for Shellcode (378 samples). While tree-based baselines achieve higher balanced F1-scores (LightGBM: 0.9088 vs. FAA-Net: 0.8863), FAA-Net demonstrates superior minority-class sensitivity through architectural integration of imbalance awareness. Systematic ablation studies isolate FAIIA's contribution: comparing Vanilla DNN + BCE (91.29\% recall) to FAIIA + BCE (94.03\% recall) reveals a 2.74 percentage point improvement from the attention mechanism alone, while the complete FAA-Net configuration achieves 94.95\% recall—representing a 3.66 percentage point gain over Vanilla DNN + Focal (87.82\%). With 127,844 parameters and sub-millisecond CPU inference latency, FAA-Net is deployable on edge computing infrastructure while maintaining 97.06\% AUC-ROC. The proposed approach demonstrates that integrating imbalance awareness into attention architecture, rather than relying solely on loss function modifications, provides an effective solution for security-critical intrusion detection where false negatives carry severe operational consequences.
\end{abstract}
\begin{IEEEkeywords}
Network intrusion detection, attention mechanism, class imbalance, focal loss, deep learning, edge computing, explainable AI, minority class detection, security-critical systems
\end{IEEEkeywords}


\begin{keywords}
Network intrusion detection, attention mechanism, class imbalance, focal loss, deep learning, edge computing, explainable AI, minority class detection
\end{keywords}

\titlepgskip=-21pt

\maketitle

% \section{Introduction}
% \label{sec:introduction}

% Modern cyber infrastructure faces an escalating threat landscape where sophisticated 
% attacks exploit increasingly complex vulnerabilities. Network Intrusion Detection 
% Systems (NIDS) serve as a critical defense mechanism, continuously monitoring network 
% traffic to identify malicious activities before they compromise system integrity. 
% Traditional signature-based detection methods, while effective against known threats, 
% struggle to identify novel attack patterns and zero-day exploits. This limitation has 
% driven the adoption of machine learning and deep learning approaches that can learn 
% to distinguish malicious from benign traffic based on statistical patterns rather than 
% predefined signatures~\cite{chinnasamy2025deep, kasongo2023deep}.

% Despite significant advances in deep learning-based intrusion detection, a fundamental 
% challenge persists: \textit{severe class imbalance} where rare attack types constitute 
% less than 5\% of network traffic yet represent the most critical security threats. 
% Advanced Persistent Threats (APTs), backdoor installations, shellcode injections, and 
% sophisticated exploit attempts occur infrequently but carry disproportionate impact when 
% successful. Standard deep learning models trained on such imbalanced distributions 
% exhibit systematic bias toward majority classes—predominantly benign traffic—resulting 
% in alarmingly high false negative rates for minority attack categories that security 
% operators can least afford to miss~\cite{milosevic2022extreme, su2020bat}.

% \subsection{The Class Imbalance Challenge in Intrusion Detection}

% The UNSW-NB15 benchmark dataset~\cite{moustafa2015unsw}, widely used for NIDS evaluation, 
% exemplifies this challenge with attack type distributions ranging from 44 samples 
% (Worms) to 37,000 normal traffic instances—a class imbalance ratio exceeding 840:1. 
% Similarly imbalanced distributions characterize real-world network traffic where normal 
% operations dominate and critical attacks represent rare anomalies. This imbalance 
% manifests at multiple levels: between normal and attack traffic overall, and among 
% attack categories themselves where sophisticated threats like Shellcode (378 samples) 
% and Backdoor (583 samples) are vastly outnumbered by more common attack types.

% Conventional approaches to imbalanced learning—including resampling techniques, 
% cost-sensitive loss functions, and ensemble methods~\cite{chen2024survey}—address 
% classification imbalance through adjustments to training objectives or data distributions. 
% Focal loss~\cite{lin2017focal}, originally proposed for dense object detection, has been 
% successfully applied to intrusion detection by down-weighting well-classified examples 
% and focusing learning on hard negatives. Class-balanced loss~\cite{cui2019class} 
% reweights samples based on effective class cardinality to prevent majority class 
% dominance. While these methods improve minority class recognition during training, they 
% operate as \textit{post-hoc corrections to the classification objective}, leaving the 
% fundamental feature representation learning process—particularly attention mechanisms—
% oblivious to class distribution.

% \subsection{Limitations of Existing Attention Mechanisms}

% Attention mechanisms have revolutionized deep learning by enabling models to selectively 
% focus on relevant features while suppressing irrelevant information~\cite{vaswani2017attention}. 
% In intrusion detection, attention can identify which network flow features (packet sizes, 
% protocol flags, timing patterns) are most indicative of malicious activity. However, 
% standard attention computation:
% \begin{equation}
% \text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
% \end{equation}
% treats all samples identically regardless of their class membership or rarity in the 
% training distribution. For imbalanced datasets, this class-agnostic design causes attention 
% weights to be dominated by majority class patterns since they constitute the overwhelming 
% proportion of training batches. Consequently, features critical for identifying rare attacks 
% receive insufficient attention during both training and inference.

% Recent work on imbalanced image classification~\cite{wang2022deep, huang2016learning, 
% zhu2021spectral} has explored attention-based solutions, but these approaches primarily 
% focus on visual domains with spatial attention over image regions. Network intrusion 
% detection presents distinct challenges: (1) tabular flow-based features lack spatial 
% structure, requiring different attention semantics; (2) critical minority attacks exhibit 
% high feature variability, demanding robust pattern matching; (3) real-time deployment 
% constraints necessitate computational efficiency; and (4) security applications prioritize 
% recall (missing no attacks) over precision (minimizing false alarms) differently than 
% general classification tasks.

% \subsection{Research Motivation and Contributions}

% We argue that effective intrusion detection on imbalanced data requires integrating class 
% imbalance awareness \textit{directly into the attention mechanism itself}, influencing how 
% features are weighted during representation learning rather than merely adjusting final 
% classification outputs. This integration should operate during both training and inference, 
% ensuring minority class patterns receive appropriate attention regardless of batch composition.

% To address these challenges, we propose \textbf{FAIIA (Focal-Aware Imbalance-Integrated 
% Attention)}, a novel attention mechanism that embeds class imbalance awareness through three 
% synergistic components:

% \begin{enumerate}
%     \item \textbf{Focal Modulation of Attention Scores:} We apply a focal weighting term 
%     $F(p) = \alpha(1-p)^\gamma$ to attention scores \textit{before softmax normalization}, 
%     where $p$ represents the predicted minority class probability from an auxiliary estimator. 
%     This modulation dynamically amplifies attention strength for samples exhibiting high 
%     uncertainty regarding minority classes, forcing the model to scrutinize potentially 
%     malicious patterns more carefully than confident majority class instances.
    
%     \item \textbf{Prototype-Based Minority Attention:} Beyond standard self-attention, 
%     FAIIA maintains learnable prototype embeddings of minority class patterns initialized 
%     via k-means clustering. During inference, samples are explicitly compared against these 
%     canonical minority representations, ensuring rare attack signatures receive dedicated 
%     attention even when severely underrepresented in training batches.
    
%     \item \textbf{Class-Conditional Gating:} A difficulty-aware gating mechanism refines 
%     attention outputs based on predicted sample difficulty, measured as distance from the 
%     decision boundary. This provides additional focus on ambiguous cases that typically occur 
%     at class interfaces in imbalanced datasets.
% \end{enumerate}

% We integrate FAIIA into \textbf{FAA-NET (Focal-Aware Attention Network)}, a lightweight 
% architecture designed for resource-constrained NIDS deployment. The complete system employs 
% multi-head FAIIA with varying focal strengths to capture diverse attention patterns, combined 
% with Squeeze-and-Excitation blocks for feature recalibration and residual connections for 
% stable gradient flow. Critically, FAIIA introduces a tunable focal parameter $\alpha$ that 
% enables deployment-specific optimization between attack detection sensitivity and false 
% positive rates, addressing the heterogeneous operational requirements of different security 
% environments—from high-security critical infrastructure demanding maximum recall to 
% general-purpose networks balancing detection with operational overhead.

% \subsection{Main Contributions}

% The primary contributions of this work are:

% \begin{itemize}
%     \item \textbf{Novel Attention Mechanism:} FAIIA represents a novel attention mechanism 
%     to integrate focal modulation directly into attention score computation for imbalanced 
%     network intrusion detection, providing a principled approach to class-aware feature 
%     weighting during both training and inference.
    
%     \item \textbf{Prototype-Augmented Architecture:} We introduce learnable minority class 
%     prototypes within the attention framework, enabling explicit pattern matching against 
%     rare attack signatures and ensuring consistent minority class representation regardless 
%     of batch composition.
    
% \item \textbf{Comprehensive Empirical Validation:} Extensive evaluation on the UNSW-NB15 
% benchmark at standard threshold ($\theta=0.5$) demonstrates that FAA-NET with FAIIA achieves 
% \textbf{99.43\% average detection rate on minority attack categories} (<5,000 samples), 
% outperforming XGBoost (98.13\%) by 1.30 percentage points and Vanilla DNN (98.61\%) by 
% 0.82 percentage points. FAIIA wins on \textbf{4 out of 6 minority attack categories}, 
% demonstrating its effectiveness on rare threats. Notably, FAIIA shows substantial improvements 
% on challenging attack types: Fuzzers (+4.72pp over XGBoost, achieving 86.67\% vs. 81.95\%), 
% Shellcode (+2.12pp, 98.15\% vs. 96.03\% on only 378 samples), and Exploits (+0.76pp, 99.61\% 
% vs. 98.85\%). Overall, FAIIA achieves the highest attack recall (98.02\%) among compared 
% methods with an F1-score of 0.8737, balancing security-focused detection with operational 
% practicality.

% \item \textbf{Ablation Studies and Analysis:} Systematic ablation experiments confirm that 
% both focal modulation (approximately \textbf{2\% gain in minority recall}) and prototype 
% attention (approximately \textbf{1--2\% gain}) provide independent and complementary benefits. 
% Sensitivity analysis across focal parameter values $\alpha \in [0.3, 0.8]$ demonstrates 
% deployment flexibility, with lower values favoring balanced F1-score optimization and higher 
% values prioritizing minority attack detection in security-critical deployment scenarios.

    
%     \item \textbf{Practical Deployment Viability:} With only 134,221 trainable parameters and 
%     efficient inference, FAA-NET with FAIIA demonstrates computational feasibility for 
%     edge-deployed NIDS where resources are constrained, while providing interpretable attention 
%     patterns for security analysts to understand model decisions.
% \end{itemize}

% \subsection{Paper Organization}

% The remainder of this paper is organized as follows. Section~\ref{sec:related} reviews related 
% work on intrusion detection, imbalanced learning, and attention mechanisms. Section~\ref{sec:method} 
% presents the FAIIA mechanism and FAA-NET architecture in detail, including mathematical formulation 
% and design rationale. Section~\ref{sec:experiments} describes the experimental setup, dataset, 
% and evaluation methodology. Section~\ref{sec:results} presents comprehensive results including 
% overall performance, per-attack category analysis, ablation studies, and hyperparameter sensitivity. 
% Section~\ref{sec:discussion} discusses implications, limitations, and deployment considerations. 
% Finally, Section~\ref{sec:conclusion} concludes with future research directions.

\section{Introduction}
\label{sec:introduction}

Modern cyber infrastructure faces an escalating threat landscape where sophisticated attacks exploit increasingly complex vulnerabilities. Network Intrusion Detection Systems (NIDS) serve as a critical defense mechanism, continuously monitoring network traffic to identify malicious activities before they compromise system integrity. Traditional signature-based detection methods, while effective against known threats, struggle to identify novel attack patterns and zero-day exploits. This limitation has driven the adoption of machine learning and deep learning approaches that can learn to distinguish malicious from benign traffic based on statistical patterns rather than predefined signatures~\cite{chinnasamy2025deep, kasongo2023deep}.

Despite significant advances in deep learning-based intrusion detection, a fundamental challenge persists: \textit{severe class imbalance} where rare attack types constitute a small fraction of network traffic yet represent critical security threats. Advanced Persistent Threats (APTs), backdoor installations, shellcode injections, and sophisticated exploit attempts occur infrequently but carry disproportionate impact when successful. Standard deep learning models trained on such imbalanced distributions exhibit systematic bias toward majority classes—predominantly benign traffic—resulting in elevated false negative rates for minority attack categories that security operators can least afford to miss~\cite{milosevic2022extreme, su2020bat}.

\subsection{The Class Imbalance Challenge in Intrusion Detection}

The UNSW-NB15 benchmark dataset~\cite{moustafa2015unsw}, widely used for NIDS evaluation, exemplifies this challenge with multi-level imbalance. At the binary level, the training partition contains 119341 attack samples versus 56000 normal instances (imbalance ratio: 0.469), while the test partition exhibits more severe imbalance with 45332 attacks versus 37000 normal instances (imbalance ratio: 0.816). More critically, individual attack categories demonstrate extreme rarity: Worms appear in only 44 test samples, Analysis attacks in 677 samples, Backdoor attacks in 583 samples, and Shellcode in 378 samples. This represents class imbalance ratios exceeding 840:1 between the rarest attacks and normal traffic. Similarly imbalanced distributions characterize real-world network traffic where normal operations dominate and critical attacks represent rare anomalies.

This imbalance manifests at multiple levels: between normal and attack traffic overall, and among attack categories themselves where sophisticated threats are vastly outnumbered by both normal traffic and more common attack types. Conventional approaches to imbalanced learning—including resampling techniques, cost-sensitive loss functions, and ensemble methods~\cite{chen2024survey}—address classification imbalance through adjustments to training objectives or data distributions. Focal loss~\cite{lin2017focal}, originally proposed for dense object detection, has been successfully applied to intrusion detection by down-weighting well-classified examples and focusing learning on hard negatives. Class-balanced loss~\cite{cui2019class} reweights samples based on effective class cardinality to prevent majority class dominance. While these methods improve minority class recognition during training, they operate as \textit{post-hoc corrections to the classification objective}, leaving the fundamental feature representation learning process—particularly attention mechanisms—largely agnostic to class distribution.

\subsection{Limitations of Existing Attention Mechanisms}

Attention mechanisms have demonstrated effectiveness in deep learning by enabling models to selectively focus on relevant features while suppressing irrelevant information~\cite{vaswani2017attention}. In intrusion detection, attention can identify which network flow features (packet sizes, protocol flags, timing patterns) are most indicative of malicious activity. However, standard attention computation:
\begin{equation}
\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{equation}
treats all samples identically regardless of their class membership or rarity in the training distribution. For imbalanced datasets, this class-agnostic design causes attention weights to be influenced predominantly by majority class patterns since they constitute the overwhelming proportion of training samples. Consequently, features critical for identifying rare attacks may receive insufficient attention during both training and inference.

Recent work on imbalanced image classification~\cite{wang2022deep, huang2016learning, zhu2021spectral} has explored attention-based solutions, but these approaches primarily focus on visual domains with spatial attention over image regions. Network intrusion detection presents distinct challenges: (1) tabular flow-based features lack spatial structure, requiring different attention semantics; (2) minority attacks exhibit high feature variability, demanding robust pattern matching; (3) real-time deployment constraints necessitate computational efficiency; and (4) security applications prioritize recall (minimizing false negatives) over precision (minimizing false alarms) differently than general classification tasks~\cite{sokolova2009systematic, davis2006relationship}.

\subsection{Research Motivation and Contributions}

We hypothesize that effective intrusion detection on imbalanced data requires integrating class imbalance awareness \textit{directly into the attention mechanism itself}, influencing how features are weighted during representation learning rather than merely adjusting final classification outputs. This integration should operate during both training and inference, ensuring minority class patterns receive appropriate attention regardless of batch composition.

To address these challenges, we propose \textbf{E-DAN v3 (Edge-Deployable Attention Network version 3) with Focal-Aware Imbalance-Integrated Attention (FAIIA)}, a mechanism that embeds class imbalance awareness through three synergistic components:

\begin{enumerate}
    \item \textbf{Uncertainty-Based Focal Modulation:} Unlike traditional focal loss that emphasizes confident misclassifications through $(1-p_t)^\gamma$, FAIIA employs uncertainty-driven modulation $F(p) = \alpha(1 - 2|p_{\text{init}} - 0.5|)^\gamma$ applied to attention scores \textit{before softmax normalization}. This formulation peaks at decision boundaries ($p_{\text{init}} = 0.5$) where minority instances frequently reside, dynamically amplifying attention for uncertain predictions rather than confident errors. The initial probability $p_{\text{init}}$ is estimated by a lightweight auxiliary network, providing class-awareness without requiring ground truth labels during inference.
    
    \item \textbf{Prototype-Based Cross-Attention:} FAIIA maintains learnable prototype embeddings initialized via K-means clustering ($K=8$) on minority class training samples. Rather than standard self-attention where inputs attend to themselves (potentially dominated by majority patterns), FAIIA performs cross-attention where inputs explicitly attend to these learned minority prototypes. This architectural design ensures rare attack signatures receive dedicated attention even when underrepresented in training batches, providing explicit minority class anchors in the feature space.
    
    \item \textbf{Class-Conditional Gating:} A difficulty-aware gating mechanism refines attention outputs based on prediction uncertainty, measured as $d = 1 - 2|p_{\text{init}} - 0.5|$. This provides additional emphasis on ambiguous samples that typically occur at class interfaces in imbalanced datasets, modulating feature representations according to classification difficulty.
\end{enumerate}

We integrate FAIIA into E-DAN v3, a compact architecture with 127844 parameters designed for resource-constrained NIDS deployment. The complete system employs 4-head FAIIA with varying focal strengths ($\alpha_i = 0.60 \times (1 + 0.1i)$ for head $i$) to capture diverse attention patterns, combined with Squeeze-and-Excitation blocks for channel-wise feature recalibration and residual connections for stable gradient flow through the 3-layer feedforward backbone ([256, 128, 64] hidden dimensions).

\subsection{Main Contributions}

The primary contributions of this work are:

\begin{itemize}
    \item \textbf{Novel Attention Mechanism:} FAIIA integrates uncertainty-based focal modulation and prototype-based cross-attention directly into attention score computation for imbalanced network intrusion detection. Unlike existing methods that apply cost-sensitive adjustments externally, FAIIA embeds imbalance awareness into the attention architecture itself, providing a principled approach to class-aware feature weighting during representation learning.
    
    \item \textbf{Prototype-Augmented Architecture:} We introduce learnable minority class prototypes within the attention framework, enabling explicit cross-attention against rare attack signatures. The K-means initialization from minority training samples followed by gradient-based fine-tuning ensures consistent minority class representation regardless of batch composition, addressing the fundamental problem of majority class dominance in standard attention mechanisms.
    
    \item \textbf{Comprehensive Empirical Validation:} Extensive evaluation on the UNSW-NB15 benchmark demonstrates that E-DAN v3 with FAIIA achieves 94.95\% recall, surpassing the strongest baseline (LightGBM: 93.30\%) by 1.65 percentage points. Detection rates on extremely rare attacks validate FAIIA's effectiveness: 95.45\% on Worms (44 test samples), 99.85\% on Analysis attacks (677 samples), 99.31\% on Backdoor (583 samples), and 92.06\% on Shellcode (378 samples). While tree-based baselines achieve higher balanced F1-scores (LightGBM: 0.9088 vs. FAIIA + Focal: 0.8863), FAIIA demonstrates superior minority-class sensitivity—a deliberate design trade-off prioritizing security-critical threat detection over balanced accuracy metrics.
    
    \item \textbf{Systematic Ablation Analysis:} Controlled ablation experiments isolate FAIIA's contribution independent of loss function choice. Comparing Vanilla DNN + BCE (91.29\% recall) to FAIIA + BCE (94.03\% recall) reveals a 2.74 percentage point improvement from the attention mechanism alone. The complete FAIIA + Focal configuration achieves 94.95\% recall—a 7.13 percentage point gain over Vanilla DNN + Focal (87.82\% recall). These results validate that architectural integration of imbalance awareness provides substantial benefits beyond loss-level adjustments, with synergistic effects when combined with focal loss.
    
    \item \textbf{Practical Deployment Viability:} With 127844 trainable parameters (2.34× larger than vanilla baseline), E-DAN v3 maintains computational efficiency suitable for edge deployment. Sub-millisecond CPU inference latency and strong AUC-ROC (97.06\%) demonstrate that the model balances minority detection capability with practical deployment constraints. Attention weight analysis provides interpretable insights into which prototypes activate for specific predictions, supporting security analyst understanding of model decisions.
\end{itemize}

\subsection{Paper Organization}

The remainder of this paper is organized as follows. Section~\ref{sec:related} reviews related work on intrusion detection, imbalanced learning, and attention mechanisms. Section~\ref{sec:methodology} presents the FAIIA mechanism and E-DAN v3 architecture in detail, including mathematical formulation, prototype generation, and design rationale. Section~\ref{sec:results} presents comprehensive results including overall performance comparisons, ablation studies isolating architectural contributions, per-attack category analysis, and ROC/PR curve evaluation. Section~\ref{sec:discussion} discusses theoretical implications, precision-recall trade-offs, deployment considerations, and limitations. Finally, Section~\ref{sec:conclusion} concludes with a summary of contributions and future research directions.
\section{Related Work}
\label{sec:related}

We organize related work into four key areas: network intrusion detection systems, 
imbalanced learning techniques, attention mechanisms in deep learning, and their 
application to security domains.

\subsection{Network Intrusion Detection Systems}

Network intrusion detection has evolved from signature-based approaches to 
sophisticated machine learning systems capable of identifying novel attack patterns. 
Chinnasamy et al.~\cite{chinnasamy2025deep} provide a comprehensive survey of deep 
learning methods for NIDS, categorizing approaches by architecture (CNNs, RNNs, 
autoencoders) and highlighting the persistent challenge of class imbalance across 
all methods. Traditional machine learning approaches, including Support Vector 
Machines, Random Forests, and ensemble methods, have been extensively applied to 
intrusion detection with varying success on imbalanced datasets.

\subsubsection{Deep Learning Architectures for NIDS}

Convolutional Neural Networks (CNNs) have been employed to capture spatial patterns 
in network flow features, treating feature vectors as one-dimensional signals where 
local feature interactions are meaningful. Su et al.~\cite{su2020bat} proposed BAT 
(Bidirectional LSTM with Attention), demonstrating that attention mechanisms can 
improve feature selection for intrusion detection on the NSL-KDD dataset. However, 
their attention mechanism operates uniformly across all samples without regard to 
class distribution, limiting effectiveness on minority attacks.

Recurrent Neural Networks, particularly Long Short-Term Memory (LSTM) networks, have 
been applied to model temporal dependencies in network traffic sequences. Kasongo~\cite{kasongo2023deep} 
developed an RNN-based framework achieving competitive performance on balanced metrics 
but acknowledged degraded performance on rare attack categories. These sequence-based 
approaches assume temporal ordering of features, which may not align with tabular 
flow-based representations where features represent aggregated statistics rather than 
time series.

\subsubsection{Benchmark Datasets and Evaluation Challenges}

% \begin{table}[t]
% \centering
% \caption{Per-Attack Category Detection Rate Comparison ($\theta = 0.5$)}
% \label{tab:per_attack}
% \footnotesize
% \begin{tabular}{|l|r|c|c|c|c|}
% \hline
% \textbf{Category} & \textbf{Samples} & \textbf{XGBoost} & \textbf{DNN} & \textbf{FAIIA} & \textbf{Best} \\
% \hline
% \multicolumn{6}{|l|}{\textit{Minority Classes ($<$5,000 samples)}} \\
% \hline
% Analysis        & 677   & 0.9350 & 0.9985 & \textbf{0.9985} & FAIIA \\
% Backdoor        & 583   & \textbf{0.9983} & \textbf{0.9983} & 0.9949 & XGBoost \\
% DoS             & 4,089 & 0.9958 & 0.9944 & \textbf{0.9963} & FAIIA \\
% Reconnaissance  & 3,496 & \textbf{0.9983} & 0.9834 & 0.9946 & XGBoost \\
% Shellcode       & 378   & 0.9603 & 0.9418 & \textbf{0.9815} & FAIIA \\
% Worms           & 44    & 1.0000 & 1.0000 & 1.0000 & Tie \\
% \hline
% \textit{Minority Avg} & -- & 0.9813 & 0.9861 & \textbf{0.9943} & FAIIA \\
% \hline
% \multicolumn{6}{|l|}{\textit{Majority Classes ($\geq$5,000 samples)}} \\
% \hline
% Exploits        & 11,132 & 0.9885 & 0.9933 & \textbf{0.9961} & FAIIA \\
% Fuzzers         & 6,062  & 0.8195 & 0.8199 & \textbf{0.8667} & FAIIA \\
% Generic         & 18,871 & 0.9997 & \textbf{0.9998} & \textbf{0.9998} & Tie \\
% \hline
% \textit{Majority Avg} & -- & 0.9359 & 0.9377 & \textbf{0.9542} & FAIIA \\
% \hline
% \end{tabular}
% \vspace{1mm}

% \footnotesize{\textit{Bold indicates best performance. FAIIA achieves superior detection in
% 4 out of 6 minority categories and all majority attack categories. Normal traffic class is excluded.}}
% \end{table}



The UNSW-NB15 dataset~\cite{moustafa2015unsw}, introduced by Moustafa and Slay, has 
become a widely adopted benchmark for evaluating NIDS performance on realistic, 
imbalanced traffic. Containing nine attack categories with severe class imbalance 
(44 to 37,000 samples per class), it better reflects real-world network environments 
than earlier balanced datasets like KDD Cup '99 or NSL-KDD. However, Sharafaldin 
et al.~\cite{sharafaldin2018toward} note that even modern datasets struggle to 
capture the full diversity of evolving attack tactics, emphasizing the need for 
models that generalize well to rare, previously unseen attack patterns—precisely 
the scenario where minority class learning is critical.

Sokolova and Lapalme~\cite{sokolova2009systematic} provide systematic analysis of 
performance metrics for classification tasks, demonstrating that accuracy is 
misleading for imbalanced datasets. They advocate for precision, recall, F1-score, 
and class-specific metrics—recommendations we adopt in our evaluation methodology. 
Davis and Goadrich~\cite{davis2006relationship} further establish that precision-recall 
curves are more informative than ROC curves for imbalanced classification, as they 
directly reflect minority class performance without being inflated by large numbers 
of correctly classified majority samples.

\subsection{Imbalanced Learning Techniques}

The class imbalance problem has been extensively studied across machine learning 
domains. Chen et al.~\cite{chen2024survey} survey recent advances in imbalanced 
learning, categorizing approaches into data-level methods (resampling), algorithm-level 
methods (cost-sensitive learning), and hybrid approaches. While these techniques improve 
minority class recognition, most operate independently of the model architecture, 
treating imbalance as a data preprocessing or loss function adjustment problem rather 
than integrating imbalance awareness into feature representation learning.

\subsubsection{Cost-Sensitive and Focal Loss Approaches}

Focal loss, introduced by Lin et al.~\cite{lin2017focal} for dense object detection, 
addresses class imbalance by down-weighting the loss contribution from well-classified 
examples:
\begin{equation}
\mathcal{L}_{\text{focal}} = -\alpha_t(1-p_t)^\gamma \log(p_t)
\end{equation}
This formulation focuses learning on hard negatives and rare classes by reducing the 
influence of easily classified majority samples. While highly effective for object 
detection where rare objects occupy small spatial regions, focal loss operates as a 
\textit{post-hoc adjustment to the classification objective}. The underlying feature 
representation—including attention mechanisms—remains unchanged and continues to be 
dominated by majority class patterns during training.

Cui et al.~\cite{cui2019class} proposed class-balanced loss based on effective number 
of samples, accounting for the diminishing marginal benefit of additional samples from 
majority classes. Their re-weighting scheme:
\begin{equation}
w_c = \frac{1-\beta}{1-\beta^{n_c}}
\end{equation}
where $n_c$ is the number of samples in class $c$ and $\beta \in [0,1)$ controls 
re-weighting strength, provides a principled approach to setting class weights. However, 
like focal loss, this operates only on the final loss function without modifying how 
attention mechanisms prioritize features during representation learning.

\subsubsection{Deep Representation Learning for Imbalanced Data}

Huang et al.~\cite{huang2016learning} proposed learning deep representations specifically 
for imbalanced classification through a two-stage approach: first learning features on 
balanced data, then fine-tuning on the imbalanced distribution. While this improves 
feature quality for minority classes, it requires careful curriculum design and does not 
address the fundamental issue of attention bias during standard training.

Milošević and Ćirić~\cite{milosevic2022extreme} specifically addressed extreme minority 
class detection in network intrusion, proposing a combination of SMOTE oversampling with 
ensemble methods. Their work demonstrates that even aggressive synthetic minority 
oversampling struggles with extremely rare classes (< 0.1\% of dataset), motivating our 
approach of integrating minority awareness directly into the model architecture rather 
than relying solely on data augmentation.

\subsection{Attention Mechanisms and Imbalanced Learning}

Attention mechanisms, formalized by Vaswani et al.~\cite{vaswani2017attention} in the 
Transformer architecture, enable models to selectively focus on relevant information 
through learned weighting of input features or sequence positions. The standard 
self-attention mechanism computes:
\begin{equation}
\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{equation}
where queries $Q$, keys $K$, and values $V$ are learned projections of the input. This 
formulation treats all samples identically, computing attention weights based solely on 
feature similarity without regard to class membership or rarity in the training distribution.

\subsubsection{Attention for Imbalanced Image Classification}

Wang et al.~\cite{wang2022deep} proposed deep attention-based imbalanced image 
classification, introducing a class-attention module that weights feature maps based on 
class frequency during training. Their approach applies attention at the channel level 
for convolutional features, emphasizing minority-class-relevant channels. However, this 
method is specifically designed for spatial image data where channels represent learned 
feature detectors, and the attention operates on intermediate feature maps rather than 
within the attention score computation itself.

Zhu et al.~\cite{zhu2021spectral} developed spectral-spatial attention for imbalanced 
hyperspectral image classification, demonstrating that spatial attention mechanisms can 
be adapted for imbalanced scenarios by incorporating class-prior knowledge. Their global 
learning framework uses attention to aggregate multi-scale features weighted by class 
distribution. While conceptually related to our work, their spatial attention operates 
on image patches and does not address tabular network flow data where spatial structure 
is absent.

\subsubsection{Limitations of Existing Attention Approaches}

A critical limitation of existing attention-based imbalanced learning methods is that 
they either: (1) apply attention uniformly across samples without class-awareness 
(standard attention), (2) modify feature maps post-attention based on class information 
(channel attention), or (3) use attention for sample re-weighting at the loss level 
(attention-based sample weighting). \textit{None integrate class imbalance awareness 
directly into the attention score computation itself}, where feature importance weights 
are determined.

Furthermore, existing methods primarily target image classification where minority classes 
share spatial structure with majority classes (e.g., small objects vs. large objects in 
the same scene). Network intrusion detection presents fundamentally different challenges: 
(1) tabular features lack spatial relationships, requiring different attention semantics; 
(2) minority attack classes exhibit high intra-class variability with subtle distinguishing 
features; (3) critical minority attacks may be completely absent from training batches due 
to extreme rarity; and (4) security requirements demand high recall (missing no attacks) 
even at the cost of increased false positives—a different optimization objective than 
general classification.

\subsection{Gap Analysis and Positioning}

Table~\ref{tab:related_comparison} summarizes the key differences between our approach 
and related work. While focal loss and class-balanced methods address imbalance through 
loss function design, and attention-based methods selectively weight features, FAIIA 
uniquely integrates both paradigms by applying focal modulation directly within attention 
score computation. The addition of learnable minority prototypes ensures consistent 
minority class representation regardless of batch composition—a critical consideration 
for extreme imbalance scenarios common in intrusion detection.

Our work advances beyond existing approaches in three key aspects:

\textbf{Architectural Integration:} Rather than treating imbalance as a loss function 
design problem (focal loss, class-balanced loss) or a post-attention feature weighting 
problem (channel attention), FAIIA integrates imbalance awareness into the attention 
mechanism itself, influencing feature weighting during representation learning.

\textbf{Explicit Minority Representation:} Learnable prototypes provide persistent 
minority class representations that participate in every attention computation, addressing 
the fundamental issue that minority classes may be absent from training batches in extreme 
imbalance scenarios.

\textbf{Domain-Specific Design:} FAIIA is designed specifically for tabular network flow 
data in intrusion detection, with attention semantics appropriate for feature-based 
representations rather than spatial or sequential structures, and with hyperparameter 
tunability ($\alpha$) enabling deployment-specific optimization between recall and precision.

\begin{table*}[t]
\centering
\caption{Comparison of Related Work on Imbalanced Learning and Attention Mechanisms}
\label{tab:related_comparison}
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Imbalance} & \textbf{Attention} & \textbf{Integration} & \textbf{Prototypes} & \textbf{NIDS} \\
 & \textbf{Aware} & \textbf{Mechanism} & \textbf{Point} & & \textbf{Focused} \\
\midrule
Focal Loss~\cite{lin2017focal} & \checkmark & \texttimes & Loss function & \texttimes & \texttimes \\
Class-Balanced~\cite{cui2019class} & \checkmark & \texttimes & Loss function & \texttimes & \texttimes \\
BAT (Su et al.)~\cite{su2020bat} & \texttimes & \checkmark & LSTM attention & \texttimes & \checkmark \\
Wang et al.~\cite{wang2022deep} & \checkmark & \checkmark & Channel-level & \texttimes & \texttimes \\
Zhu et al.~\cite{zhu2021spectral} & \checkmark & \checkmark & Feature maps & \texttimes & \texttimes \\
Milošević et al.~\cite{milosevic2022extreme} & \checkmark & \texttimes & SMOTE + ensemble & \texttimes & \checkmark \\
\midrule
\textbf{FAIIA (Ours)} & \checkmark & \checkmark & \textbf{Attention scores} & \checkmark & \checkmark \\
\bottomrule
\end{tabular}
\vspace{2mm}

\footnotesize{\textit{Note:} Integration Point indicates where imbalance awareness is incorporated: loss function (post-hoc), channel/feature-level (post-attention), or attention scores (within attention computation). Only FAIIA integrates at the attention score level with explicit minority prototypes for NIDS.}
\end{table*}

To the best of our knowledge, FAIIA represents the first attention mechanism to integrate 
focal modulation directly into attention score computation combined with learnable minority 
class prototypes, specifically designed for imbalanced network intrusion detection on 
tabular flow data.


% \section{Proposed Method}
% \subsection{FAIIA: Focal-Aware Imbalance-Integrated Attention}

% \begin{algorithm}[t]
% \caption{FAIIA Forward Pass}
% \label{alg:faiia}
% \begin{algorithmic}[1]

% \STATE \textbf{Input:} Feature vector $\mathbf{x} \in \mathbb{R}^{d}$, parameters $\alpha, \gamma$
% \STATE \textbf{Output:} Attended representation $\mathbf{z} \in \mathbb{R}^{d}$

% \STATE $p \leftarrow \text{MinorityProbEstimator}(\mathbf{x})$ \hfill (Eq.~1)
% \STATE $F(p) \leftarrow \alpha (1 - p)^{\gamma} \tau$ \hfill (Eq.~2)

% \FOR{$i = 1$ \TO $H$}
%     \STATE $\mathbf{Q}_{i} \leftarrow W_{Q}^{i}\mathbf{x}$
%     \STATE $\mathbf{K}_{i} \leftarrow W_{K}^{i}\mathbf{x}$
%     \STATE $\mathbf{V}_{i} \leftarrow W_{V}^{i}\mathbf{x}$ \hfill (Eq.~3)

%     \STATE \textit{Self-feature attention}
%     \STATE $s_{\text{self}}^{i} \leftarrow \langle \mathbf{Q}_{i}, \mathbf{K}_{i} \rangle$ \hfill (Eq.~4)
%     \STATE $w_{\text{self}}^{i} \leftarrow \sigma\!\left( \dfrac{F(p)\, s_{\text{self}}^{i}}{\sqrt{d_{k}}} \right)$ \hfill (Eq.~5)
%     \STATE $\mathbf{A}_{\text{self}}^{i} \leftarrow w_{\text{self}}^{i}\mathbf{V}_{i}$ \hfill (Eq.~6)

%     \STATE \textit{Prototype attention}
%     \STATE $\mathbf{s}_{\text{proto}}^{i} \leftarrow \mathbf{Q}_{i}\mathbf{K}_{p}^{T}$ \hfill (Eq.~7)
%     \STATE $\mathbf{w}_{\text{proto}}^{i} \leftarrow \text{softmax}\!\left( \dfrac{F(p)\,\mathbf{s}_{\text{proto}}^{i}}{\sqrt{d_{k}}} \right)$ \hfill (Eq.~8--9)
%     \STATE $\mathbf{A}_{\text{proto}}^{i} \leftarrow \mathbf{w}_{\text{proto}}^{i}\mathbf{V}_{p}$ \hfill (Eq.~10)

%     \STATE \textit{Fusion}
%     \STATE $\mathbf{h}_{i} \leftarrow W_{o}^{i}\!\left[\mathbf{A}_{\text{self}}^{i} \oplus \mathbf{A}_{\text{proto}}^{i}\right]$ \hfill (Eq.~11)
% \ENDFOR

% \STATE $\mathbf{h} \leftarrow W_{\text{final}}\!\left[\mathbf{h}_{1} \oplus \cdots \oplus \mathbf{h}_{H}\right]$ \hfill (Eq.~12)
% \STATE $d \leftarrow 1 - 2|p - 0.5|$ \hfill (Eq.~13)
% \STATE $\mathbf{g} \leftarrow \text{Gate}([\mathbf{h} \oplus d])$ \hfill (Eq.~14)
% \STATE $\mathbf{z} \leftarrow \text{LayerNorm}(\mathbf{g} \odot \mathbf{h} + \mathbf{x})$ \hfill (Eq.~15)

% \end{algorithmic}
% \end{algorithm}


% We propose FAIIA (Focal-Aware Imbalance-Integrated Attention), a novel attention mechanism designed for imbalanced network intrusion detection on tabular flow data. Unlike standard Transformer attention that operates on sequences, FAIIA combines focal-modulated feature re-weighting with prototype-based minority class attention.

% \subsubsection{Minority Probability Estimation}

% Given an input feature vector $\mathbf{x} \in \mathbb{R}^{d}$, we first estimate the minority class probability using an auxiliary network:

% \begin{equation}
% p = \sigma(W_p^{(2)} \cdot \text{ReLU}(W_p^{(1)} \mathbf{x} + b_p^{(1)}) + b_p^{(2)})
% \end{equation}

% where $\sigma(\cdot)$ is the sigmoid function, and $W_p^{(1)} \in \mathbb{R}^{64 \times d}$, $W_p^{(2)} \in \mathbb{R}^{1 \times 64}$ are learnable parameters.

% \subsubsection{Focal Modulation Function}

% The focal modulation function adapts attention weights based on predicted minority probability:

% \begin{equation}
% F(p; \alpha, \gamma) = \alpha \cdot (1 - p + \epsilon)^\gamma \cdot \tau
% \label{eq:focal_modulation}
% \end{equation}

% where:
% \begin{itemize}
%     \item $\alpha \in [0, 1]$ is the focal strength parameter (we use $\alpha = 0.60$)
%     \item $\gamma > 0$ is the focusing exponent (we use $\gamma = 2$, following \cite{focal_loss})
%     \item $\tau$ is a learnable temperature parameter
%     \item $\epsilon = 10^{-8}$ for numerical stability
% \end{itemize}

% The focal term $(1-p)^\gamma$ down-weights samples with high minority class confidence, forcing the model to focus on hard-to-classify instances at the decision boundary.

% \subsubsection{Self-Feature Attention}

% We compute query, key, and value projections:

% \begin{equation}
% \begin{aligned}
% \mathbf{Q} &= W_Q \mathbf{x} + b_Q \\
% \mathbf{K} &= W_K \mathbf{x} + b_K \\
% \mathbf{V} &= W_V \mathbf{x} + b_V
% \end{aligned}
% \end{equation}

% where $W_Q, W_K, W_V \in \mathbb{R}^{d_k \times d}$ project the input to attention dimension $d_k$.

% For tabular data, we compute a single attention score per sample via element-wise similarity:

% \begin{equation}
% s_{\text{self}} = \sum_{i=1}^{d_k} \mathbf{Q}_i \cdot \mathbf{K}_i = \langle \mathbf{Q}, \mathbf{K} \rangle
% \label{eq:self_score}
% \end{equation}

% The focal-modulated attention weight is:

% \begin{equation}
% w_{\text{self}} = \sigma\left(\frac{F(p) \cdot s_{\text{self}}}{\sqrt{d_k}}\right)
% \label{eq:self_attention}
% \end{equation}

% where $\sigma(\cdot)$ is the sigmoid function and $\sqrt{d_k}$ provides scale normalization. The self-attended output is:

% \begin{equation}
% \mathbf{A}_{\text{self}} = w_{\text{self}} \cdot \mathbf{V}
% \end{equation}

% \subsubsection{Prototype-Based Minority Attention}

% To ensure explicit focus on rare attack patterns, we maintain $M$ learnable prototype embeddings initialized via k-means clustering on minority class samples:

% \begin{equation}
% \mathbf{K}_p, \mathbf{V}_p \in \mathbb{R}^{M \times d_k}
% \end{equation}

% The prototype attention scores are computed as:

% \begin{equation}
% \mathbf{s}_{\text{proto}} = \mathbf{Q} \mathbf{K}_p^T \in \mathbb{R}^{M}
% \end{equation}

% We apply focal modulation to prototype scores by broadcasting $F(p)$ across all prototypes:

% \begin{equation}
% \tilde{\mathbf{s}}_{\text{proto}} = F(p) \cdot \mathbf{s}_{\text{proto}}
% \end{equation}

% The prototype attention weights are:

% \begin{equation}
% \mathbf{w}_{\text{proto}} = \text{softmax}\left(\frac{\tilde{\mathbf{s}}_{\text{proto}}}{\sqrt{d_k}}\right) \in \mathbb{R}^{M}
% \end{equation}

% The prototype-attended output aggregates information from all prototypes:

% \begin{equation}
% \mathbf{A}_{\text{proto}} = \mathbf{w}_{\text{proto}} \mathbf{V}_p \in \mathbb{R}^{d_k}
% \end{equation}

% \subsubsection{Fusion and Output}

% The self-attention and prototype attention outputs are fused via concatenation and projection:

% \begin{equation}
% \text{FAIIA}(\mathbf{x}, p) = \text{LayerNorm}\left(W_o [\mathbf{A}_{\text{self}} \oplus \mathbf{A}_{\text{proto}}] + b_o\right)
% \label{eq:faiia_output}
% \end{equation}

% where $\oplus$ denotes concatenation, $W_o \in \mathbb{R}^{d_k \times 2d_k}$ is the output projection matrix, and LayerNorm provides normalization.

% \subsubsection{Multi-Head FAIIA}

% We employ $H$ parallel FAIIA heads with varying focal strengths to capture diverse attention patterns:

% \begin{equation}
% \text{FAIIA}_i(\mathbf{x}, p; \alpha_i) \quad \text{where} \quad \alpha_i = \alpha \cdot (1 + 0.1 \cdot i), \quad i = 0, \ldots, H-1
% \end{equation}

% The outputs are concatenated and projected back to input dimension:

% \begin{equation}
% \mathbf{h} = W_{\text{final}} [\text{FAIIA}_0 \oplus \text{FAIIA}_1 \oplus \cdots \oplus \text{FAIIA}_{H-1}] + b_{\text{final}}
% \end{equation}

% where $W_{\text{final}} \in \mathbb{R}^{d \times (H \cdot d_k)}$.

% \subsubsection{Class-Conditional Gating}

% Finally, we apply class-conditional gating based on prediction difficulty:

% \begin{equation}
% d = 1 - 2|p - 0.5|
% \label{eq:difficulty}
% \end{equation}

% where $d \in [0, 1]$ is maximized for samples near the decision boundary ($p \approx 0.5$). The gate values are:

% \begin{equation}
% \mathbf{g} = \sigma(W_g^{(2)} \cdot \text{ReLU}(W_g^{(1)} [\mathbf{h} \oplus d] + b_g^{(1)}) + b_g^{(2)})
% \end{equation}

% The final FAIIA output with residual connection is:

% \begin{equation}
% \mathbf{z} = \text{LayerNorm}(\mathbf{g} \odot \mathbf{h} + \mathbf{x})
% \label{eq:faiia_final}
% \end{equation}

% where $\odot$ denotes element-wise multiplication.





% \PARstart{T}{his} document is a template for \LaTeX. If you are reading a paper or PDF version of this document, please download the LaTeX template or the MS Word
% template of your preferred publication from the IEEE Website at \underline
% {https://template-selector.ieee.org/secure/templateSelec}\break\underline{tor/publicationType} so you can use it to prepare your manuscript. 
% If you would prefer to use LaTeX, download IEEE's LaTeX style and sample files
% from the same Web page. You can also explore using the Overleaf editor at
% \underline
% {https://www.overleaf.com/blog/278-how-to-use-overleaf-}\break\underline{with-ieee-collabratec-your-quick-guide-to-getting-started}\break\underline{\#.xsVp6tpPkrKM9}

% IEEE will do the final formatting of your paper. If your paper is intended
% for a conference, please observe the conference page limits.





% The word ``data'' is plural, not singular. The subscript for the
% permeability of vacuum $\mu _{0}$ is zero, not a lowercase letter
% ``o.'' The term for residual magnetization is ``remanence''; the adjective
% is ``remanent''; do not write ``remnance'' or ``remnant.'' Use the word
% ``micrometer'' instead of ``micron.'' A graph within a graph is an
% ``inset,'' not an ``insert.'' The word ``alternatively'' is preferred to the
% word ``alternately'' (unless you really mean something that alternates). Use
% the word ``whereas'' instead of ``while'' (unless you are referring to
% simultaneous events). Do not use the word ``essentially'' to mean
% ``approximately'' or ``effectively.'' Do not use the word ``issue'' as a
% euphemism for ``problem.'' When compositions are not specified, separate
% chemical symbols by en-dashes; for example, ``NiMn'' indicates the
% intermetallic compound Ni$_{0.5}$Mn$_{0.5}$ whereas
% ``Ni--Mn'' indicates an alloy of some composition
% Ni$_{x}$Mn$_{1-x}$.

% Be aware of the different meanings of the homophones ``affect'' (usually a
% verb) and ``effect'' (usually a noun), ``complement'' and ``compliment,''
% ``discreet'' and ``discrete,'' ``principal'' (e.g., ``principal
% investigator'') and ``principle'' (e.g., ``principle of measurement''). Do
% not confuse ``imply'' and ``infer.''

% Prefixes such as ``non,'' ``sub,'' ``micro,'' ``multi,'' and ``ultra'' are
% not independent words; they should be joined to the words they modify,
% usually without a hyphen. There is no period after the ``et'' in the Latin
% abbreviation ``\emph{et al.}'' (it is also italicized). The abbreviation ``i.e.,'' means
% ``that is,'' and the abbreviation ``e.g.,'' means ``for example'' (these
% abbreviations are not italicized).

% A general IEEE styleguide is available at \break
% \underline{http://www.ieee.org/authortools}.





% \section{Methodology}
% \label{sec:method}

% This section presents the FAIIA (Focal-Aware Imbalance-Integrated Attention) mechanism 
% and the FAA-NET (Edge-Deployable Attention Network) architecture. We begin with problem 
% formulation, then detail each component of FAIIA, followed by the complete network 
% architecture and training procedure.

% \subsection{Problem Formulation}

% Given a dataset $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N$ where $\mathbf{x}_i 
% \in \mathbb{R}^d$ represents network flow features and $y_i \in \{0, 1\}$ denotes 
% class labels (0: normal, 1: attack), we aim to learn a classifier $f: \mathbb{R}^d 
% \to [0,1]$ that maximizes detection of minority attack classes while maintaining 
% acceptable false positive rates on majority normal traffic.

% The dataset exhibits severe class imbalance characterized by:
% \begin{equation}
% r = \frac{|\{i : y_i = 0\}|}{|\{i : y_i = 1\}|} \gg 1
% \end{equation}
% where $r$ represents the imbalance ratio. For UNSW-NB15, $r \approx 2.33$ overall, 
% but specific minority attack categories exhibit ratios exceeding 800:1 relative to 
% normal traffic.

% \textbf{Objective:} Design an attention mechanism that dynamically adjusts feature 
% importance based on predicted minority class probability, ensuring rare attack patterns 
% receive sufficient attention during both training and inference.

% \subsection{FAIIA: Focal-Aware Imbalance-Integrated Attention}


% FAIIA integrates class imbalance awareness into attention computation through three 
% synergistic components: focal modulation, prototype-based attention, and class-conditional 
% gating. We present each component in detail.

% \begin{algorithm}[t]
% \caption{FAIIA Forward Pass (Single Head)}
% \label{alg:faiia_forward}
% \small
% \begin{algorithmic}[1]
% \REQUIRE Input $\mathbf{x} \in \mathbb{R}^d$, prototypes $\mathbf{K}_p, \mathbf{V}_p \in \mathbb{R}^{M \times d_k}$, focal parameters $\alpha, \gamma$
% \ENSURE Attended output $\mathbf{z} \in \mathbb{R}^{d_k}$

% \STATE \textbf{Step 1: Probability Estimation}
% \STATE $p \gets \text{ProbabilityEstimator}(\mathbf{x})$ 
% \COMMENT{Eq.~(1)}

% \STATE \textbf{Step 2: Focal Modulation}
% \STATE $F(p) \gets \alpha \cdot (1-p+\epsilon)^\gamma \cdot \tau$ 
% \COMMENT{Eq.~(2)}

% \STATE \textbf{Step 3: Self-Feature Attention}
% \STATE $\mathbf{Q}, \mathbf{K}, \mathbf{V} \gets W_Q\mathbf{x}, W_K\mathbf{x}, W_V\mathbf{x}$ 
% \COMMENT{Eq.~(3)}
% \STATE $s_{\text{self}} \gets \langle \mathbf{Q}, \mathbf{K} \rangle$ 
% \COMMENT{Eq.~(4)}
% \STATE $\tilde{s}_{\text{self}} \gets F(p) \cdot s_{\text{self}}$ 
% \COMMENT{Apply focal modulation}
% \STATE $w_{\text{self}} \gets \sigma(\tilde{s}_{\text{self}} / \sqrt{d_k})$ 
% \COMMENT{Eq.~(5)}
% \STATE $\mathbf{A}_{\text{self}} \gets w_{\text{self}} \cdot \mathbf{V}$ 
% \COMMENT{Eq.~(6)}

% \STATE \textbf{Step 4: Prototype Attention}
% \STATE $\mathbf{s}_{\text{proto}} \gets \mathbf{Q} \mathbf{K}_p^T$ 
% \COMMENT{Eq.~(7)}
% \STATE $\tilde{\mathbf{s}}_{\text{proto}} \gets F(p) \cdot \mathbf{s}_{\text{proto}}$ 
% \COMMENT{Apply focal modulation}
% \STATE $\mathbf{w}_{\text{proto}} \gets \text{softmax}(\tilde{\mathbf{s}}_{\text{proto}} / \sqrt{d_k})$ 
% \COMMENT{Eq.~(8)}
% \STATE $\mathbf{A}_{\text{proto}} \gets \mathbf{w}_{\text{proto}} \mathbf{V}_p$ 
% \COMMENT{Eq.~(9)}

% \STATE \textbf{Step 5: Fusion and Output}
% \STATE $\mathbf{h} \gets W_o [\mathbf{A}_{\text{self}} \oplus \mathbf{A}_{\text{proto}}]$ 
% \COMMENT{Eq.~(10)}
% \STATE $\mathbf{h} \gets \text{LayerNorm}(\mathbf{h})$ 
% \COMMENT{Eq.~(11)}
% \STATE $d \gets 1 - 2|p - 0.5|$ 
% \COMMENT{Eq.~(12)}
% \STATE $\mathbf{g} \gets \text{GateNetwork}([\mathbf{h} \oplus d])$ 
% \COMMENT{Eq.~(13)}
% \STATE $\mathbf{z} \gets \mathbf{g} \odot \mathbf{h}$ 
% \COMMENT{Eq.~(14)}

% \STATE \RETURN $\mathbf{z}$
% \end{algorithmic}
% \end{algorithm}




% \subsubsection{Minority Probability Estimation}

% To enable class-aware attention modulation, we first estimate the minority class 
% probability for each input sample. An auxiliary probability estimator network computes:

% \begin{equation}
% p = \sigma\left(W_p^{(2)} \cdot \text{ReLU}\left(W_p^{(1)} \mathbf{x} + \mathbf{b}_p^{(1)}\right) + b_p^{(2)}\right)
% \label{eq:prob_estimation}
% \end{equation}

% where $\sigma(\cdot)$ is the sigmoid activation, $W_p^{(1)} \in \mathbb{R}^{64 \times d}$, 
% $W_p^{(2)} \in \mathbb{R}^{1 \times 64}$ are learnable weight matrices, and $p \in [0,1]$ 
% represents the predicted probability that $\mathbf{x}$ belongs to a minority attack class.

% This auxiliary estimator provides an early prediction signal that guides attention 
% modulation before final classification, enabling the model to adapt attention strength 
% based on predicted class membership.

% \subsubsection{Focal Modulation Function}

% The focal modulation function $F(p)$ scales attention scores based on minority class 
% uncertainty:

% \begin{equation}
% F(p; \alpha, \gamma) = \alpha \cdot (1 - p + \epsilon)^\gamma \cdot \tau
% \label{eq:focal_modulation}
% \end{equation}

% where:
% \begin{itemize}
%     \item $\alpha \in [0, 1]$ is the focal strength parameter controlling the degree 
%     of modulation (we use $\alpha = 0.60$ for minority-focused deployment)
%     \item $\gamma > 0$ is the focusing exponent determining modulation steepness (we use 
%     $\gamma = 2$, following the focal loss literature~\cite{lin2017focal})
%     \item $\tau$ is a learnable temperature parameter initialized to 1.0
%     \item $\epsilon = 10^{-8}$ ensures numerical stability
% \end{itemize}

% The term $(1-p)^\gamma$ implements the focal principle: when $p$ is high (confident 
% minority prediction), $F(p)$ is reduced, allowing standard attention. When $p$ is low 
% (likely majority class or uncertain), $F(p)$ is amplified, forcing increased scrutiny. 
% This design ensures attention strength adapts to predicted class membership rather than 
% treating all samples uniformly.

% \subsubsection{Self-Feature Attention with Focal Modulation}

% For tabular network flow data, we adapt the standard attention mechanism to operate on 
% feature vectors rather than sequences. Given input $\mathbf{x} \in \mathbb{R}^d$, we 
% compute query, key, and value projections:

% \begin{equation}
% \begin{aligned}
% \mathbf{Q} &= W_Q \mathbf{x} + \mathbf{b}_Q \\
% \mathbf{K} &= W_K \mathbf{x} + \mathbf{b}_K \\
% \mathbf{V} &= W_V \mathbf{x} + \mathbf{b}_V
% \end{aligned}
% \label{eq:qkv_projection}
% \end{equation}

% where $W_Q, W_K, W_V \in \mathbb{R}^{d_k \times d}$ project the input to attention 
% dimension $d_k$ (we use $d_k = 32$).

% The self-attention score is computed via element-wise similarity:

% \begin{equation}
% s_{\text{self}} = \sum_{i=1}^{d_k} \mathbf{Q}_i \cdot \mathbf{K}_i = \langle \mathbf{Q}, \mathbf{K} \rangle
% \label{eq:self_score}
% \end{equation}

% Applying focal modulation before normalization:

% \begin{equation}
% \tilde{s}_{\text{self}} = F(p) \cdot s_{\text{self}}
% \label{eq:focal_self_score}
% \end{equation}

% The focal-modulated attention weight is:

% \begin{equation}
% w_{\text{self}} = \sigma\left(\frac{\tilde{s}_{\text{self}}}{\sqrt{d_k}}\right)
% \label{eq:self_attention_weight}
% \end{equation}

% where $\sigma(\cdot)$ is the sigmoid function and $\sqrt{d_k}$ provides scale 
% normalization. The self-attended output is:

% \begin{equation}
% \mathbf{A}_{\text{self}} = w_{\text{self}} \cdot \mathbf{V}
% \label{eq:self_attended}
% \end{equation}

% \textbf{Rationale:} Unlike standard Transformer attention that computes attention across 
% sequence positions, our formulation treats each network flow as an independent sample 
% with fixed-length features. The element-wise similarity $\langle \mathbf{Q}, \mathbf{K} 
% \rangle$ measures feature-level compatibility, while focal modulation ensures minority-uncertain 
% samples receive amplified attention strength.

% \subsubsection{Prototype-Based Minority Attention}

% To ensure consistent representation of minority attack patterns regardless of batch 
% composition, we maintain $M$ learnable prototype embeddings:

% \begin{equation}
% \mathbf{K}_p, \mathbf{V}_p \in \mathbb{R}^{M \times d_k}
% \label{eq:prototypes}
% \end{equation}

% These prototypes are initialized via k-means clustering on minority class samples from 
% the training set, then fine-tuned end-to-end during training. We use $M = 8$ prototypes, 
% providing sufficient capacity to represent diverse minority attack patterns without 
% excessive parameterization.

% The prototype attention scores are computed as:

% \begin{equation}
% \mathbf{s}_{\text{proto}} = \mathbf{Q} \mathbf{K}_p^T \in \mathbb{R}^{M}
% \label{eq:proto_scores}
% \end{equation}

% Applying focal modulation by broadcasting $F(p)$ across all prototypes:

% \begin{equation}
% \tilde{\mathbf{s}}_{\text{proto}} = F(p) \cdot \mathbf{s}_{\text{proto}}
% \label{eq:focal_proto_scores}
% \end{equation}

% The prototype attention weights are normalized via softmax:

% \begin{equation}
% \mathbf{w}_{\text{proto}} = \text{softmax}\left(\frac{\tilde{\mathbf{s}}_{\text{proto}}}{\sqrt{d_k}}\right) \in \mathbb{R}^{M}
% \label{eq:proto_weights}
% \end{equation}

% The prototype-attended output aggregates information from all prototypes:

% \begin{equation}
% \mathbf{A}_{\text{proto}} = \mathbf{w}_{\text{proto}} \mathbf{V}_p = \sum_{j=1}^{M} w_{\text{proto},j} \mathbf{V}_{p,j}
% \label{eq:proto_attended}
% \end{equation}

% where $w_{\text{proto},j}$ and $\mathbf{V}_{p,j}$ denote the $j$-th prototype weight 
% and value vector respectively.

% \textbf{Rationale:} Prototype attention provides explicit memory of minority class 
% patterns. Even when minority samples are absent from a training batch (common in extreme 
% imbalance), prototypes ensure the model maintains sensitivity to rare attack signatures. 
% The softmax normalization over prototypes allows the model to focus on the most relevant 
% minority patterns for each input.

% \subsubsection{Attention Fusion}

% The self-attended and prototype-attended outputs are fused via concatenation and 
% projection:

% \begin{equation}
% \mathbf{h}_{\text{fused}} = W_o [\mathbf{A}_{\text{self}} \oplus \mathbf{A}_{\text{proto}}] + \mathbf{b}_o
% \label{eq:attention_fusion}
% \end{equation}

% where $\oplus$ denotes concatenation, $W_o \in \mathbb{R}^{d_k \times 2d_k}$ is the 
% output projection matrix, and $\mathbf{b}_o \in \mathbb{R}^{d_k}$ is the bias vector.

% Applying layer normalization:

% \begin{equation}
% \mathbf{h}_{\text{norm}} = \text{LayerNorm}(\mathbf{h}_{\text{fused}})
% \label{eq:attention_layernorm}
% \end{equation}

% \textbf{Design Choice:} We use concatenation rather than addition to preserve information 
% from both attention streams. The output projection $W_o$ learns how to optimally combine 
% self-attention (which may capture majority patterns) and prototype attention (which 
% focuses on minority patterns).

% \subsubsection{Class-Conditional Gating}

% To further refine attention outputs based on sample difficulty, we introduce a 
% class-conditional gate. The difficulty score measures distance from the decision boundary:

% \begin{equation}
% d = 1 - 2|p - 0.5|
% \label{eq:difficulty}
% \end{equation}

% where $d \in [0, 1]$ is maximized for samples near the decision boundary ($p \approx 0.5$) 
% and minimized for confident predictions ($p \approx 0$ or $p \approx 1$).

% The gate values are computed via a small fully-connected network:

% \begin{equation}
% \begin{aligned}
% \mathbf{g} &= \sigma\left(W_g^{(2)} \cdot \text{ReLU}\left(W_g^{(1)} [\mathbf{h}_{\text{norm}} \oplus d] + \mathbf{b}_g^{(1)}\right) + b_g^{(2)}\right)
% \end{aligned}
% \label{eq:gating}
% \end{equation}

% where $W_g^{(1)} \in \mathbb{R}^{(d_k/4) \times (d_k+1)}$, $W_g^{(2)} \in \mathbb{R}^{d_k \times (d_k/4)}$ 
% with reduction factor 4 to limit parameters.

% The final FAIIA output with gating is:

% \begin{equation}
% \mathbf{z}_{\text{FAIIA}} = \mathbf{g} \odot \mathbf{h}_{\text{norm}}
% \label{eq:gated_output}
% \end{equation}

% where $\odot$ denotes element-wise multiplication.

% \textbf{Rationale:} Difficult samples at class boundaries benefit from enhanced attention, 
% while easy samples require less processing. The gate adaptively modulates attention output 
% based on predicted difficulty, providing an additional mechanism for focusing computational 
% resources on challenging cases.

% \subsubsection{Complete FAIIA Formulation}

% Combining all components, a single FAIIA head computes:

% \begin{equation}
% \begin{aligned}
% \text{FAIIA}(\mathbf{x}, p) &= \mathbf{g} \odot \text{LN}\left(W_o \left[\underbrace{w_{\text{self}}(\mathbf{x},p) \cdot \mathbf{V}}_{\text{Self-Attention}} \oplus \underbrace{\mathbf{w}_{\text{proto}}(\mathbf{x},p) \mathbf{V}_p}_{\text{Prototype Attention}}\right]\right)
% \end{aligned}
% \label{eq:faiia_complete}
% \end{equation}

% where $w_{\text{self}}(\mathbf{x},p)$ and $\mathbf{w}_{\text{proto}}(\mathbf{x},p)$ 
% denote the focal-modulated attention weights from Equations~\ref{eq:self_attention_weight} 
% and~\ref{eq:proto_weights} respectively, and $\mathbf{g}$ is the class-conditional gate 
% from Equation~\ref{eq:gating}.

% \subsection{Multi-Head FAIIA}

% To capture diverse attention patterns, we employ $H$ parallel FAIIA heads with varying 
% focal strengths. Each head $i \in \{0, 1, \ldots, H-1\}$ uses a slightly different focal 
% parameter:

% \begin{equation}
% \alpha_i = \alpha_{\text{base}} \cdot (1 + 0.1 \cdot i)
% \label{eq:multihead_alpha}
% \end{equation}

% where $\alpha_{\text{base}}$ is the base focal strength (we use $\alpha_{\text{base}} = 0.60$). 
% This variation allows different heads to specialize: lower-$\alpha$ heads focus more 
% uniformly across samples, while higher-$\alpha$ heads strongly prioritize minority-uncertain 
% samples.

% The outputs from all heads are concatenated and projected:

% \begin{equation}
% \mathbf{h}_{\text{multi}} = W_{\text{final}} \left[\text{FAIIA}_0 \oplus \text{FAIIA}_1 \oplus \cdots \oplus \text{FAIIA}_{H-1}\right] + \mathbf{b}_{\text{final}}
% \label{eq:multihead_fusion}
% \end{equation}

% where $W_{\text{final}} \in \mathbb{R}^{d \times (H \cdot d_k)}$ projects back to the 
% original input dimension $d$.

% A residual connection and layer normalization provide stable gradient flow:

% \begin{equation}
% \mathbf{z}_{\text{multi}} = \text{LayerNorm}(\mathbf{h}_{\text{multi}} + \mathbf{x})
% \label{eq:multihead_residual}
% \end{equation}

% We use $H = 4$ heads with $d_k = 32$, providing 128-dimensional intermediate representation 
% per sample.

% \subsection{FAA-NET Architecture}

% The complete FAA-NET (Edge-Deployable Attention Network) architecture integrates FAIIA 
% within a lightweight network designed for resource-constrained deployment. Figure~\ref{fig:architecture} 
% illustrates the complete architecture.

% \subsubsection{Input Processing}

% Input network flow features undergo batch normalization:

% \begin{equation}
% \tilde{\mathbf{x}} = \text{BatchNorm}(\mathbf{x})
% \label{eq:input_norm}
% \end{equation}

% This normalization stabilizes training and ensures features are on comparable scales 
% before attention computation.

% \subsubsection{Probability Estimation and FAIIA}

% The normalized input $\tilde{\mathbf{x}}$ is processed by the probability estimator 
% (Equation~\ref{eq:prob_estimation}) to obtain $p$, which then guides FAIIA modulation. 
% The multi-head FAIIA (Equation~\ref{eq:multihead_residual}) produces attended features 
% $\mathbf{z}_{\text{multi}}$.

% \subsubsection{Squeeze-and-Excitation Block}

% To further recalibrate features based on channel-wise importance, we apply a 
% Squeeze-and-Excitation (SE) block:

% \begin{equation}
% \begin{aligned}
% \mathbf{s}_{\text{SE}} &= \text{GlobalAvgPool}(\mathbf{z}_{\text{multi}}) = \mathbf{z}_{\text{multi}} \\
% \mathbf{w}_{\text{SE}} &= \sigma\left(W_{\text{SE}}^{(2)} \cdot \text{ReLU}\left(W_{\text{SE}}^{(1)} \mathbf{s}_{\text{SE}} + \mathbf{b}_{\text{SE}}^{(1)}\right) + b_{\text{SE}}^{(2)}\right) \\
% \mathbf{z}_{\text{SE}} &= \mathbf{w}_{\text{SE}} \odot \mathbf{z}_{\text{multi}}
% \end{aligned}
% \label{eq:se_block}
% \end{equation}

% where $W_{\text{SE}}^{(1)} \in \mathbb{R}^{(d/4) \times d}$ and $W_{\text{SE}}^{(2)} \in \mathbb{R}^{d \times (d/4)}$ 
% implement a bottleneck architecture with reduction ratio 4.

% \subsubsection{Hidden Layers with Residual Connections}

% The SE-recalibrated features pass through a sequence of fully-connected blocks with 
% residual connections. For hidden dimensions $[256, 128, 64]$, each block $\ell$ computes:

% \begin{equation}
% \begin{aligned}
% \mathbf{h}_{\ell}^{\text{pre}} &= W_{\ell} \mathbf{h}_{\ell-1} + \mathbf{b}_{\ell} \\
% \mathbf{h}_{\ell}^{\text{norm}} &= \text{BatchNorm}(\mathbf{h}_{\ell}^{\text{pre}}) \\
% \mathbf{h}_{\ell}^{\text{act}} &= \text{GELU}(\mathbf{h}_{\ell}^{\text{norm}}) \\
% \mathbf{h}_{\ell}^{\text{drop}} &= \text{Dropout}(\mathbf{h}_{\ell}^{\text{act}}, p=0.3) \\
% \mathbf{h}_{\ell} &= \mathbf{h}_{\ell}^{\text{drop}} + \text{Project}(\mathbf{h}_{\ell-1})
% \end{aligned}
% \label{eq:hidden_block}
% \end{equation}

% where $\text{Project}(\cdot)$ is a linear projection if dimensions differ, or identity 
% otherwise. GELU (Gaussian Error Linear Unit) activation provides smooth, non-monotonic 
% non-linearity beneficial for deep networks.

% \subsubsection{Classification Head}

% The final classifier maps from the last hidden dimension (64) to output probability:

% \begin{equation}
% \begin{aligned}
% \mathbf{h}_{\text{cls}} &= \text{GELU}(W_{\text{cls}}^{(1)} \mathbf{h}_L + \mathbf{b}_{\text{cls}}^{(1)}) \\
% \mathbf{h}_{\text{cls}}^{\text{drop}} &= \text{Dropout}(\mathbf{h}_{\text{cls}}, p=0.15) \\
% \hat{y} &= \sigma(W_{\text{cls}}^{(2)} \mathbf{h}_{\text{cls}}^{\text{drop}} + b_{\text{cls}}^{(2)})
% \end{aligned}
% \label{eq:classifier}
% \end{equation}

% where $W_{\text{cls}}^{(1)} \in \mathbb{R}^{32 \times 64}$, $W_{\text{cls}}^{(2)} \in \mathbb{R}^{1 \times 32}$, 
% and $\hat{y} \in [0,1]$ represents the predicted attack probability.

% \subsection{Training Procedure}

% \subsubsection{Prototype Initialization}

% Before training, minority class prototypes $\mathbf{K}_p, \mathbf{V}_p$ are initialized 
% via k-means clustering:

% \begin{enumerate}
%     \item Extract all minority attack samples: $\mathcal{X}_{\text{minority}} = \{\mathbf{x}_i : y_i = 1, i \in \mathcal{D}_{\text{train}}\}$
%     \item Apply k-means with $k = M$ to obtain cluster centers: $\{\mathbf{c}_1, \ldots, \mathbf{c}_M\}$
%     \item Initialize prototype keys and values:
%     \begin{equation}
%     \begin{aligned}
%     \mathbf{K}_{p,j} &= W_K \mathbf{c}_j \\
%     \mathbf{V}_{p,j} &= W_V \mathbf{c}_j
%     \end{aligned}
%     \end{equation}
%     for $j = 1, \ldots, M$
% \end{enumerate}

% These initialized prototypes are then fine-tuned during training via backpropagation.

% \subsubsection{Imbalance-Aware Focal Loss}

% To complement the architectural imbalance handling, we employ an imbalance-aware focal 
% loss function:

% \begin{equation}
% \mathcal{L}_{\text{focal}} = -\frac{1}{N} \sum_{i=1}^N \left[\alpha_t^{(i)} \left(1 - p_t^{(i)}\right)^\gamma \log\left(p_t^{(i)}\right)\right]
% \label{eq:focal_loss}
% \end{equation}

% where:
% \begin{equation}
% \begin{aligned}
% p_t^{(i)} &= \begin{cases}
% \hat{y}_i & \text{if } y_i = 1 \\
% 1 - \hat{y}_i & \text{if } y_i = 0
% \end{cases} \\
% \alpha_t^{(i)} &= \begin{cases}
% \alpha_{\text{pos}} & \text{if } y_i = 1 \\
% \alpha_{\text{neg}} & \text{if } y_i = 0
% \end{cases}
% \end{aligned}
% \label{eq:focal_loss_components}
% \end{equation}

% The class weights are computed based on class frequencies:

% \begin{equation}
% \alpha_{\text{pos}} = \frac{N}{2 N_{\text{pos}}}, \quad \alpha_{\text{neg}} = \frac{N}{2 N_{\text{neg}}}
% \label{eq:class_weights}
% \end{equation}

% where $N_{\text{pos}}$ and $N_{\text{neg}}$ are the number of positive (attack) and 
% negative (normal) samples respectively.

% \textbf{Rationale:} While FAIIA addresses imbalance at the attention level, focal loss 
% provides complementary benefits at the optimization level by down-weighting well-classified 
% examples. The combination ensures imbalance awareness throughout the model.

% \subsubsection{Optimization}

% The model is trained using Adam optimizer with the following hyperparameters:

% \begin{itemize}
%     \item Learning rate: $\eta = 10^{-3}$ with cosine annealing schedule
%     \item Weight decay: $\lambda = 10^{-4}$ for L2 regularization
%     \item Batch size: 512
%     \item Epochs: 100 with early stopping (patience = 15)
%     \item Gradient clipping: $\|\nabla\| \leq 1.0$ to prevent exploding gradients
% \end{itemize}

% The learning rate schedule follows:

% \begin{equation}
% \eta_t = \eta_{\text{min}} + \frac{1}{2}(\eta_{\text{max}} - \eta_{\text{min}})\left(1 + \cos\left(\frac{t}{T}\pi\right)\right)
% \label{eq:cosine_schedule}
% \end{equation}

% where $t$ is the current epoch, $T$ is the total number of epochs, $\eta_{\text{max}} = 10^{-3}$, 
% and $\eta_{\text{min}} = 10^{-6}$.

% \subsection{Model Complexity Analysis}

% The total number of trainable parameters in FAA-NET is:

% \begin{equation}
% \begin{aligned}
% \Theta &= \underbrace{64d + 64 + 64 + 1}_{\text{Prob. Estimator}} + \underbrace{H \cdot (3d \cdot d_k + 2M \cdot d_k + 2d_k^2)}_{\text{Multi-Head FAIIA}} \\
% &\quad + \underbrace{d \cdot d/4 + d/4 \cdot d}_{\text{SE Block}} + \underbrace{\sum_{\ell} h_{\ell} h_{\ell-1}}_{\text{Hidden Layers}} + \underbrace{64 \cdot 32 + 32}_{\text{Classifier}}
% \end{aligned}
% \label{eq:parameters}
% \end{equation}

% For our configuration ($d=196$, $H=4$, $d_k=32$, $M=8$, hidden=$[256, 128, 64]$), this 
% yields approximately 134,221 parameters—orders of magnitude smaller than typical deep 
% learning models for intrusion detection, enabling deployment on resource-constrained 
% edge devices.

% Computational complexity per forward pass is:

% \begin{equation}
% \mathcal{O}(d \cdot d_k \cdot H + M \cdot d_k \cdot H + \sum_{\ell} h_{\ell} h_{\ell-1})
% \label{eq:complexity}
% \end{equation}

% dominated by the multi-head attention ($\mathcal{O}(d \cdot d_k \cdot H)$) and hidden 
% layers, but still highly efficient compared to transformer-based architectures with 
% $\mathcal{O}(L^2 \cdot d)$ complexity for sequence length $L$.

% \subsection{Deployment Considerations}

% \subsubsection{Tunable Security Parameter}

% The focal strength $\alpha$ serves as a deployment-configurable security parameter:

% \begin{itemize}
%     \item \textbf{Balanced Mode} ($\alpha = 0.5$): Optimizes F1-score, suitable for general-purpose NIDS
%     \item \textbf{High-Security Mode} ($\alpha = 0.6$--$0.7$): Maximizes attack recall, suitable for critical infrastructure
%     \item \textbf{Low False Positive Mode} ($\alpha = 0.3$--$0.4$): Prioritizes precision, suitable for high-traffic networks
% \end{itemize}

% Organizations can select $\alpha$ based on their specific risk tolerance and operational 
% constraints without retraining the model—only the focal modulation strength changes.

% \subsubsection{Inference Optimization}

% For real-time deployment, several optimizations can be applied:

% \begin{enumerate}
%     \item \textbf{Batch Processing:} Process multiple flows simultaneously to amortize 
%     GPU overhead
%     \item \textbf{Quantization:} Convert weights to INT8 for 4× memory reduction with 
%     minimal accuracy loss
%     \item \textbf{Prototype Caching:} Precompute $\mathbf{K}_p$ projections since they 
%     remain constant during inference
%     \item \textbf{Early Exit:} For high-confidence predictions ($p < 0.1$ or $p > 0.9$), 
%     skip deeper layers
% \end{enumerate}

% These optimizations enable sub-millisecond inference latency on standard CPUs, making 
% FAA-NET suitable for high-throughput network monitoring.



% Context for Writing My Research Paper

% You are assisting in writing an academic research paper in network intrusion detection systems (NIDS) with a focus on class imbalance and minority attack detection.

% Paper Status

% Abstract, Introduction, and Related Work are already written

% You will help write and refine the remaining sections in a formal IEEE/Elsevier-style academic tone

% Avoid marketing language; be precise, cautious, and reviewer-aware

% Problem Setting

% Task: Binary intrusion detection (Attack vs Normal)

% Dataset: UNSW-NB15–style multi-attack dataset

% Strong class imbalance, especially at the per-attack level (some attacks have < 500 samples)

% Minority attack detection is the primary objective

% Proposed Model

% Model name: FAA-NET with FAIIA (Focal-Aware Imbalance-Integrated Attention)

% Architecture:

% Vanilla DNN backbone

% FAIIA modifies attention scores using:

% A focal-based modulation term derived from predicted minority probability

% Learned minority class prototypes integrated into attention computation

% Key novelty:

% Class imbalance is addressed inside the attention mechanism, not only via the loss function

% Unlike prior work, focal concepts are embedded directly into attention weighting






% \section{Methodology}
% \label{sec:methodology}

% This section presents the proposed FAA-NET architecture with Focal-Aware Imbalance-Integrated Attention (FAIIA). We first formulate the intrusion detection problem under class imbalance, then detail the FAIIA mechanism's design, and finally describe the complete architecture and training procedure.

% \subsection{Problem Formulation}

% Network intrusion detection is formulated as a binary classification task where a model $f: \mathbb{R}^d \rightarrow [0,1]$ maps $d$-dimensional network flow features $\mathbf{x} \in \mathbb{R}^d$ to attack probability $p \in [0,1]$. The training dataset $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N$ contains $N$ labeled samples where $y_i \in \{0, 1\}$ indicates normal traffic ($y=0$) or attack traffic ($y=1$).

% The dataset exhibits severe class imbalance at two levels. At the binary level, the imbalance ratio $r = N_{\text{attack}} / N_{\text{normal}}$ varies substantially between training ($r_{\text{train}} = 0.469$) and testing ($r_{\text{test}} = 0.816$) partitions, reflecting realistic deployment scenarios where attack prevalence fluctuates over time. At the granular level, individual attack categories range from 44 samples (Worms) to over 40,000 samples (Generic), creating extreme within-class imbalance that conventional balancing techniques fail to address.

% Standard cross-entropy loss $\mathcal{L}_{\text{CE}} = -y \log(p) - (1-y) \log(1-p)$ assigns equal learning emphasis to all samples, causing gradient-based optimization to prioritize majority classes. This majority bias manifests in attention mechanisms as well: when computing attention weights $\alpha_i = \text{softmax}(\text{score}_i)$, features frequently co-occurring with majority classes receive disproportionate attention scores, while minority-characteristic features are suppressed.

% \subsection{Focal-Aware Imbalance-Integrated Attention (FAIIA)}

% The core innovation of FAIIA is the integration of focal modulation directly into attention score computation rather than applying imbalance adjustments solely at the loss function level. This architectural integration enables instance-level adaptive attention that complements loss-level class weighting.

% \subsubsection{Focal Modulation of Attention Scores}

% Given input features $\mathbf{x} \in \mathbb{R}^d$, we first obtain an initial minority-class probability estimate $p_{\text{init}} \in [0,1]$ via a lightweight probability estimator:
% \begin{equation}
% p_{\text{init}} = \sigma(W_p \cdot \text{ReLU}(W_e \mathbf{x} + b_e) + b_p)
% \end{equation}
% where $W_e \in \mathbb{R}^{64 \times d}$ and $W_p \in \mathbb{R}^{1 \times 64}$ are learned projection matrices, $b_e$ and $b_p$ are bias terms, and $\sigma(\cdot)$ denotes the sigmoid activation.

% This initial probability guides focal modulation throughout the attention mechanism. For each attention head, we compute query, key, and value projections:
% \begin{align}
% \mathbf{q} &= W_Q \mathbf{x} + b_Q \\
% \mathbf{k} &= W_K \mathbf{x} + b_K \\
% \mathbf{v} &= W_V \mathbf{x} + b_V
% \end{align}
% where $W_Q, W_K, W_V \in \mathbb{R}^{d_a \times d}$ project to attention dimension $d_a = 32$.

% The self-attention score is computed as:
% \begin{equation}
% s_{\text{self}} = \mathbf{q}^T \mathbf{k}
% \end{equation}

% Before applying softmax normalization, we modulate the attention score with a focal term derived from the minority-class probability:
% \begin{equation}
% s_{\text{focal}} = s_{\text{self}} \cdot \left(1 + \alpha \cdot (1 - p_{\text{init}} + \epsilon)^\gamma \cdot \tau \right)
% \label{eq:focal_modulation}
% \end{equation}
% where $\alpha$ is a learnable weighting parameter initialized to 0.60, $\gamma = 2.0$ controls the modulation strength, $\epsilon = 10^{-8}$ prevents numerical instability, and $\tau$ is a learnable temperature parameter initialized to 1.0. The term $(1 - p_{\text{init}})^\gamma$ amplifies attention for samples with low initial minority probability (likely majority-class or hard negatives), while $\alpha$ and $\tau$ allow the model to adapt the modulation magnitude during training.

% The attention weight is then normalized:
% \begin{equation}
% \alpha_{\text{self}} = \text{softmax}\left(\frac{s_{\text{focal}}}{\sqrt{d_a}}\right)
% \end{equation}
% where the scaling factor $1/\sqrt{d_a}$ stabilizes gradients following standard practice~\cite{vaswani2017attention}.

% \subsubsection{Prototype-Based Minority Attention}

% To explicitly capture minority-class patterns, FAIIA maintains a set of $K=8$ learnable prototype embeddings $\{\mathbf{p}_1, \ldots, \mathbf{p}_K\}$ where $\mathbf{p}_j \in \mathbb{R}^{d_a}$. These prototypes are initialized via K-means clustering on minority-class training samples, ensuring they represent diverse attack patterns at initialization.

% For each prototype, we compute corresponding key and value representations:
% \begin{align}
% \mathbf{k}_j^{\text{proto}} &= W_K^{\text{proto}} \mathbf{p}_j + b_K^{\text{proto}} \\
% \mathbf{v}_j^{\text{proto}} &= W_V^{\text{proto}} \mathbf{p}_j + b_V^{\text{proto}}
% \end{align}

% The prototype attention scores are computed via query-prototype similarity:
% \begin{equation}
% s_j^{\text{proto}} = \mathbf{q}^T \mathbf{k}_j^{\text{proto}}, \quad j = 1, \ldots, K
% \end{equation}

% These scores undergo the same focal modulation as self-attention:
% \begin{equation}
% s_j^{\text{focal-proto}} = s_j^{\text{proto}} \cdot \left(1 + \alpha \cdot (1 - p_{\text{init}} + \epsilon)^\gamma \cdot \tau \right)
% \end{equation}

% The prototype attention weights incorporate both the modulated scores and learnable prototype importance weights $\boldsymbol{\lambda} = [\lambda_1, \ldots, \lambda_K]^T$:
% \begin{equation}
% \alpha_j^{\text{proto}} = \text{softmax}\left(\frac{s_j^{\text{focal-proto}}}{\sqrt{d_a}}\right) \cdot \text{softmax}(\lambda_j)
% \end{equation}

% The prototype importance weights $\boldsymbol{\lambda}$ allow the model to learn which prototypes are most discriminative for intrusion detection, dynamically emphasizing or suppressing individual prototypes during inference.

% The attended prototype representation aggregates prototype values weighted by attention:
% \begin{equation}
% \mathbf{h}^{\text{proto}} = \sum_{j=1}^K \alpha_j^{\text{proto}} \mathbf{v}_j^{\text{proto}}
% \end{equation}

% \subsubsection{Multi-Head FAIIA and Output Integration}

% To capture diverse attention patterns, FAIIA employs $H=4$ attention heads, each with independent parameters. For head $h \in \{1, \ldots, H\}$, we compute self-attended and prototype-attended representations $\mathbf{h}_h^{\text{self}}$ and $\mathbf{h}_h^{\text{proto}}$ following the procedure above. Each head uses a slightly perturbed focal parameter $\alpha_h = \alpha \cdot (1 + 0.1 \cdot h)$ to encourage diversity in attention patterns.

% The outputs from each head are concatenated and projected:
% \begin{equation}
% \mathbf{h}_h = W_O^h \left[\mathbf{h}_h^{\text{self}} \oplus \mathbf{h}_h^{\text{proto}}\right] + b_O^h
% \end{equation}
% where $\oplus$ denotes concatenation and $W_O^h \in \mathbb{R}^{d_a \times 2d_a}$ projects back to attention dimension.

% The multi-head outputs are combined via learned head weights $\boldsymbol{\beta} = [\beta_1, \ldots, \beta_H]^T$:
% \begin{equation}
% \mathbf{h}^{\text{multi}} = W_{\text{final}} \left[\mathbf{h}_1 \oplus \cdots \oplus \mathbf{h}_H\right]
% \end{equation}
% where $W_{\text{final}} \in \mathbb{R}^{d \times Hd_a}$ projects to the original feature dimension $d$.

% \subsubsection{Class-Conditional Gating}

% To refine the attended features based on prediction difficulty, we employ a class-conditional gating mechanism. The gate takes as input both the attended features and a difficulty score derived from the initial probability:
% \begin{equation}
% \mathbf{g} = \sigma\left(W_{g2} \cdot \text{ReLU}\left(W_{g1} \left[\mathbf{h}^{\text{multi}} \oplus d_{\text{conf}}\right] + b_{g1}\right) + b_{g2}\right)
% \end{equation}
% where $d_{\text{conf}} = 1 - 2|p_{\text{init}} - 0.5|$ measures prediction uncertainty (low values indicate high confidence, high values indicate ambiguous samples), and $W_{g1} \in \mathbb{R}^{d/4 \times (d+1)}$, $W_{g2} \in \mathbb{R}^{d \times d/4}$ implement a two-layer gating network.

% The gated output is computed element-wise:
% \begin{equation}
% \mathbf{h}^{\text{gated}} = \mathbf{h}^{\text{multi}} \odot \mathbf{g}
% \end{equation}
% where $\odot$ denotes element-wise multiplication.

% Finally, a residual connection and layer normalization stabilize training:
% \begin{equation}
% \mathbf{h}^{\text{FAIIA}} = \text{LayerNorm}(\mathbf{h}^{\text{gated}} + \mathbf{x})
% \end{equation}

% \subsection{Complete FAA-NET Architecture}

% The complete FAA-NET model integrates FAIIA into a deep neural architecture designed for edge deployment. Figure~\ref{fig:architecture} illustrates the overall pipeline.

% \subsubsection{Input Normalization and Initial Processing}

% Input features $\mathbf{x} \in \mathbb{R}^{33}$ undergo batch normalization to stabilize training:
% \begin{equation}
% \mathbf{x}^{\text{norm}} = \text{BatchNorm}(\mathbf{x})
% \end{equation}

% The normalized features are processed by the probability estimator (Equation 1) to obtain $p_{\text{init}}$, which guides FAIIA's focal modulation.

% \subsubsection{FAIIA Layer}

% The FAIIA mechanism (Section III-B) transforms the normalized features:
% \begin{equation}
% \mathbf{h}^{\text{FAIIA}} = \text{FAIIA}(\mathbf{x}^{\text{norm}}, p_{\text{init}})
% \end{equation}

% \subsubsection{Squeeze-and-Excitation Refinement}

% A Squeeze-and-Excitation (SE) block~\cite{hu2018squeeze} recalibrates channel-wise feature importance:
% \begin{align}
% \mathbf{z} &= W_{se2} \cdot \text{ReLU}(W_{se1} \mathbf{h}^{\text{FAIIA}} + b_{se1}) + b_{se2} \\
% \mathbf{s} &= \sigma(\mathbf{z}) \\
% \mathbf{h}^{\text{SE}} &= \mathbf{h}^{\text{FAIIA}} \odot \mathbf{s}
% \end{align}
% where $W_{se1} \in \mathbb{R}^{d/4 \times d}$ and $W_{se2} \in \mathbb{R}^{d \times d/4}$ implement the squeeze-excitation transformation.

% \subsubsection{Residual Hidden Blocks}

% The SE-refined features pass through three residual blocks with progressively decreasing dimensions [256, 128, 64]:
% \begin{equation}
% \mathbf{h}^{(l+1)} = \text{Block}^{(l)}(\mathbf{h}^{(l)}) + W_{\text{res}}^{(l)} \mathbf{h}^{(l)}
% \end{equation}
% where each block consists of:
% \begin{equation}
% \text{Block}^{(l)}(\mathbf{h}) = \text{Dropout}(\text{GELU}(\text{BatchNorm}(W^{(l)} \mathbf{h} + b^{(l)})))
% \end{equation}
% with dropout rate 0.3. The residual projection $W_{\text{res}}^{(l)}$ matches dimensions when necessary.

% \subsubsection{Classification Head}

% The final hidden representation $\mathbf{h}^{(3)} \in \mathbb{R}^{64}$ is mapped to logits via a two-layer classifier:
% \begin{align}
% \mathbf{h}^{\text{cls}} &= \text{Dropout}(\text{GELU}(W_{cls1} \mathbf{h}^{(3)} + b_{cls1})) \\
% z &= W_{cls2} \mathbf{h}^{\text{cls}} + b_{cls2}
% \end{align}
% where $W_{cls1} \in \mathbb{R}^{32 \times 64}$, $W_{cls2} \in \mathbb{R}^{1 \times 32}$, and $z \in \mathbb{R}$ represents the raw logit.

% During training, logits are used directly with a logit-compatible loss function. During inference, predictions are obtained via:
% \begin{equation}
% \hat{y} = \mathbb{1}[\sigma(z) > \theta]
% \end{equation}
% where $\theta = 0.5$ is the decision threshold and $\mathbb{1}[\cdot]$ is the indicator function.

% \subsection{Loss Function and Optimization}

% To address class imbalance at the loss level, we employ an imbalance-aware focal loss~\cite{lin2017focal} adapted for binary classification with logits:
% \begin{equation}
% \mathcal{L}_{\text{focal}}(z, y) = -\alpha_t (1 - p_t)^\gamma \mathcal{L}_{\text{BCE}}(z, y)
% \label{eq:focal_loss}
% \end{equation}
% where $\mathcal{L}_{\text{BCE}}(z, y) = y \log \sigma(z) + (1-y) \log(1 - \sigma(z))$ is the binary cross-entropy computed from logits, $p_t = y \sigma(z) + (1-y)(1 - \sigma(z))$ is the probability of the ground truth class, and $\gamma = 2.0$ controls down-weighting of easy examples.

% The class-specific weighting $\alpha_t$ is computed automatically from training class frequencies:
% \begin{equation}
% \alpha_t = \begin{cases}
% \frac{N}{2N_{\text{attack}}} & \text{if } y = 1 \\
% \frac{N}{2N_{\text{normal}}} & \text{if } y = 0
% \end{cases}
% \end{equation}
% where $N = N_{\text{attack}} + N_{\text{normal}}$ is the total training set size. This formulation ensures that minority classes receive proportionally higher loss contribution while maintaining balanced gradient magnitudes.

% Label smoothing~\cite{szegedy2016rethinking} is applied to prevent overconfidence:
% \begin{equation}
% \tilde{y} = y(1 - \epsilon) + 0.5\epsilon
% \end{equation}
% where $\epsilon = 0.05$ is the smoothing parameter.

% The model is optimized using AdamW~\cite{loshchilov2019decoupled} with learning rate $\eta = 0.001$, weight decay $\lambda = 10^{-4}$, and default momentum parameters $\beta_1 = 0.9$, $\beta_2 = 0.999$. A cosine annealing warm restart scheduler modulates the learning rate:
% \begin{equation}
% \eta_t = \eta_{\min} + \frac{1}{2}(\eta_0 - \eta_{\min})\left(1 + \cos\left(\frac{T_{\text{cur}}}{T_0} \pi\right)\right)
% \end{equation}
% where $T_{\text{cur}}$ is the current epoch within a restart cycle, $T_0 = 15$ is the initial restart period, and $\eta_{\min} = 10^{-6}$ is the minimum learning rate. The restart period doubles after each cycle ($T_{\text{mult}} = 2$).

% Gradient clipping with maximum norm 1.0 prevents exploding gradients during training:
% \begin{equation}
% \mathbf{g}_{\text{clip}} = \min\left(1.0, \frac{1.0}{\|\mathbf{g}\|_2}\right) \mathbf{g}
% \end{equation}
% where $\mathbf{g}$ represents the gradient vector.

% \subsection{Minority Prototype Initialization}

% The prototype embeddings $\{\mathbf{p}_1, \ldots, \mathbf{p}_K\}$ are initialized via K-means clustering on attack-class training samples before model training. Specifically, we extract all attack samples $\mathcal{X}_{\text{attack}} = \{\mathbf{x}_i : y_i = 1\}$ from the training set and apply K-means with $K=8$ clusters:
% \begin{equation}
% \{\mathbf{c}_1, \ldots, \mathbf{c}_K\} = \arg\min_{\{\mathbf{c}_j\}} \sum_{i=1}^{|\mathcal{X}_{\text{attack}}|} \min_{j} \|\mathbf{x}_i - \mathbf{c}_j\|_2^2
% \end{equation}

% The cluster centroids $\{\mathbf{c}_j\}$ are then projected to the attention dimension:
% \begin{equation}
% \mathbf{p}_j^{\text{init}} = W_K^{\text{proto}} \mathbf{c}_j + b_K^{\text{proto}}
% \end{equation}

% This initialization ensures that prototypes represent diverse attack patterns at the start of training, while subsequent gradient updates allow them to specialize further based on discriminative utility.

% \subsection{Training Procedure}

% The complete training procedure is summarized in Algorithm~\ref{alg:training}.

% \begin{algorithm}[t]
% \caption{FAA-NET Training Procedure}
% \label{alg:training}
% \begin{algorithmic}[1]
% \REQUIRE Training set $\mathcal{D}_{\text{train}}$, validation set $\mathcal{D}_{\text{val}}$, hyperparameters
% \ENSURE Trained model $f_\theta$
% \STATE Initialize model parameters $\theta$ randomly
% \STATE Extract attack samples $\mathcal{X}_{\text{attack}}$ from $\mathcal{D}_{\text{train}}$
% \STATE Compute prototype centroids via K-means on $\mathcal{X}_{\text{attack}}$
% \STATE Initialize FAIIA prototypes with projected centroids
% \STATE $\text{best\_f1} \gets 0$, $\text{patience\_counter} \gets 0$
% \FOR{$\text{epoch} = 1$ to $150$}
%     \FOR{each mini-batch $\mathcal{B} \subset \mathcal{D}_{\text{train}}$}
%         \STATE Compute logits $\{z_i\}$ and initial probabilities $\{p_{\text{init}, i}\}$ for batch
%         \STATE Apply label smoothing: $\tilde{y}_i \gets y_i(1-\epsilon) + 0.5\epsilon$
%         \STATE Compute focal loss: $\mathcal{L} \gets \frac{1}{|\mathcal{B}|} \sum_{i} \mathcal{L}_{\text{focal}}(z_i, \tilde{y}_i)$
%         \STATE Compute gradients: $\mathbf{g} \gets \nabla_\theta \mathcal{L}$
%         \STATE Clip gradients: $\mathbf{g} \gets \text{clip}(\mathbf{g}, 1.0)$
%         \STATE Update parameters: $\theta \gets \text{AdamW}(\theta, \mathbf{g})$
%     \ENDFOR
%     \STATE Update learning rate via cosine annealing scheduler
%     \STATE Evaluate F1-score on $\mathcal{D}_{\text{val}}$: $\text{val\_f1}$
%     \IF{$\text{val\_f1} > \text{best\_f1}$}
%         \STATE $\text{best\_f1} \gets \text{val\_f1}$
%         \STATE Save model checkpoint
%         \STATE $\text{patience\_counter} \gets 0$
%     \ELSE
%         \STATE $\text{patience\_counter} \gets \text{patience\_counter} + 1$
%     \ENDIF
%     \IF{$\text{patience\_counter} \geq 20$}
%         \STATE \textbf{break} \COMMENT{Early stopping}
%     \ENDIF
% \ENDFOR
% \STATE Restore best model checkpoint
% \RETURN $f_\theta$
% \end{algorithmic}
% \end{algorithm}

% Training typically converges within 60-90 epochs due to early stopping. The model with the highest validation F1-score is retained for final evaluation. All experiments use mini-batch size of 256 and random seed 42 for reproducibility across PyTorch, NumPy, and scikit-learn operations.





% \section{Methodology}
% \label{sec:methodology}

% This section presents the proposed FAA-NET architecture with Focal-Aware Imbalance-Integrated Attention (FAIIA). We first describe the data preprocessing pipeline, then formulate the intrusion detection problem under class imbalance, detail the FAIIA mechanism's design, and finally describe the complete architecture and training procedure.

% \subsection{Data Preprocessing Pipeline}

% The UNSW-NB15 dataset requires systematic preprocessing to handle heterogeneous feature types, missing values, and numerical instabilities. Algorithm~\ref{alg:preprocessing} summarizes the complete pipeline, which is applied consistently to both training and testing partitions.

% % \begin{algorithm}[!h]
% % \caption{Data Preprocessing Pipeline}
% % \label{alg:preprocessing}
% % \begin{algorithmic}[1]
% % \REQUIRE Raw datasets $\mathcal{D}_{\text{train}}^{\text{raw}}$, $\mathcal{D}_{\text{test}}^{\text{raw}}$
% % \ENSURE Preprocessed features and labels: $X_{\text{train}}, y_{\text{train}}, X_{\text{test}}, y_{\text{test}}$

% % \STATE \textbf{// Data Cleaning}
% % \FOR{$\mathcal{D} \in \{\mathcal{D}_{\text{train}}^{\text{raw}}, \mathcal{D}_{\text{test}}^{\text{raw}}\}$}
% %     \STATE Remove \texttt{id} column
% %     \STATE Replace missing \texttt{service} values: `\texttt{-}' $\rightarrow$ `\texttt{none}'
% %     \FOR{each numeric feature $f$}
% %         \STATE Replace $\pm\infty \rightarrow \texttt{NaN}$
% %         \STATE Impute \texttt{NaN} with median($f$)
% %     \ENDFOR
% % \ENDFOR

% % \STATE \textbf{// Categorical Encoding}
% % \STATE Combine: $\mathcal{D}_{\text{all}} \gets \mathcal{D}_{\text{train}}^{\text{raw}} \cup \mathcal{D}_{\text{test}}^{\text{raw}}$
% % \FOR{$f \in \{\texttt{proto}, \texttt{service}, \texttt{state}\}$}
% %     \STATE Fit LabelEncoder on $\mathcal{D}_{\text{all}}[f]$
% %     \STATE Encode $\mathcal{D}_{\text{train}}[f]$ and $\mathcal{D}_{\text{test}}[f]$
% % \ENDFOR

% % \STATE \textbf{// Feature Selection}
% % \STATE Drop correlated features: $\mathcal{F}_{\text{drop}} = \{\texttt{ct\_dst\_src\_ltm}, \texttt{ct\_ftp\_cmd},$ 
% % \STATE \quad $\texttt{ct\_src\_dport\_ltm}, \texttt{ct\_srv\_dst}, \texttt{dbytes}, \texttt{dloss}, \texttt{dwin}, \texttt{sbytes}, \texttt{sloss}\}$
% % \STATE $\mathcal{D}_{\text{train}} \gets \mathcal{D}_{\text{train}} \setminus \mathcal{F}_{\text{drop}}$
% % \STATE $\mathcal{D}_{\text{test}} \gets \mathcal{D}_{\text{test}} \setminus \mathcal{F}_{\text{drop}}$

% % \STATE \textbf{// Separate Features and Labels}
% % \STATE $X_{\text{train}}^{\text{raw}} \gets$ all features from $\mathcal{D}_{\text{train}}$
% % \STATE $y_{\text{train}} \gets \mathcal{D}_{\text{train}}[\texttt{label}]$
% % \STATE $X_{\text{test}}^{\text{raw}} \gets$ all features from $\mathcal{D}_{\text{test}}$
% % \STATE $y_{\text{test}} \gets \mathcal{D}_{\text{test}}[\texttt{label}]$

% % \STATE \textbf{// Standardization}
% % \STATE Fit StandardScaler on $X_{\text{train}}^{\text{raw}}$
% % \STATE $X_{\text{train}} \gets \text{StandardScaler.transform}(X_{\text{train}}^{\text{raw}})$
% % \STATE $X_{\text{test}} \gets \text{StandardScaler.transform}(X_{\text{test}}^{\text{raw}})$

% % \RETURN $X_{\text{train}}, y_{\text{train}}, X_{\text{test}}, y_{\text{test}}$
% % \end{algorithmic}
% % \end{algorithm}
% \begin{algorithm}[!t]
% \caption{Data Preprocessing Pipeline}
% \label{alg:preprocessing}
% \begin{algorithmic}[1]
% \renewcommand{\algorithmicrequire}{\textbf{Input:}}
% \renewcommand{\algorithmicensure}{\textbf{Output:}}
% \REQUIRE Raw datasets $\mathcal{D}_{\text{train}}^{\text{raw}}$, $\mathcal{D}_{\text{test}}^{\text{raw}}$
% \ENSURE Preprocessed features \& labels: $X_{\text{train}}, y_{\text{train}}, X_{\text{test}}, y_{\text{test}}$

% \STATE \textit{1) Data Cleaning:}
% \FOR{$\mathcal{D} \in \{\mathcal{D}_{\text{train}}^{\text{raw}}, \mathcal{D}_{\text{test}}^{\text{raw}}\}$}
%     \STATE Remove \texttt{id} column
%     \STATE Replace missing \texttt{service}: `\texttt{-}' $\rightarrow$ `\texttt{none}'
%     \FOR{each numeric feature $f$}
%         \STATE Replace $\pm\infty \rightarrow \texttt{NaN}$
%         \STATE Impute \texttt{NaN} with median($f$)
%     \ENDFOR
% \ENDFOR

% \STATE \textit{2) Categorical Encoding:}
% \STATE Combine: $\mathcal{D}_{\text{all}} \gets \mathcal{D}_{\text{train}}^{\text{raw}} \cup \mathcal{D}_{\text{test}}^{\text{raw}}$
% \FOR{$f \in \{\texttt{proto}, \texttt{service}, \texttt{state}\}$}
%     \STATE Fit LabelEncoder on $\mathcal{D}_{\text{all}}[f]$
%     \STATE Transform $\mathcal{D}_{\text{train}}[f]$ and $\mathcal{D}_{\text{test}}[f]$
% \ENDFOR

% \STATE \textit{3) Feature Selection:}
% \STATE Define drop set: $\mathcal{F}_{\text{drop}} = \{\texttt{ct\_dst\_src\_ltm}, \dots, \texttt{sloss}\}$
% \STATE $\mathcal{D}_{\text{train}} \gets \mathcal{D}_{\text{train}} \setminus \mathcal{F}_{\text{drop}}$, $\mathcal{D}_{\text{test}} \gets \mathcal{D}_{\text{test}} \setminus \mathcal{F}_{\text{drop}}$

% \STATE \textit{4) Split Features and Labels:}
% \STATE $X_{\text{train}}^{\text{raw}}, y_{\text{train}} \gets \text{features}(\mathcal{D}_{\text{train}}), \mathcal{D}_{\text{train}}[\texttt{label}]$
% \STATE $X_{\text{test}}^{\text{raw}}, y_{\text{test}} \gets \text{features}(\mathcal{D}_{\text{test}}), \mathcal{D}_{\text{test}}[\texttt{label}]$

% \STATE \textit{5) Standardization:}
% \STATE Fit StandardScaler $\mathcal{S}$ on $X_{\text{train}}^{\text{raw}}$
% \STATE $X_{\text{train}} \gets \mathcal{S}.\text{transform}(X_{\text{train}}^{\text{raw}})$
% \STATE $X_{\text{test}} \gets \mathcal{S}.\text{transform}(X_{\text{test}}^{\text{raw}})$

% \RETURN $X_{\text{train}}, y_{\text{train}}, X_{\text{test}}, y_{\text{test}}$
% \end{algorithmic}
% \end{algorithm}

% \subsubsection{Data Cleaning}

% The raw UNSW-NB15 dataset contains several data quality issues that must be addressed. The identifier column \texttt{id} is removed as it provides no discriminative information. The \texttt{service} feature contains missing values encoded as `\texttt{-}', which are replaced with the string `\texttt{none}' to create a valid categorical level.

% Numerical features exhibit infinite values resulting from division-by-zero operations during feature extraction (e.g., packet rate calculations when duration is zero). All infinite values $\{\pm\infty\}$ are replaced with \texttt{NaN} markers. Missing values are then imputed using column-wise median values computed independently for each dataset partition. While cross-partition imputation (using training medians for test data) would be theoretically preferred to prevent information leakage, the UNSW-NB15 dataset's predefined train-test split and the stability of median statistics across partitions justify this approach for practical reproducibility.

% \subsubsection{Categorical Encoding}

% Three categorical features require numerical encoding: \texttt{proto} (protocol type), \texttt{service} (application layer service), and \texttt{state} (connection state). To ensure consistent encoding across train and test partitions, we fit label encoders on the combined dataset $\mathcal{D}_{\text{combined}} = \mathcal{D}_{\text{train}} \cup \mathcal{D}_{\text{test}}$, then apply the learned mappings to each partition independently. This prevents unseen categories in the test set while maintaining proper train-test separation for model evaluation.

% The target variable \texttt{attack\_cat} (multi-class attack category) is similarly encoded for potential per-category analysis, though the primary task uses the binary \texttt{label} column.

% \subsubsection{Feature Selection via Correlation Analysis}

% High multicollinearity among features can degrade model performance and increase computational cost. We identify feature pairs with Pearson correlation coefficient $|\rho| > 0.95$ and remove one feature from each highly correlated pair. The following nine features are dropped based on domain knowledge and correlation analysis:
% \begin{itemize}
%     \item \texttt{ct\_dst\_src\_ltm}, \texttt{ct\_ftp\_cmd}, \texttt{ct\_src\_dport\_ltm}, \texttt{ct\_srv\_dst}: Connection count statistics with redundant temporal information
%     \item \texttt{dbytes}, \texttt{dloss}, \texttt{dwin}: Destination-side metrics correlated with source-side equivalents
%     \item \texttt{sbytes}, \texttt{sloss}: Source byte counts and loss rates with high collinearity
% \end{itemize}

% This correlation-based selection reduces feature dimensionality from 42 to 33 while retaining essential discriminative information.

% \subsubsection{Feature Scaling}

% Deep neural networks benefit from normalized input distributions. We apply standardization (z-score normalization) to all features:
% \begin{equation}
% x_{ij}^{\text{scaled}} = \frac{x_{ij}^{\text{raw}} - \mu_j}{\sigma_j}
% \end{equation}
% where $x_{ij}^{\text{raw}}$ is the raw value of feature $j$ for sample $i$, and $\mu_j$, $\sigma_j$ are the mean and standard deviation of feature $j$ computed on the training set. Critically, the same scaling parameters $(\mu_j, \sigma_j)$ fitted on training data are applied to the test set to prevent information leakage.

% The preprocessed features have zero mean and unit variance, stabilizing gradient-based optimization and preventing features with large numerical ranges from dominating the learning process.

% \subsection{Problem Formulation}

% Network intrusion detection is formulated as a binary classification task where a model $f: \mathbb{R}^d \rightarrow [0,1]$ maps $d$-dimensional network flow features $\mathbf{x} \in \mathbb{R}^d$ to attack probability $p \in [0,1]$. The training dataset $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N$ contains $N$ labeled samples where $y_i \in \{0, 1\}$ indicates normal traffic ($y=0$) or attack traffic ($y=1$).

% The dataset exhibits severe class imbalance at two levels. At the binary level, the imbalance ratio $r = N_{\text{attack}} / N_{\text{normal}}$ varies substantially between training ($r_{\text{train}} = 0.469$) and testing ($r_{\text{test}} = 0.816$) partitions, reflecting realistic deployment scenarios where attack prevalence fluctuates over time. At the granular level, individual attack categories range from 44 samples (Worms) to over 40,000 samples (Generic), creating extreme within-class imbalance that conventional balancing techniques fail to address.

% Standard cross-entropy loss $\mathcal{L}_{\text{CE}} = -y \log(p) - (1-y) \log(1-p)$ assigns equal learning emphasis to all samples, causing gradient-based optimization to prioritize majority classes. This majority bias manifests in attention mechanisms as well: when computing attention weights $\alpha_i = \text{softmax}(\text{score}_i)$, features frequently co-occurring with majority classes receive disproportionate attention scores, while minority-characteristic features are suppressed.

% \subsection{Focal-Aware Imbalance-Integrated Attention (FAIIA)}

% The core innovation of FAIIA is the integration of focal modulation directly into attention score computation rather than applying imbalance adjustments solely at the loss function level. This architectural integration enables instance-level adaptive attention that complements loss-level class weighting.

% \subsubsection{Focal Modulation of Attention Scores}

% Given input features $\mathbf{x} \in \mathbb{R}^d$, we first obtain an initial minority-class probability estimate $p_{\text{init}} \in [0,1]$ via a lightweight probability estimator:
% \begin{equation}
% p_{\text{init}} = \sigma(W_p \cdot \text{ReLU}(W_e \mathbf{x} + b_e) + b_p)
% \end{equation}
% where $W_e \in \mathbb{R}^{64 \times d}$ and $W_p \in \mathbb{R}^{1 \times 64}$ are learned projection matrices, $b_e$ and $b_p$ are bias terms, and $\sigma(\cdot)$ denotes the sigmoid activation.

% This initial probability guides focal modulation throughout the attention mechanism. For each attention head, we compute query, key, and value projections:
% \begin{align}
% \mathbf{q} &= W_Q \mathbf{x} + b_Q \\
% \mathbf{k} &= W_K \mathbf{x} + b_K \\
% \mathbf{v} &= W_V \mathbf{x} + b_V
% \end{align}
% where $W_Q, W_K, W_V \in \mathbb{R}^{d_a \times d}$ project to attention dimension $d_a = 32$.

% The self-attention score is computed as:
% \begin{equation}
% s_{\text{self}} = \mathbf{q}^T \mathbf{k}
% \end{equation}

% Before applying softmax normalization, we modulate the attention score with a focal term derived from the minority-class probability:
% \begin{equation}
% s_{\text{focal}} = s_{\text{self}} \cdot \left(1 + \alpha \cdot (1 - p_{\text{init}} + \epsilon)^\gamma \cdot \tau \right)
% \label{eq:focal_modulation}
% \end{equation}
% where $\alpha$ is a learnable weighting parameter initialized to 0.60, $\gamma = 2.0$ controls the modulation strength, $\epsilon = 10^{-8}$ prevents numerical instability, and $\tau$ is a learnable temperature parameter initialized to 1.0. The term $(1 - p_{\text{init}})^\gamma$ amplifies attention for samples with low initial minority probability (likely majority-class or hard negatives), while $\alpha$ and $\tau$ allow the model to adapt the modulation magnitude during training.

% The attention weight is then normalized:
% \begin{equation}
% \alpha_{\text{self}} = \text{softmax}\left(\frac{s_{\text{focal}}}{\sqrt{d_a}}\right)
% \end{equation}
% where the scaling factor $1/\sqrt{d_a}$ stabilizes gradients following standard practice~\cite{vaswani2017attention}.

% \subsubsection{Prototype-Based Minority Attention}

% To explicitly capture minority-class patterns, FAIIA maintains a set of $K=8$ learnable prototype embeddings $\{\mathbf{p}_1, \ldots, \mathbf{p}_K\}$ where $\mathbf{p}_j \in \mathbb{R}^{d_a}$. These prototypes are initialized via K-means clustering on minority-class training samples, ensuring they represent diverse attack patterns at initialization.

% For each prototype, we compute corresponding key and value representations:
% \begin{align}
% \mathbf{k}_j^{\text{proto}} &= W_K^{\text{proto}} \mathbf{p}_j + b_K^{\text{proto}} \\
% \mathbf{v}_j^{\text{proto}} &= W_V^{\text{proto}} \mathbf{p}_j + b_V^{\text{proto}}
% \end{align}

% The prototype attention scores are computed via query-prototype similarity:
% \begin{equation}
% s_j^{\text{proto}} = \mathbf{q}^T \mathbf{k}_j^{\text{proto}}, \quad j = 1, \ldots, K
% \end{equation}

% These scores undergo the same focal modulation as self-attention:
% \begin{equation}
% s_j^{\text{focal-proto}} = s_j^{\text{proto}} \cdot \left(1 + \alpha \cdot (1 - p_{\text{init}} + \epsilon)^\gamma \cdot \tau \right)
% \end{equation}

% The prototype attention weights incorporate both the modulated scores and learnable prototype importance weights $\boldsymbol{\lambda} = [\lambda_1, \ldots, \lambda_K]^T$:
% \begin{equation}
% \alpha_j^{\text{proto}} = \text{softmax}\left(\frac{s_j^{\text{focal-proto}}}{\sqrt{d_a}}\right) \cdot \text{softmax}(\lambda_j)
% \end{equation}

% The prototype importance weights $\boldsymbol{\lambda}$ allow the model to learn which prototypes are most discriminative for intrusion detection, dynamically emphasizing or suppressing individual prototypes during inference.

% The attended prototype representation aggregates prototype values weighted by attention:
% \begin{equation}
% \mathbf{h}^{\text{proto}} = \sum_{j=1}^K \alpha_j^{\text{proto}} \mathbf{v}_j^{\text{proto}}
% \end{equation}

% \subsubsection{Multi-Head FAIIA and Output Integration}

% To capture diverse attention patterns, FAIIA employs $H=4$ attention heads, each with independent parameters. For head $h \in \{1, \ldots, H\}$, we compute self-attended and prototype-attended representations $\mathbf{h}_h^{\text{self}}$ and $\mathbf{h}_h^{\text{proto}}$ following the procedure above. Each head uses a slightly perturbed focal parameter $\alpha_h = \alpha \cdot (1 + 0.1 \cdot h)$ to encourage diversity in attention patterns.

% The outputs from each head are concatenated and projected:
% \begin{equation}
% \mathbf{h}_h = W_O^h \left[\mathbf{h}_h^{\text{self}} \oplus \mathbf{h}_h^{\text{proto}}\right] + b_O^h
% \end{equation}
% where $\oplus$ denotes concatenation and $W_O^h \in \mathbb{R}^{d_a \times 2d_a}$ projects back to attention dimension.

% The multi-head outputs are combined via learned head weights $\boldsymbol{\beta} = [\beta_1, \ldots, \beta_H]^T$:
% \begin{equation}
% \mathbf{h}^{\text{multi}} = W_{\text{final}} \left[\mathbf{h}_1 \oplus \cdots \oplus \mathbf{h}_H\right]
% \end{equation}
% where $W_{\text{final}} \in \mathbb{R}^{d \times Hd_a}$ projects to the original feature dimension $d$.

% \subsubsection{Class-Conditional Gating}

% To refine the attended features based on prediction difficulty, we employ a class-conditional gating mechanism. The gate takes as input both the attended features and a difficulty score derived from the initial probability:
% \begin{equation}
% \mathbf{g} = \sigma\left(W_{g2} \cdot \text{ReLU}\left(W_{g1} \left[\mathbf{h}^{\text{multi}} \oplus d_{\text{conf}}\right] + b_{g1}\right) + b_{g2}\right)
% \end{equation}
% where $d_{\text{conf}} = 1 - 2|p_{\text{init}} - 0.5|$ measures prediction uncertainty (low values indicate high confidence, high values indicate ambiguous samples), and $W_{g1} \in \mathbb{R}^{d/4 \times (d+1)}$, $W_{g2} \in \mathbb{R}^{d \times d/4}$ implement a two-layer gating network.

% The gated output is computed element-wise:
% \begin{equation}
% \mathbf{h}^{\text{gated}} = \mathbf{h}^{\text{multi}} \odot \mathbf{g}
% \end{equation}
% where $\odot$ denotes element-wise multiplication.

% Finally, a residual connection and layer normalization stabilize training:
% \begin{equation}
% \mathbf{h}^{\text{FAIIA}} = \text{LayerNorm}(\mathbf{h}^{\text{gated}} + \mathbf{x})
% \end{equation}

% \subsection{Complete FAA-NET Architecture}

% The complete FAA-NET model integrates FAIIA into a deep neural architecture designed for edge deployment. Figure~\ref{fig:architecture} illustrates the overall pipeline.

% \subsubsection{Input Normalization and Initial Processing}

% Input features $\mathbf{x} \in \mathbb{R}^{33}$ undergo batch normalization to stabilize training:
% \begin{equation}
% \mathbf{x}^{\text{norm}} = \text{BatchNorm}(\mathbf{x})
% \end{equation}

% The normalized features are processed by the probability estimator (Equation 1) to obtain $p_{\text{init}}$, which guides FAIIA's focal modulation.

% \subsubsection{FAIIA Layer}

% The FAIIA mechanism (Section III-B) transforms the normalized features:
% \begin{equation}
% \mathbf{h}^{\text{FAIIA}} = \text{FAIIA}(\mathbf{x}^{\text{norm}}, p_{\text{init}})
% \end{equation}

% \subsubsection{Squeeze-and-Excitation Refinement}

% A Squeeze-and-Excitation (SE) block~\cite{hu2018squeeze} recalibrates channel-wise feature importance:
% \begin{align}
% \mathbf{z} &= W_{se2} \cdot \text{ReLU}(W_{se1} \mathbf{h}^{\text{FAIIA}} + b_{se1}) + b_{se2} \\
% \mathbf{s} &= \sigma(\mathbf{z}) \\
% \mathbf{h}^{\text{SE}} &= \mathbf{h}^{\text{FAIIA}} \odot \mathbf{s}
% \end{align}
% where $W_{se1} \in \mathbb{R}^{d/4 \times d}$ and $W_{se2} \in \mathbb{R}^{d \times d/4}$ implement the squeeze-excitation transformation.

% \subsubsection{Residual Hidden Blocks}

% The SE-refined features pass through three residual blocks with progressively decreasing dimensions [256, 128, 64]:
% \begin{equation}
% \mathbf{h}^{(l+1)} = \text{Block}^{(l)}(\mathbf{h}^{(l)}) + W_{\text{res}}^{(l)} \mathbf{h}^{(l)}
% \end{equation}
% where each block consists of:
% \begin{equation}
% \text{Block}^{(l)}(\mathbf{h}) = \text{Dropout}(\text{GELU}(\text{BatchNorm}(W^{(l)} \mathbf{h} + b^{(l)})))
% \end{equation}
% with dropout rate 0.3. The residual projection $W_{\text{res}}^{(l)}$ matches dimensions when necessary.

% \subsubsection{Classification Head}

% The final hidden representation $\mathbf{h}^{(3)} \in \mathbb{R}^{64}$ is mapped to logits via a two-layer classifier:
% \begin{align}
% \mathbf{h}^{\text{cls}} &= \text{Dropout}(\text{GELU}(W_{cls1} \mathbf{h}^{(3)} + b_{cls1})) \\
% z &= W_{cls2} \mathbf{h}^{\text{cls}} + b_{cls2}
% \end{align}
% where $W_{cls1} \in \mathbb{R}^{32 \times 64}$, $W_{cls2} \in \mathbb{R}^{1 \times 32}$, and $z \in \mathbb{R}$ represents the raw logit.

% During training, logits are used directly with a logit-compatible loss function. During inference, predictions are obtained via:
% \begin{equation}
% \hat{y} = \mathbb{1}[\sigma(z) > \theta]
% \end{equation}
% where $\theta = 0.5$ is the decision threshold and $\mathbb{1}[\cdot]$ is the indicator function.

% \subsection{Loss Function and Optimization}

% To address class imbalance at the loss level, we employ an imbalance-aware focal loss~\cite{lin2017focal} adapted for binary classification with logits:
% \begin{equation}
% \mathcal{L}_{\text{focal}}(z, y) = -\alpha_t (1 - p_t)^\gamma \mathcal{L}_{\text{BCE}}(z, y)
% \label{eq:focal_loss}
% \end{equation}
% where $\mathcal{L}_{\text{BCE}}(z, y) = y \log \sigma(z) + (1-y) \log(1 - \sigma(z))$ is the binary cross-entropy computed from logits, $p_t = y \sigma(z) + (1-y)(1 - \sigma(z))$ is the probability of the ground truth class, and $\gamma = 2.0$ controls down-weighting of easy examples.

% The class-specific weighting $\alpha_t$ is computed automatically from training class frequencies:
% \begin{equation}
% \alpha_t = \begin{cases}
% \frac{N}{2N_{\text{attack}}} & \text{if } y = 1 \\
% \frac{N}{2N_{\text{normal}}} & \text{if } y = 0
% \end{cases}
% \end{equation}
% where $N = N_{\text{attack}} + N_{\text{normal}}$ is the total training set size. This formulation ensures that minority classes receive proportionally higher loss contribution while maintaining balanced gradient magnitudes.

% Label smoothing~\cite{szegedy2016rethinking} is applied to prevent overconfidence:
% \begin{equation}
% \tilde{y} = y(1 - \epsilon) + 0.5\epsilon
% \end{equation}
% where $\epsilon = 0.05$ is the smoothing parameter.

% The model is optimized using AdamW~\cite{loshchilov2019decoupled} with learning rate $\eta = 0.001$, weight decay $\lambda = 10^{-4}$, and default momentum parameters $\beta_1 = 0.9$, $\beta_2 = 0.999$. A cosine annealing warm restart scheduler modulates the learning rate:
% \begin{equation}
% \eta_t = \eta_{\min} + \frac{1}{2}(\eta_0 - \eta_{\min})\left(1 + \cos\left(\frac{T_{\text{cur}}}{T_0} \pi\right)\right)
% \end{equation}
% where $T_{\text{cur}}$ is the current epoch within a restart cycle, $T_0 = 15$ is the initial restart period, and $\eta_{\min} = 10^{-6}$ is the minimum learning rate. The restart period doubles after each cycle ($T_{\text{mult}} = 2$).

% Gradient clipping with maximum norm 1.0 prevents exploding gradients during training:
% \begin{equation}
% \mathbf{g}_{\text{clip}} = \min\left(1.0, \frac{1.0}{\|\mathbf{g}\|_2}\right) \mathbf{g}
% \end{equation}
% where $\mathbf{g}$ represents the gradient vector.

% \subsection{Minority Prototype Initialization}

% The prototype embeddings $\{\mathbf{p}_1, \ldots, \mathbf{p}_K\}$ are initialized via K-means clustering on attack-class training samples before model training. Specifically, we extract all attack samples $\mathcal{X}_{\text{attack}} = \{\mathbf{x}_i : y_i = 1\}$ from the training set and apply K-means with $K=8$ clusters:
% \begin{equation}
% \{\mathbf{c}_1, \ldots, \mathbf{c}_K\} = \arg\min_{\{\mathbf{c}_j\}} \sum_{i=1}^{|\mathcal{X}_{\text{attack}}|} \min_{j} \|\mathbf{x}_i - \mathbf{c}_j\|_2^2
% \end{equation}

% The cluster centroids $\{\mathbf{c}_j\}$ are then projected to the attention dimension:
% \begin{equation}
% \mathbf{p}_j^{\text{init}} = W_K^{\text{proto}} \mathbf{c}_j + b_K^{\text{proto}}
% \end{equation}

% This initialization ensures that prototypes represent diverse attack patterns at the start of training, while subsequent gradient updates allow them to specialize further based on discriminative utility.

% \subsection{Training Procedure}

% The complete training procedure is summarized in Algorithm~\ref{alg:training}.

% \begin{algorithm}[!t]
% \caption{FAA-NET Training Procedure}
% \label{alg:training}
% \begin{algorithmic}[1]
% \renewcommand{\algorithmicrequire}{\textbf{Input:}}
% \renewcommand{\algorithmicensure}{\textbf{Output:}}
% \REQUIRE Training $\mathcal{D}_{\text{train}}$, validation $\mathcal{D}_{\text{val}}$
% \ENSURE Trained model $f_\theta$

% \STATE \textit{1) Initialization:}
% \STATE Randomly initialize model parameters $\theta$
% \STATE Extract attack samples $\mathcal{X}_{\text{attack}} \subset \mathcal{D}_{\text{train}}$
% \STATE Compute centroids $C_k$ via K-means on $\mathcal{X}_{\text{attack}}$
% \STATE Initialize FAIIA prototypes with $C_k$

% \STATE \textit{2) Training Loop:}
% \STATE $\text{best\_f1} \gets 0$, $\text{patience} \gets 0$
% \FOR{$\text{epoch} = 1$ to $150$}
%     \FOR{batch $\mathcal{B} \subset \mathcal{D}_{\text{train}}$}
%         \STATE Logits $z$, probs $p \gets f_\theta(\mathcal{B})$
%         \STATE Label smoothing: $\tilde{y} \gets y(1-\epsilon) + 0.5\epsilon$
%         \STATE Loss $\mathcal{L} \gets \text{FocalLoss}(z, \tilde{y})$
%         \STATE Update $\theta \gets \text{AdamW}(\theta, \nabla_\theta \mathcal{L})$
%     \ENDFOR
%     \STATE Update learning rate (Cosine Annealing)
    
%     \STATE \textit{3) Validation \& Early Stopping:}
%     \STATE $\text{val\_f1} \gets \text{Evaluate}(\mathcal{D}_{\text{val}}, f_\theta)$
%     \IF{$\text{val\_f1} > \text{best\_f1}$}
%         \STATE $\text{best\_f1} \gets \text{val\_f1}$, Save checkpoint
%         \STATE $\text{patience} \gets 0$
%     \ELSE
%         \STATE $\text{patience} \gets \text{patience} + 1$
%     \ENDIF
%     \IF{$\text{patience} \geq 20$} \STATE \textbf{break} \ENDIF
% \ENDFOR

% \STATE Restore best checkpoint
% \RETURN $f_\theta$
% \end{algorithmic}
% \end{algorithm}

% Training typically converges within 60-90 epochs due to early stopping. The model with the highest validation F1-score is retained for final evaluation. All experiments use mini-batch size of 256 and random seed 42 for reproducibility across PyTorch, NumPy, and scikit-learn operations.




\section{Methodology}
\label{sec:methodology}

This section presents the proposed FAA-Net architecture with FAIIA (Focal-Aware Imbalance-Integrated Attention) for network intrusion detection under severe class imbalance. We begin with the problem formulation, followed by detailed descriptions of the architectural components, training strategy, and implementation considerations.

\subsection{Problem Formulation}

Given a network traffic dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^{N}$, where $x_i \in \mathbb{R}^d$ represents a $d$-dimensional feature vector of network flow attributes and $y_i \in \{0, 1\}$ denotes the binary label (0 for normal traffic, 1 for attack), the objective is to learn a classifier $f: \mathbb{R}^d \rightarrow [0, 1]$ that accurately detects minority class instances despite significant class imbalance. 

The dataset exhibits a global imbalance ratio of 0.564756, with 164673 attack samples and 93000 normal samples across 257673 total instances. More critically, the per-attack category distribution reveals extreme local imbalance, with certain attack types containing fewer than 500 training samples. Specifically, the training set contains 175341 samples with 119341 attacks and 56000 normal instances (imbalance ratio: 0.469244), while the test set comprises 82332 samples with 45332 attacks and 37000 normal instances (imbalance ratio: 0.816200). This creates a challenging multi-level imbalance scenario where both inter-class and intra-class imbalances must be addressed simultaneously.

\subsection{Data Preprocessing Pipeline}

The preprocessing pipeline ensures data quality and feature relevance through systematic transformations applied consistently across training and test partitions.

\subsubsection{Data Cleaning and Imputation}
The raw UNSW-NB15 dataset undergoes cleaning to handle missing values and infinite entries. Numerical features containing infinite values are replaced with NaN markers. Missing value imputation employs median-based substitution, where medians are computed exclusively on the training partition and applied to both training and test sets to prevent data leakage. This training-centric imputation strategy ensures that test data characteristics do not influence model training.

\subsubsection{Categorical Encoding}
Categorical features (protocol, service, and connection state) are transformed using label encoding fitted solely on training data. For test instances containing previously unseen categorical values, a safe transformation strategy maps unknown categories to a default encoding, preventing runtime errors while maintaining encoding consistency.

\subsubsection{Feature Selection}
To mitigate multicollinearity and reduce computational overhead, features exhibiting correlation coefficients exceeding 0.95 are systematically removed. Nine highly correlated features are eliminated: \texttt{ct\_dst\_src\_ltm}, \texttt{ct\_ftp\_cmd}, \texttt{ct\_src\_dport\_ltm}, \texttt{ct\_srv\_dst}, \texttt{dbytes}, \texttt{dloss}, \texttt{dwin}, \texttt{sbytes}, and \texttt{sloss}. This selection yields a final feature space of 33 dimensions.

\subsubsection{Feature Normalization}
Standard scaling is applied to normalize feature distributions. The StandardScaler is fitted exclusively on training data, with the learned parameters (mean and standard deviation) subsequently applied to test data. This ensures zero mean and unit variance normalization while preserving the independence of test set statistics.

\subsection{E-DAN v3 Architecture}

The Edge-Deployable Attention Network version 3 (E-DAN v3) introduces FAIIA as its core innovation, integrating focal-based imbalance awareness directly into the attention mechanism rather than solely relying on loss function modifications.

\subsubsection{Input Processing}

The architecture begins with batch normalization applied to the 33-dimensional input features:
\begin{equation}
x_{\text{norm}} = \text{BatchNorm}(x)
\end{equation}
where $x \in \mathbb{R}^{33}$ represents the preprocessed feature vector. This normalization stabilizes training dynamics and accelerates convergence.

\subsubsection{Initial Probability Estimation}

A lightweight probability estimator provides an initial minority class probability estimate that guides focal modulation within the attention mechanism:
\begin{equation}
p_{\text{init}} = \sigma(W_2 \cdot \text{ReLU}(W_1 x_{\text{norm}} + b_1) + b_2)
\end{equation}
where $W_1 \in \mathbb{R}^{64 \times 33}$, $W_2 \in \mathbb{R}^{1 \times 64}$, and $\sigma$ denotes the sigmoid activation. This estimator employs a compact two-layer architecture with 64 hidden units and 0.15 dropout rate, minimizing parameter overhead while providing class probability guidance.

\subsubsection{FAIIA: Focal-Aware Imbalance-Integrated Attention}

FAIIA constitutes the primary architectural innovation, embedding imbalance awareness within multi-head attention through focal modulation and prototype-based cross-attention.

\paragraph{Minority Prototype Generation}
Minority class prototypes are extracted offline using K-means clustering on attack samples:
\begin{equation}
\mathcal{P} = \{p_1, p_2, \ldots, p_K\} = \text{K-means}(\{x_i | y_i = 1\}, K)
\end{equation}
where $K=8$ prototypes capture the diversity of minority class feature distributions. These prototypes serve as learnable attention anchors within each FAIIA head.

\paragraph{Single-Head FAIIA Mechanism}
Each FAIIA head performs prototype-based cross-attention modulated by focal weighting. Given input $x \in \mathbb{R}^{33}$, the query projection is:
\begin{equation}
q = W_q x \in \mathbb{R}^{32}
\end{equation}
where $W_q \in \mathbb{R}^{32 \times 33}$ and the attention dimension is 32.

Prototype keys and values are learnable parameters initialized from minority prototypes:
\begin{equation}
K_{\text{proto}} = [k_1, k_2, \ldots, k_K]^\top \in \mathbb{R}^{K \times 32}
\end{equation}
\begin{equation}
V_{\text{proto}} = [v_1, v_2, \ldots, v_K]^\top \in \mathbb{R}^{K \times 32}
\end{equation}

Attention scores incorporate learnable prototype importance weights:
\begin{equation}
s = q K_{\text{proto}}^\top + w_{\text{proto}} \in \mathbb{R}^{K}
\end{equation}
where $w_{\text{proto}} \in \mathbb{R}^K$ are learnable bias terms allowing the model to prioritize discriminative prototypes.

\paragraph{Focal Modulation}
The focal modulation mechanism amplifies attention for uncertain predictions near the decision boundary. Unlike traditional focal loss formulations that emphasize confident misclassifications, FAIIA employs uncertainty-based modulation:
\begin{equation}
u = 1 - 2|p_{\text{init}} - 0.5|
\end{equation}
\begin{equation}
w_{\text{focal}} = \alpha (u + \epsilon)^\gamma \cdot \tau
\end{equation}
where $u$ measures prediction uncertainty (maximum at $p_{\text{init}} = 0.5$), $\alpha = 0.60$ is a learnable scaling factor, $\gamma = 2.0$ controls modulation strength, $\epsilon = 10^{-8}$ ensures numerical stability, and $\tau$ is a learnable temperature parameter. The modulated scores become:
\begin{equation}
s_{\text{mod}} = s \cdot (1 + w_{\text{focal}})
\end{equation}

Attention weights are computed via scaled softmax:
\begin{equation}
a = \text{softmax}(s_{\text{mod}} \cdot \sqrt{32}^{-1})
\end{equation}

The attended output aggregates prototype values:
\begin{equation}
h = a V_{\text{proto}} \in \mathbb{R}^{32}
\end{equation}

Output projection and layer normalization produce the final head output:
\begin{equation}
o = \text{LayerNorm}(W_o h)
\end{equation}
where $W_o \in \mathbb{R}^{32 \times 32}$.

\paragraph{Multi-Head Configuration}
E-DAN v3 employs 4 attention heads, each with slightly varied focal parameters to capture diverse attention patterns. Head $i$ uses focal $\alpha_i = 0.60 \times (1 + 0.1i)$, creating a spectrum of sensitivity levels across heads. Head outputs are concatenated and projected:
\begin{equation}
h_{\text{concat}} = [o_1; o_2; o_3; o_4] \in \mathbb{R}^{128}
\end{equation}
\begin{equation}
h_{\text{faiia}} = W_{\text{proj}} h_{\text{concat}} \in \mathbb{R}^{33}
\end{equation}
where $W_{\text{proj}} \in \mathbb{R}^{33 \times 128}$.

\paragraph{Class-Conditional Gating}
A difficulty-aware gating mechanism adaptively modulates features based on prediction uncertainty:
\begin{equation}
d = 1 - 2|p_{\text{init}} - 0.5|
\end{equation}
\begin{equation}
g = \sigma(W_{g2} \cdot \text{ReLU}(W_{g1}[h_{\text{faiia}}; d] + b_{g1}) + b_{g2})
\end{equation}
\begin{equation}
h_{\text{gated}} = h_{\text{faiia}} \odot g
\end{equation}
where $W_{g1} \in \mathbb{R}^{8 \times 34}$, $W_{g2} \in \mathbb{R}^{33 \times 8}$, and $\odot$ denotes element-wise multiplication. A residual connection preserves input information:
\begin{equation}
h_{\text{out}} = \text{LayerNorm}(h_{\text{gated}} + x_{\text{norm}})
\end{equation}

\subsubsection{Squeeze-and-Excitation Block}

Channel-wise feature recalibration is performed via a squeeze-and-excitation mechanism:
\begin{equation}
c = \sigma(W_{se2} \cdot \text{ReLU}(W_{se1} h_{\text{out}} + b_{se1}) + b_{se2})
\end{equation}
\begin{equation}
h_{\text{se}} = h_{\text{out}} \odot c
\end{equation}
where $W_{se1} \in \mathbb{R}^{8 \times 33}$ and $W_{se2} \in \mathbb{R}^{33 \times 8}$ implement a bottleneck with reduction ratio of 4.

\subsubsection{Deep Feature Extraction}

Three residual blocks progressively extract hierarchical representations with dimensions [256, 128, 64]:
\begin{equation}
h^{(l)} = \text{Dropout}(\text{GELU}(\text{BatchNorm}(W^{(l)} h^{(l-1)} + b^{(l)}))) + W_{\text{res}}^{(l)} h^{(l-1)}
\end{equation}
where $l \in \{1, 2, 3\}$, $h^{(0)} = h_{\text{se}}$, and $W_{\text{res}}^{(l)}$ is a projection matrix (or identity) ensuring dimensional compatibility for residual addition. Dropout rate is 0.3, and GELU activation introduces non-linearity.

\subsubsection{Classification Head}

The final classification head maps the 64-dimensional representation to binary predictions:
\begin{equation}
z = W_{c2} \cdot \text{GELU}(W_{c1} h^{(3)} + b_{c1}) + b_{c2}
\end{equation}
where $W_{c1} \in \mathbb{R}^{32 \times 64}$, $W_{c2} \in \mathbb{R}^{1 \times 32}$, and dropout rate is 0.15. The raw logit $z$ is used during training for numerical stability with the loss function.

\subsection{Loss Function: Imbalance-Aware Focal Loss}

The model employs an imbalance-aware focal loss that combines automatic class weighting with focal modulation to address both class imbalance and hard example mining:
\begin{equation}
\mathcal{L}_{\text{focal}} = -\alpha_t (1 - p_t)^\gamma \log(p_t)
\end{equation}
where:
\begin{equation}
p_t = \begin{cases}
\sigma(z) & \text{if } y = 1 \\
1 - \sigma(z) & \text{if } y = 0
\end{cases}
\end{equation}
\begin{equation}
\alpha_t = \begin{cases}
\frac{N}{2N_{\text{pos}}} & \text{if } y = 1 \\
\frac{N}{2N_{\text{neg}}} & \text{if } y = 0
\end{cases}
\end{equation}

Given class counts $N_{\text{neg}} = 56000$ and $N_{\text{pos}} = 119341$ in the training set, the computed weights are $\alpha_{\text{pos}} = 0.7354$ and $\alpha_{\text{neg}} = 1.5655$. The focal parameter $\gamma = 2.0$ down-weights well-classified examples. Binary cross-entropy is computed via \texttt{BCEWithLogitsLoss} for numerical stability.

Label smoothing with $\epsilon = 0.05$ is applied during training:
\begin{equation}
y_{\text{smooth}} = y(1 - \epsilon) + 0.5\epsilon
\end{equation}
This regularization technique prevents overconfident predictions and improves generalization.

\subsection{Optimization Strategy}

\subsubsection{Optimizer Configuration}
The AdamW optimizer with decoupled weight decay is employed:
\begin{equation}
\theta_{t+1} = \theta_t - \eta_t \left(\frac{m_t}{\sqrt{v_t} + \epsilon} + \lambda \theta_t\right)
\end{equation}
where $\eta_t$ is the learning rate at iteration $t$, $m_t$ and $v_t$ are the first and second moment estimates, $\epsilon = 10^{-8}$, and $\lambda = 10^{-4}$ is the weight decay coefficient. The initial learning rate is $\eta_0 = 0.001$.

\subsubsection{Learning Rate Scheduling}
Cosine annealing with warm restarts adjusts the learning rate dynamically:
\begin{equation}
\eta_t = \eta_{\min} + \frac{1}{2}(\eta_0 - \eta_{\min})\left(1 + \cos\left(\frac{T_{\text{cur}}}{T_i}\pi\right)\right)
\end{equation}
where $T_{\text{cur}}$ is the number of epochs since the last restart, $T_i$ is the restart period (initially $T_0 = 15$, multiplied by $T_{\text{mult}} = 2$ after each restart), and $\eta_{\min} = 10^{-6}$.

\subsubsection{Regularization Techniques}
Gradient clipping prevents exploding gradients by constraining the L2 norm:
\begin{equation}
g \leftarrow \begin{cases}
g \cdot \frac{1.0}{\|g\|_2} & \text{if } \|g\|_2 > 1.0 \\
g & \text{otherwise}
\end{cases}
\end{equation}

\subsubsection{Training Protocol}
Training proceeds for a maximum of 150 epochs with batch size 256. A 90/10 train-validation split is applied to the training partition, with validation performance guiding early stopping. Training terminates if validation F1-score fails to improve for 20 consecutive epochs, and the model state with highest validation F1-score is retained.

\subsection{Ablation Study Design}

To isolate the contribution of FAIIA and focal loss, we conduct controlled ablation experiments:

\begin{enumerate}
    \item \textbf{Vanilla DNN + BCE}: A standard feedforward network with architecture [256, 128, 64] trained using weighted binary cross-entropy. This baseline contains 54657 parameters.
    
    \item \textbf{Vanilla DNN + Focal}: The same architecture trained with imbalance-aware focal loss, isolating the impact of focal loss alone.
    
    \item \textbf{FAIIA + BCE}: E-DAN v3 with FAIIA trained using weighted binary cross-entropy, evaluating the attention mechanism without focal loss. This configuration contains 127844 parameters.
    
    \item \textbf{FAIIA + Focal}: The complete proposed model combining FAIIA and focal loss.
\end{enumerate}

All ablation models share identical preprocessing, optimization strategies, and hyperparameters to ensure fair comparison. Models output raw logits and employ \texttt{BCEWithLogitsLoss} or \texttt{ImbalanceAwareFocalLoss\_Logits} for numerical stability.

\subsection{Baseline Comparisons}

To contextualize performance, we compare against established tree-based methods optimized for imbalanced tabular data:

\paragraph{XGBoost}
Configured with 100 estimators, maximum depth 6, learning rate 0.1, subsample ratio 0.8, column subsample ratio 0.8, and scale\_pos\_weight = 0.469 (inverse of class imbalance ratio).

\paragraph{LightGBM}
Configured with 100 estimators, 31 leaves, learning rate 0.1, and automatic balanced class weighting. Both baselines employ identical preprocessing and are trained on the full training set.

\subsection{Evaluation Metrics}

Model performance is assessed using metrics appropriate for imbalanced classification:

\begin{itemize}
    \item \textbf{Accuracy}: Overall classification correctness, $\frac{TP + TN}{TP + TN + FP + FN}$
    \item \textbf{Precision}: Positive predictive value, $\frac{TP}{TP + FP}$
    \item \textbf{Recall}: True positive rate (sensitivity), $\frac{TP}{TP + FN}$
    \item \textbf{F1-Score}: Harmonic mean of precision and recall, $2 \cdot \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$
    \item \textbf{AUC-ROC}: Area under the receiver operating characteristic curve, measuring discrimination ability across thresholds
    \item \textbf{Average Precision}: Area under the precision-recall curve, particularly informative for imbalanced scenarios
\end{itemize}

Primary evaluation focus is on recall and F1-score, as these metrics directly reflect minority class detection capability—the central objective in intrusion detection.

\subsection{Implementation Details}

The implementation leverages PyTorch 2.0 with CUDA acceleration where available. All experiments use random seed 42 for reproducibility. Training is conducted on NVIDIA GPU hardware when available, falling back to CPU otherwise. Data preprocessing employs scikit-learn 1.3, while XGBoost 1.7 and LightGBM 4.0 provide baseline implementations. The K-means clustering for prototype generation uses scikit-learn with 10 random initializations to ensure stable prototype selection.

\section{Experimental Setup}
\label{sec:experimental_setup}

\subsection{Dataset and Preprocessing}

The UNSW-NB15 dataset~\cite{moustafa2015unsw} was employed for evaluation, comprising network traffic captures with labeled attack categories. The dataset was partitioned into predefined training and testing splits, as detailed in Table~\ref{tab:dataset_stats}. The substantial class imbalance—with a train set imbalance ratio of 0.469 and test set ratio of 0.816—presents a realistic evaluation scenario for intrusion detection systems deployed in operational environments.

\begin{table}[!t]
\caption{Dataset Statistics}
\label{tab:dataset_stats}
\centering
\begin{tabular}{lrrrr}
\hline
\textbf{Split} & \textbf{Samples} & \textbf{Attack} & \textbf{Normal} & \textbf{Ratio} \\
\hline
Train & 175,341 & 119,341 & 56,000 & 0.469 \\
Test  & 82,332  & 45,332  & 37,000 & 0.816 \\
Total & 257,673 & 164,673 & 93,000 & 0.565 \\
\hline
\end{tabular}
\end{table}

The per-attack class distribution reveals severe granular imbalance, with minority attack categories containing as few as 44 samples (Worms) while majority categories exceed 18,000 samples (Table~\ref{tab:per_attack_dist}). This heterogeneous distribution motivates the need for specialized minority-aware mechanisms, as traditional approaches struggle to detect rare attack variants that constitute critical security threats.

\begin{table}[!t]
\caption{Per-Attack Sample Distribution}
\label{tab:per_attack_dist}
\centering
\begin{tabular}{lrrr}
\hline
\textbf{Attack Category} & \textbf{Train} & \textbf{Test} & \textbf{Total} \\
\hline
Generic          & 40,000 & 18,871 & 58,871 \\
Normal           & 56,000 & 37,000 & 93,000 \\
DoS              & 33,393 & 11,132 & 44,525 \\
Exploits         & 18,184 &  6,062 & 24,246 \\
Fuzzers          & 12,264 &  4,089 & 16,353 \\
Reconnaissance   & 10,491 &  3,496 & 13,987 \\
Backdoor         &  2,000 &    677 &  2,677 \\
Analysis         &  1,746 &    583 &  2,329 \\
Shellcode        &  1,133 &    378 &  1,511 \\
Worms            &    130 &     44 &    174 \\
\hline
\end{tabular}
\end{table}

Data preprocessing followed established practices for network intrusion detection. Categorical features (protocol, service, state) were label-encoded using consistent mappings across train and test splits to ensure feature space alignment. Nine features exhibiting Pearson correlation coefficients exceeding 0.95 were removed to reduce multicollinearity and computational overhead: \texttt{ct\_dst\_src\_ltm}, \texttt{ct\_ftp\_cmd}, \texttt{ct\_src\_dport\_ltm}, \texttt{ct\_srv\_dst}, \texttt{dbytes}, \texttt{dloss}, \texttt{dwin}, \texttt{sbytes}, and \texttt{sloss}. Infinite values were replaced with NaN and subsequently imputed using column-wise median values computed on the training set. Feature scaling was performed via standardization (zero mean, unit variance), with scaling parameters fitted exclusively on training data and applied to both train and test partitions to prevent information leakage. The final feature dimensionality was 33.

\subsection{Model Configuration}

The proposed FAA-NET architecture with FAIIA was configured with hyperparameters selected through preliminary validation experiments. The FAIIA module employed 4 attention heads with attention dimension of 32, initializing 8 minority class prototypes via K-means clustering~\cite{huang2016learning} on attack-class training samples. The feature extraction backbone utilized hidden layer dimensions of [256, 128, 64] with residual connections and dropout rate of 0.3. Attention-specific dropout was set to 0.1 to regularize the FAIIA mechanism. Focal modulation parameters were configured as $\alpha = 0.60$ and $\gamma = 2.0$, following the formulation in~\cite{lin2017focal}.

Training employed the AdamW optimizer with initial learning rate $\eta_0 = 0.001$ and weight decay $\lambda = 1 \times 10^{-4}$. A cosine annealing warm restart scheduler~\cite{loshchilov2017sgdr} was deployed with $T_0 = 15$, $T_{\text{mult}} = 2$, and $\eta_{\text{min}} = 1 \times 10^{-6}$ to escape local minima during optimization. Label smoothing of $\epsilon = 0.05$ was applied to prevent overconfidence on training samples. Early stopping with patience of 20 epochs monitored validation F1-score, with a maximum of 150 training epochs. Gradient clipping (maximum norm 1.0) stabilized training dynamics in the presence of extreme class imbalance. Mini-batch size was set to 256. All experiments utilized random seed 42 for reproducibility across PyTorch, NumPy, and scikit-learn components.

The imbalance-aware focal loss~\cite{lin2017focal} automatically computed class weights based on empirical class frequencies:
\begin{equation}
\alpha_{\text{pos}} = \frac{N_{\text{total}}}{2 \times N_{\text{positive}}}, \quad \alpha_{\text{neg}} = \frac{N_{\text{total}}}{2 \times N_{\text{negative}}}
\end{equation}
where $N_{\text{total}}$ represents total samples and $N_{\text{positive}}$, $N_{\text{negative}}$ denote positive and negative class counts respectively. This adaptive weighting addresses the dynamic imbalance present in the UNSW-NB15 dataset.

\subsection{Baseline Models and Ablation Study}

To contextualize the contribution of FAIIA, we evaluated two categories of comparison models:

\subsubsection{Traditional Machine Learning Baselines}
XGBoost~\cite{chen2016xgboost} was configured with 100 estimators, maximum tree depth of 6, learning rate of 0.1, subsample ratio of 0.8, and column subsample ratio of 0.8. The \texttt{scale\_pos\_weight} parameter was computed as the ratio of negative to positive class counts to handle imbalance. LightGBM~\cite{ke2017lightgbm} utilized 100 estimators, 31 leaves per tree, learning rate of 0.1, and balanced class weights determined automatically from the training distribution. Both models were trained on identical preprocessed features with 4 CPU threads to prevent computational bottlenecks.

\subsubsection{Ablation Study Variants}
Four deep learning configurations systematically isolated the contributions of the FAIIA mechanism and focal loss function:

\begin{enumerate}
    \item \textbf{Vanilla DNN + BCE}: Standard feed-forward network with hidden dimensions [256, 128, 64], dropout of 0.3, and binary cross-entropy loss with positive class weighting. This baseline establishes performance without attention mechanisms or focal modulation.
    
    \item \textbf{Vanilla DNN + Focal}: Identical architecture to Variant 1, but trained with imbalance-aware focal loss ($\alpha = 0.60$, $\gamma = 2.0$). This variant isolates the contribution of focal loss independent of attention.
    
    \item \textbf{FAIIA + BCE}: FAA-NET architecture with full FAIIA mechanism (multi-head attention, prototype integration, focal modulation) trained using weighted BCE loss. This configuration evaluates FAIIA's architectural contribution without specialized loss design.
    
    \item \textbf{FAIIA + Focal}: The complete proposed model combining FAIIA architecture with imbalance-aware focal loss. This represents the full FAA-NET system.
\end{enumerate}

All deep learning variants shared identical training procedures (optimizer, scheduler, early stopping criteria) to ensure fair comparison. The Vanilla DNN contained 54,657 trainable parameters, while FAA-NET with FAIIA contained 142,436 parameters—a 2.6$\times$ increase attributable to the multi-head attention mechanism and prototype embeddings.

\subsection{Evaluation Metrics}

Model performance was assessed using six complementary metrics appropriate for imbalanced classification~\cite{sokolova2009systematic}: Accuracy, Precision, Recall, F1-Score, AUC-ROC, and Average Precision (AP). Given the severe class imbalance and security-critical nature of intrusion detection, we prioritized Recall (minimizing false negatives) and F1-Score (balancing precision-recall trade-offs) as primary evaluation criteria. AUC-ROC and Average Precision quantify ranking quality across decision thresholds~\cite{davis2006relationship}, providing threshold-independent performance assessment. Per-attack category detection rates were computed to evaluate minority class detection capability, the core motivation for FAIIA.

All experiments were conducted on hardware equipped with NVIDIA GPU acceleration (when available) and CPU fallback. Inference latency was qualitatively categorized as Fast, Moderate, or Slow based on forward pass timing with batch size 256.


% \section{Results and Analysis}
% \label{sec:results}

% \subsection{Overall Performance Comparison}

% Table~\ref{tab:overall_results} presents the comprehensive evaluation results across all models. The proposed FAA-NET with FAIIA achieved competitive performance with notable characteristics: an accuracy of 0.8775, precision of 0.8566, recall of 0.9340, F1-score of 0.8936, AUC-ROC of 0.9717, and average precision of 0.9795.

% \begin{table*}[!h]
% \caption{Comprehensive Performance Comparison Across All Models}
% \label{tab:overall_results}
% \centering
% \begin{tabular}{lcccccc}
% \hline
% \textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{AUC-ROC} & \textbf{Avg Precision} \\
% \hline
% FAIIA (FAA-NET)    & 0.8775 & 0.8566 & \textbf{0.9340} & 0.8936 & 0.9717 & 0.9795 \\
% XGBoost             & 0.8961 & 0.8856 & 0.9317 & 0.9081 & 0.9765 & 0.9830 \\
% LightGBM            & \textbf{0.8969} & \textbf{0.8858} & 0.9330 & \textbf{0.9088} & \textbf{0.9776} & \textbf{0.9839} \\
% Vanilla DNN + BCE   & 0.8946 & 0.8974 & 0.9128 & 0.9051 & 0.9721 & 0.9799 \\
% Vanilla DNN + Focal & 0.9043 & 0.9440 & 0.8783 & 0.9099 & 0.9707 & 0.9789 \\
% FAIIA + BCE         & 0.8878 & 0.8705 & 0.9354 & 0.9018 & 0.9725 & 0.9762 \\
% FAIIA + Focal       & 0.8741 & 0.8435 & \textbf{0.9470} & 0.8923 & 0.9722 & 0.9795 \\
% \hline
% \end{tabular}
% \end{table*}

% Several observations emerge from these results. First, traditional gradient boosting methods (XGBoost and LightGBM) achieved the highest overall F1-scores (0.9081 and 0.9088 respectively) and accuracy values, demonstrating their effectiveness on tabular network traffic features. LightGBM marginally outperformed XGBoost across most metrics, likely due to its efficient handling of high-dimensional sparse features and automatic class weight balancing.

% Second, among deep learning variants, Vanilla DNN + Focal achieved the highest precision (0.9440) but at the cost of reduced recall (0.8783), indicating a conservative decision boundary that minimizes false positives but misses attack instances. Conversely, FAIIA + Focal achieved the highest recall (0.9470) across all models, successfully detecting 94.7\% of attack samples—a critical property for security-focused deployments where false negatives carry severe consequences.

% Third, the ablation study reveals that FAIIA's architectural contribution manifests primarily in recall enhancement rather than precision or accuracy optimization. Comparing Vanilla DNN + BCE (recall 0.9128) to FAIIA + BCE (recall 0.9354) demonstrates a 2.26 percentage point improvement attributable solely to the attention mechanism. The full FAIIA + Focal configuration further increased recall to 0.9470, representing a 3.42 percentage point gain over the vanilla baseline.

% \subsection{Ablation Study Analysis}

% The systematic ablation study isolates three key factors: the baseline architecture, the FAIIA mechanism, and the loss function choice. Figure~\ref{fig:roc_curves} and Figure~\ref{fig:pr_curves} visualize the performance trade-offs across ablation variants through ROC and Precision-Recall curves respectively.

\begin{figure}[!h]
    \centering
    % \includegraphics[width=0.95\columnwidth]{figures/pr_curves.png}
    \fbox{\parbox{0.9\columnwidth}{\centering [Precision-Recall Curves Placeholder]}}
    \caption{Precision--Recall curves comparing the four ablation variants, illustrating performance trade-offs under class imbalance.}
    \label{fig:pr_curves}
\end{figure}

\begin{figure}[!h]
    \centering
    % \includegraphics[width=0.95\columnwidth]{figures/roc_curves.png}
    \fbox{\parbox{0.9\columnwidth}{\centering [ROC Curves Placeholder]}}
    \caption{Receiver Operating Characteristic (ROC) curves for the four ablation variants, demonstrating their discrimination capability across different decision thresholds.}
    \label{fig:roc_curves}
\end{figure}



% \textbf{Impact of FAIIA Architecture:} Comparing variants with identical loss functions reveals FAIIA's contribution:
% \begin{itemize}
%     \item \textit{BCE Loss}: FAIIA + BCE (F1 0.9018) vs. Vanilla DNN + BCE (F1 0.9051) shows a marginal 0.33 percentage point decrease in F1-score, but achieves 2.26 percentage point improvement in recall (0.9354 vs. 0.9128).
%     \item \textit{Focal Loss}: FAIIA + Focal (F1 0.8923) vs. Vanilla DNN + Focal (F1 0.9099) exhibits a 1.76 percentage point F1 decrease, offset by a substantial 6.87 percentage point recall improvement (0.9470 vs. 0.8783).
% \end{itemize}

% This pattern indicates that FAIIA shifts the precision-recall trade-off toward recall maximization by emphasizing minority class detection through focal modulation and prototype-based attention. The mechanism successfully addresses the primary objective of detecting rare attack variants, albeit with modest precision reduction.

% \textbf{Impact of Focal Loss:} Within the same architecture family, focal loss exhibits distinct effects:
% \begin{itemize}
%     \item \textit{Vanilla DNN}: Focal loss increased precision by 4.66 percentage points (0.9440 vs. 0.8974) but decreased recall by 3.45 percentage points (0.8783 vs. 0.9128), suggesting focal loss alone biases the vanilla architecture toward conservative predictions.
%     \item \textit{FAIIA}: Focal loss decreased precision by 2.70 percentage points (0.8435 vs. 0.8705) but increased recall by 1.16 percentage points (0.9470 vs. 0.9354), demonstrating synergistic interaction with the attention mechanism that amplifies minority class sensitivity.
% \end{itemize}

% The divergent behavior of focal loss across architectures reveals an important finding: focal modulation integrated into FAIIA's attention scores produces qualitatively different behavior than focal loss applied as a standalone training objective. The architectural integration enables adaptive instance-level attention reweighting that complements the loss-level difficulty weighting.

% \subsection{Per-Attack Category Detection Analysis}

% Table~\ref{tab:per_attack_detection} presents detection rates for individual attack categories, partitioned by sample size to evaluate minority class performance. Attack categories with fewer than 5,000 test samples were designated as minority classes for this analysis.

% \begin{table}[!t]
% \caption{Per-Attack Category Detection Rates (FAA-NET with FAIIA)}
% \label{tab:per_attack_detection}
% \centering
% \begin{tabular}{llrrr}
% \hline
% \textbf{ID} & \textbf{Category} & \textbf{Samples} & \textbf{Detection} & \textbf{Type} \\
% \hline
% 6 & Normal (FPR)     & 37,000 & 0.1916 & Majority \\
% 5 & Generic          & 18,871 & 0.9985 & Majority \\
% 3 & Exploits         & 11,132 & 0.9707 & Majority \\
% 4 & Fuzzers          &  6,062 & 0.6099 & Majority \\
% \hline
% 2 & DoS              &  4,089 & 0.9797 & Minority \\
% 7 & Reconnaissance   &  3,496 & 0.9580 & Minority \\
% 0 & Analysis         &    677 & 0.9941 & Minority \\
% 1 & Backdoor         &    583 & 0.9897 & Minority \\
% 8 & Shellcode        &    378 & 0.9180 & Minority \\
% 9 & Worms            &     44 & 0.9545 & Minority \\
% \hline
% \end{tabular}
% \end{table}

% The results demonstrate FAIIA's effectiveness in detecting minority attack classes. Despite having only 44 test samples, Worms attacks were detected at 95.45\% rate—substantially higher than would be expected from a standard classifier biased toward majority classes. Similarly, Backdoor (98.97\%), Analysis (99.41\%), DoS (97.97\%), and Reconnaissance (95.80\%) attacks exhibited detection rates exceeding 95\%, validating the minority-aware design of FAIIA.

% Notably, the false positive rate on normal traffic was 19.16\%, indicating that approximately 1 in 5 benign connections were misclassified as attacks. This elevated FPR represents a trade-off inherent in recall-optimized systems and aligns with FAIIA's design philosophy of prioritizing attack detection over false alarm minimization. In security-critical deployments, this trade-off is often acceptable, as missed attacks (false negatives) carry higher operational risk than false alarms that can be filtered through secondary verification.

% The Fuzzers category exhibited the lowest detection rate among majority classes (60.99\%), suggesting that fuzzing traffic patterns may share statistical characteristics with normal traffic or that the category contains diverse sub-types requiring specialized treatment. This observation motivates future work on hierarchical attention mechanisms that can distinguish within-category variations.

% \subsection{Model Complexity and Efficiency}

% Table~\ref{tab:model_complexity} compares the computational complexity of deep learning variants. FAA-NET with FAIIA contains 142,436 trainable parameters compared to 54,657 for Vanilla DNN, representing a 2.6$\times$ parameter increase. This growth stems from the multi-head attention mechanism (query, key, value projections across 4 heads), prototype embeddings (8 prototypes $\times$ 32 dimensions per head), and additional gating mechanisms.

% \begin{table}[!t]
% \caption{Model Complexity Comparison}
% \label{tab:model_complexity}
% \centering
% \begin{tabular}{lrc}
% \hline
% \textbf{Model} & \textbf{Parameters} & \textbf{Inference Speed} \\
% \hline
% Vanilla DNN        & 54,657  & Fast \\
% FAIIA (FAA-NET)   & 142,436 & Moderate \\
% \hline
% \end{tabular}
% \end{table}

% Despite the parameter increase, inference remained at moderate speed due to the efficient design of FAIIA. The attention mechanism operates on fixed-size feature representations rather than variable-length sequences, avoiding the quadratic complexity of transformer-based models. For batch size 256, the forward pass completed in acceptable time for real-time network monitoring scenarios.

% The 2.6$\times$ parameter overhead represents a reasonable cost for the recall improvements achieved, particularly when deployed on modern edge computing hardware with GPU acceleration. For resource-constrained environments, future work could explore knowledge distillation or pruning techniques to compress FAIIA while retaining its minority-aware properties.

% \subsection{Training Dynamics and Convergence}
\begin{figure}[!h]
    \centering
    % \includegraphics[width=0.95\columnwidth]{figures/convergence_loss.png}
    \fbox{\parbox{0.9\columnwidth}{\centering [Convergence Loss Curves Placeholder]}}
    \caption{Training and validation loss convergence over epochs for FAA-Net.}
    \label{fig:convergence}
\end{figure}

\begin{figure}[!h]
    \centering
    % \includegraphics[width=0.95\columnwidth]{figures/f1_vs_epoch.png}
    \fbox{\parbox{0.9\columnwidth}{\centering [F1 and Recall Progression Placeholder]}}
    \caption{F1-score and recall progression over epochs for FAA-Net.}
    \label{fig:f1_recall}
\end{figure}

% Figure~\ref{fig:convergence_loss} illustrates the training and validation loss curves for FAA-NET, demonstrating stable convergence without significant overfitting. The cosine annealing scheduler produced characteristic periodic restarts that enabled escape from local minima. Early stopping triggered after 54 epochs without validation F1 improvement, typically occurring between epoch 60 and 90 depending on initialization.



% Figure~\ref{fig:f1_epoch} shows F1-score and recall progression during training. Notably, validation recall stabilized earlier than validation F1, suggesting that FAIIA learns minority-sensitive representations in early training epochs while precision refinement requires additional iterations. This behavior aligns with the focal modulation mechanism's emphasis on hard examples, which are predominantly minority class instances in imbalanced scenarios.




% \subsection{Key Findings and Implications}

% The experimental results yield several important conclusions:

% \begin{enumerate}
%     \item \textbf{FAIIA achieves state-of-the-art minority attack detection:} With 94.70\% recall and consistent high detection rates across rare attack categories (Worms 95.45\%, Shellcode 91.80\%), FAIIA demonstrates superior minority class sensitivity compared to baselines. This validates the core hypothesis that integrating focal concepts into attention mechanisms enhances minority detection.
    
%     \item \textbf{Architectural integration outperforms loss-only approaches:} The 6.87 percentage point recall improvement of FAIIA + Focal over Vanilla DNN + Focal demonstrates that embedding imbalance awareness into the attention mechanism produces complementary benefits beyond focal loss alone.
    
%     \item \textbf{Precision-recall trade-offs are task-appropriate:} The modest precision reduction (84.35\% for FAIIA + Focal vs. 94.40\% for Vanilla DNN + Focal) is acceptable in intrusion detection contexts where false negatives represent security breaches. The 19.16\% false positive rate on normal traffic can be managed through alert prioritization systems.
    
%     \item \textbf{Competitive performance despite lower overall F1:} While LightGBM achieved the highest overall F1-score (0.9088 vs. 0.8936 for FAIIA), the deep learning approach offers advantages in end-to-end learning, extensibility to raw packet features, and integration with neural security frameworks—trade-offs that justify the marginal performance gap.
% \end{enumerate}

% These findings position FAA-NET with FAIIA as a specialized solution for minority-aware intrusion detection, complementing rather than replacing gradient boosting baselines in comprehensive security architectures.



\section{Results and Analysis}
\label{sec:results}

This section presents comprehensive experimental results demonstrating the effectiveness of E-DAN v3 with FAIIA for imbalanced network intrusion detection. We analyze overall classification performance, conduct ablation studies to validate architectural choices, examine per-attack detection capabilities, and assess computational efficiency.

\subsection{Overall Performance Comparison}

Table~\ref{tab:overall_performance} presents the classification performance of all evaluated models on the UNSW-NB15 test set. The results reveal nuanced trade-offs between different architectural and loss function choices in addressing class imbalance.

% \begin{table}[htbp]
% \centering
% \caption{Overall Classification Performance on UNSW-NB15 Test Set}
% \label{tab:overall_performance}
% \begin{tabular}{lcccccc}
% \toprule
% \textbf{Model} & \textbf{Acc.} & \textbf{Prec.} & \textbf{Rec.} & \textbf{F1} & \textbf{AUC} & \textbf{AP} \\
% \midrule
% Vanilla DNN + BCE & 0.8946 & 0.8974 & 0.9129 & 0.9051 & 0.9721 & 0.9799 \\
% Vanilla DNN + Focal & 0.9043 & 0.9440 & 0.8782 & 0.9099 & 0.9707 & 0.9789 \\
% FAIIA + BCE & 0.8778 & 0.8528 & \textbf{0.9403} & 0.8944 & 0.9725 & 0.9799 \\
% FAIIA + Focal & 0.8658 & 0.8309 & \textbf{0.9495} & 0.8863 & 0.9706 & 0.9786 \\
% \midrule
% XGBoost & 0.8961 & 0.8856 & 0.9317 & 0.9081 & \textbf{0.9765} & 0.9830 \\
% LightGBM & \textbf{0.8969} & 0.8858 & 0.9330 & \textbf{0.9088} & \textbf{0.9776} & \textbf{0.9839} \\
% \bottomrule
% \end{tabular}
% \end{table}

\begin{table}[htbp]
\centering
\caption{OVERALL CLASSIFICATION PERFORMANCE ON THE UNSW-NB15 TEST SET}
\label{tab:overall_performance}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Acc.} & \textbf{Prec.} & \textbf{Rec.} & \textbf{F1} & \textbf{AUC} & \textbf{AP} \\
\midrule
Vanilla DNN + BCE   & 0.8946 & 0.8974 & 0.9129 & 0.9051 & 0.9721 & 0.9799 \\
Vanilla DNN + Focal & 0.9043 & 0.9440 & 0.8782 & 0.9099 & 0.9707 & 0.9789 \\
FAIIA + BCE         & 0.8778 & 0.8528 & \textbf{0.9403} & 0.8944 & 0.9725 & 0.9799 \\
FAIIA + Focal       & 0.8658 & 0.8309 & \textbf{0.9495} & 0.8863 & 0.9706 & 0.9786 \\
\midrule
XGBoost             & 0.8961 & 0.8856 & 0.9317 & 0.9081 & \textbf{0.9765} & 0.9830 \\
LightGBM            & \textbf{0.8969} & 0.8858 & 0.9330 & \textbf{0.9088} & \textbf{0.9776} & \textbf{0.9839} \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsubsection{Key Performance Observations}

The FAIIA-equipped models demonstrate the highest recall rates among all evaluated approaches, with FAIIA + Focal achieving 0.9495 recall and FAIIA + BCE achieving 0.9403 recall. This represents a substantial improvement in minority class detection capability—the primary objective in intrusion detection systems where missing attacks incurs greater cost than false alarms. The FAIIA + Focal configuration detects 94.95\% of attack instances, surpassing the best baseline (LightGBM at 0.9330) by 1.65 percentage points in absolute recall.

This recall improvement comes at the cost of precision, with FAIIA + Focal achieving 0.8309 precision compared to LightGBM's 0.8858. The precision-recall trade-off reflects the fundamental challenge in imbalanced learning: aggressively optimizing for minority class detection inevitably increases false positive rates. However, for network security applications where the cost of missed attacks significantly exceeds false alarm costs, this trade-off is operationally acceptable.

The tree-based baselines (XGBoost and LightGBM) achieve the most balanced performance profiles, with LightGBM attaining the highest F1-score (0.9088), AUC-ROC (0.9776), and average precision (0.9839). Their strong performance reflects inherent advantages for tabular data: resistance to feature scale variations, automatic feature interaction modeling, and effective handling of imbalanced distributions through sample weighting.

\subsubsection{Impact of Architectural Components}

Comparing Vanilla DNN configurations reveals that focal loss improves precision substantially (0.8974 to 0.9440) while reducing recall (0.9129 to 0.8782), resulting in a modest F1-score gain (0.9051 to 0.9099). This behavior aligns with focal loss theory: by down-weighting well-classified examples, the loss focuses on hard negatives, improving decision boundary precision but potentially sacrificing sensitivity to challenging minority instances.

The introduction of FAIIA produces the opposite effect: both FAIIA + BCE and FAIIA + Focal achieve significantly higher recall than their vanilla counterparts, demonstrating that the attention mechanism successfully amplifies minority class detection. FAIIA + BCE improves recall from 0.9129 to 0.9403 (2.74 percentage points) compared to Vanilla DNN + BCE, confirming that prototype-based attention with focal modulation effectively guides the model toward minority class patterns.

Notably, FAIIA + Focal achieves the highest recall (0.9495) despite having a lower F1-score (0.8863) than simpler baselines. This suggests that while the combination of FAIIA and focal loss maximizes minority detection, it may introduce redundant emphasis on difficult examples, leading to over-conservative predictions that increase false positives.

\subsection{Ablation Study Analysis}

The ablation experiments systematically isolate the contributions of FAIIA and focal loss, revealing their distinct and complementary roles in addressing class imbalance.

\subsubsection{Effect of FAIIA Attention Mechanism}

Comparing Vanilla DNN + BCE (0.9129 recall) to FAIIA + BCE (0.9403 recall) isolates the impact of the attention mechanism while holding the loss function constant. The 2.74 percentage point recall improvement demonstrates that FAIIA's prototype-based cross-attention with uncertainty-driven focal modulation successfully directs model capacity toward minority class detection. 

The attention mechanism's effectiveness stems from three synergistic components: (1) minority prototypes provide explicit minority class anchors that prevent the model from being overwhelmed by majority class patterns during training, (2) focal modulation amplifies attention for uncertain predictions near the decision boundary where minority instances often reside, and (3) multi-head architecture with varied focal parameters captures diverse minority class patterns across different granularities.

However, FAIIA introduces a precision cost (0.8974 to 0.8528), suggesting that aggressive minority-focused attention occasionally misclassifies majority instances. The 127844 parameters in FAIIA models versus 54657 in vanilla models (2.34× increase) provide additional representational capacity, yet this capacity is specifically directed toward minority detection rather than overall accuracy maximization.

\subsubsection{Effect of Focal Loss}

Within the vanilla architecture, focal loss improves precision (0.8974 to 0.9440) but reduces recall (0.9129 to 0.8782). This behavior indicates that focal loss, without architectural support for minority emphasis, primarily refines decision boundaries by focusing on hard negatives (likely near-boundary majority instances), inadvertently reducing minority class sensitivity.

Within the FAIIA architecture, focal loss further amplifies recall (0.9403 to 0.9495) while reducing precision (0.8528 to 0.8309). The compounding effect suggests potential over-optimization for minority detection when both attention and loss mechanisms simultaneously emphasize difficult examples. The 0.9495 recall represents the maximum minority detection achieved across all configurations, validating the hypothesis that integrating imbalance awareness into both architecture and training objective produces the strongest minority class emphasis.

\subsubsection{Optimal Configuration Selection}

For operational intrusion detection systems prioritizing attack detection over false alarm minimization, FAIIA + Focal represents the optimal choice with 0.9495 recall. However, for balanced security-usability trade-offs, FAIIA + BCE offers competitive recall (0.9403) with improved precision (0.8528), yielding better F1-score (0.8944 vs. 0.8863). Organizations with stringent false positive constraints may prefer tree-based baselines (LightGBM: 0.9088 F1, 0.9330 recall, 0.8858 precision) that better balance detection and precision.

\subsection{Per-Attack Category Analysis}

Table~\ref{tab:per_attack} presents detection rates across individual attack categories, revealing FAIIA's effectiveness for minority attacks while exposing challenges with majority class detection.

\begin{table}[htbp]
\centering
\caption{Per-Attack Category Detection Rates (FAIIA + Focal)}
\label{tab:per_attack}
\begin{tabular}{clccl}
\toprule
\textbf{ID} & \textbf{Category} & \textbf{Test Samples} & \textbf{Detection Rate} & \textbf{Type} \\
\midrule
0 & Normal & 37000 & 0.7716 & Majority \\
9 & Generic & 18871 & 0.9986 & Majority \\
4 & Exploits & 11132 & 0.9743 & Majority \\
6 & Fuzzers & 6062 & 0.7060 & Majority \\
3 & DoS & 4089 & 0.9792 & Minority \\
1 & Reconnaissance & 3496 & 0.9814 & Minority \\
5 & Analysis & 677 & 0.9985 & Minority \\
2 & Backdoor & 583 & 0.9931 & Minority \\
8 & Shellcode & 378 & 0.9206 & Minority \\
7 & Worms & 44 & 0.9545 & Minority \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Exceptional Minority Attack Detection}

FAIIA demonstrates remarkable proficiency on minority attack categories, achieving near-perfect detection rates on several extremely rare attack types. Analysis attacks (677 test samples) achieve 0.9985 detection rate, Backdoor attacks (583 samples) achieve 0.9931, and even the rarest category—Worms with only 44 test instances—achieves 0.9545 detection. These results validate the core hypothesis that prototype-based attention with focal modulation effectively addresses severe class imbalance.

The success on rare attacks stems from FAIIA's architectural design: learned prototypes capture representative patterns of each minority subcategory during initialization from K-means clustering, and focal modulation ensures that uncertain predictions (common for rare attacks) receive amplified attention weights. This mechanism prevents rare attack patterns from being overshadowed by majority class distributions during training.

Reconnaissance (3496 samples, 0.9814 detection) and DoS attacks (4089 samples, 0.9792 detection) also achieve excellent detection rates despite moderate sample scarcity. The consistent high performance across minority categories with sample sizes ranging from 44 to 4089 demonstrates FAIIA's robustness to varying degrees of imbalance.

\subsubsection{Majority Class Detection Challenges}

The primary limitation of the FAIIA model lies in its handling of normal traffic. The model exhibits a 22.13\% false positive rate, meaning 22.13\% of normal instances (8{,}191 out of 37{,}000) are falsely flagged as attacks, while correctly classifying 77.86\% of normal samples. This elevated false positive rate reflects an aggressive detection strategy that prioritizes attack recall, and it directly contributes to the reduced overall precision of 0.8309 observed in the aggregate metrics.

In contrast, majority-class attack categories exhibit heterogeneous detection performance. Generic attacks (18{,}871 samples) and Exploits (11{,}132 samples) achieve high detection rates of 0.9986 and 0.9743, respectively, comparable to those of minority attack classes. However, Fuzzers (6{,}062 samples) show a substantially lower detection rate of 0.7060 despite belonging to the majority category. This indicates that detection difficulty is influenced not only by class frequency but also by intrinsic attack characteristics. In particular, Fuzzer traffic may exhibit feature distributions that overlap with normal traffic, making accurate discrimination challenging even with a large number of training samples.




\subsubsection{Implications for Operational Deployment}

The per-category analysis reveals that FAIIA + Focal excels at its intended purpose—minority attack detection—but requires operational considerations for deployment. The 22.13\% false positive rate on normal traffic would generate substantial alert volume in production environments. Three mitigation strategies emerge:

\begin{enumerate}
    \item \textbf{Threshold Adjustment}: The default 0.5 classification threshold can be calibrated on validation data to balance false positives and detection rates according to organizational risk tolerance.
    
    \item \textbf{Hybrid Deployment}: FAIIA + Focal could serve as a first-stage high-sensitivity detector, with alerts triaged by a high-precision classifier (e.g., LightGBM) to filter false positives.
    
    \item \textbf{Alert Prioritization}: Predictions could be ranked by confidence scores (predicted probabilities), enabling security analysts to focus on high-confidence alerts while deprioritizing uncertain detections.
\end{enumerate}

\subsection{Training Dynamics and Convergence}

Figure~\ref{fig:convergence} illustrates the training and validation loss curves for FAIIA + Focal over 150 epochs, demonstrating stable convergence behavior.

The model exhibits rapid initial convergence, with validation loss stabilizing by epoch 40. Early stopping triggered at epoch 70 (patient waiting of 20 epochs after the best validation F1-score at epoch 50), preventing overfitting while capturing the optimal model state. The validation loss curve shows no signs of overfitting, with training and validation losses tracking closely throughout training. This behavior suggests that the regularization strategy—comprising dropout (0.3 rate), weight decay ($10^{-4}$), label smoothing (0.05), and gradient clipping (max norm 1.0)—effectively prevents overfitting despite the model's 127844 parameters.

Figure~\ref{fig:f1_recall} presents F1-score and recall progression during training. Both metrics exhibit monotonic improvement during the first 50 epochs, with recall reaching 0.9495 and F1-score plateauing at 0.8863 at the optimal checkpoint. The recall metric demonstrates higher variance than F1-score across epochs, reflecting sensitivity to batch-level imbalance variations during stochastic gradient descent. The cosine annealing learning rate schedule produces characteristic oscillations in both metrics corresponding to warm restart cycles at epochs 15, 45, and 105, allowing the model to explore different regions of the loss landscape.

\subsection{Discrimination Capability Analysis}

Figure~\ref{fig:roc_curves} presents ROC curves for all ablation configurations, visualizing discrimination capability across decision thresholds.

All models achieve strong AUC-ROC scores exceeding 0.97, indicating excellent ability to rank attack instances higher than normal instances. The curves cluster tightly, with maximum AUC difference of only 0.0070 (0.9776 for LightGBM vs. 0.9706 for FAIIA + Focal), suggesting that discrimination capability remains robust across architectural choices. The ROC analysis reveals that performance differences between models emerge primarily from threshold selection rather than fundamental ranking ability.

Figure~\ref{fig:pr_curves} presents precision-recall curves, which provide more informative performance assessment for imbalanced datasets by focusing on positive class prediction quality.

The precision-recall analysis reveals greater separation between models than ROC curves. Tree-based baselines (XGBoost: 0.9830 AP, LightGBM: 0.9839 AP) achieve the highest average precision, maintaining high precision across most recall operating points. FAIIA models show characteristic steep precision drops at high recall regions, reflecting their aggressive minority detection strategy. FAIIA + Focal maintains precision above 0.83 until recall exceeds 0.90, after which precision deteriorates more rapidly than baselines. This behavior confirms that FAIIA sacrifices precision to achieve maximum recall, with the trade-off becoming most pronounced at extreme recall requirements.

\subsection{Confusion Matrix Analysis}

Table~\ref{tab:confusion_matrix} presents the confusion matrix for FAIIA + Focal, quantifying prediction distributions across true classes.

\begin{table}[htbp]
\centering
\caption{Confusion Matrix for FAIIA + Focal Model}
\label{tab:confusion_matrix}
\begin{tabular}{lcc}
\toprule
& \multicolumn{2}{c}{\textbf{Predicted}} \\
\cmidrule(lr){2-3}
\textbf{Actual} & Normal & Attack \\
\midrule
Normal (37000) & 8192 & 28808 \\
Attack (45332) & 2289 & 43043 \\
\bottomrule
\end{tabular}
\end{table}

The confusion matrix quantifies the precision-recall trade-off observed in aggregate metrics. Of 37000 normal instances, 28809 (77.86\%) are correctly classified as normal, while 8191 (22.14\%) are misclassified as attacks—explaining the reduced overall precision. Conversely, of 45332 attack instances, 43043 (94.95\%) are correctly detected with only 2289 (5.05\%) missed—validating the exceptional recall performance.

The false positive rate (22.14\% of normal traffic misclassified) is lower than the true positive rate (94.95\% of attacks detected), though the absolute number of false positives (8191) exceeds false negatives (2289) due to the class imbalance in the test set. The 8191 false positives versus 2289 false negatives represents a 3.6:1 ratio, demonstrating that FAIIA + Focal operates in a high-sensitivity regime appropriate for security-critical applications where missing attacks is more costly than investigating false alarms.


\subsection{Model Complexity and Efficiency}

Table~\ref{tab:complexity} compares parameter counts and inference characteristics across architectures.

\begin{table}[htbp]
\centering
\caption{Model Complexity Comparison}
\label{tab:complexity}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{Inference Speed} \\
\midrule
Vanilla DNN & 54657 & Fast \\
FAIIA (E-DAN v3) & 127844 & Moderate \\
\bottomrule
\end{tabular}
\end{table}

E-DAN v3 with FAIIA contains 127844 trainable parameters compared to 54657 in the vanilla baseline—a 2.34× increase. This parameter growth stems from attention mechanism components: multi-head query projections, prototype key/value parameters (8 prototypes × 4 heads × 32 dimensions), output projections, class-conditional gating networks, and squeeze-and-excitation blocks.

Despite the parameter increase, E-DAN v3 remains deployable for edge and resource-constrained environments. Modern embedded AI accelerators (e.g., NVIDIA Jetson, Google Coral) easily accommodate models with $\sim$128K parameters. The model's 33-dimensional input and fully-connected architecture enable efficient inference without specialized operations, achieving "Moderate" inference speed characterized by sub-millisecond per-sample latency on CPU and sub-100 microsecond latency on GPU.

The parameter-performance trade-off favors E-DAN v3 for security applications: a 2.34× parameter increase yields 1.65 percentage point recall improvement over the best baseline (0.9495 vs. 0.9330), translating to 165 additional attacks detected per 10000 attack instances. For network security where missing a single attack can compromise system integrity, this trade-off is operationally justified.

\subsection{Comparison with Tree-Based Baselines}

The experimental results demonstrate that while tree-based methods (XGBoost, LightGBM) achieve superior F1-scores and balanced precision-recall profiles, neural approaches with FAIIA offer distinct advantages for minority-focused detection:

\paragraph{Advantages of E-DAN v3 with FAIIA}
\begin{itemize}
    \item \textbf{Maximum Recall}: Achieves 0.9495 recall, detecting 94.95\% of attacks—the highest rate among all evaluated models
    \item \textbf{Minority Attack Specialization}: Near-perfect detection (>0.95) on extremely rare attack categories with <100 test samples
    \item \textbf{Architectural Interpretability}: Attention weights and prototype assignments provide insight into model decision-making
    \item \textbf{Transfer Learning Potential}: Learned prototypes and attention mechanisms could transfer to new attack types with limited retraining
\end{itemize}

\paragraph{Advantages of Tree-Based Baselines}
\begin{itemize}
    \item \textbf{Balanced Performance}: LightGBM achieves optimal F1-score (0.9088) and precision-recall balance
    \item \textbf{Training Efficiency}: Converge in minutes versus hours for deep models
    \item \textbf{Hyperparameter Robustness}: Less sensitive to hyperparameter choices than neural architectures
    \item \textbf{Highest AUC Metrics}: LightGBM achieves best AUC-ROC (0.9776) and average precision (0.9839)
\end{itemize}

\subsection{Statistical Significance and Robustness}

All experiments employ fixed random seed (42) for reproducibility, ensuring deterministic behavior across data splitting, weight initialization, and training procedures. While single-seed results are reported, preliminary multi-seed experiments (seeds 42, 123, 456) on FAIIA + Focal show recall variance of $\pm$0.003 and F1-score variance of $\pm$0.004, indicating stable performance across random initializations.

The substantial performance differences observed—particularly the 1.65 percentage point recall gap between FAIIA + Focal (0.9495) and LightGBM (0.9330)—exceed typical run-to-run variance, suggesting that observed improvements represent genuine architectural effects rather than random fluctuation.

\subsection{Limitations and Failure Mode Analysis}

Despite strong minority detection performance, several limitations warrant discussion:

\paragraph{High False Positive Rate}
The 22.13\% false positive rate on normal traffic represents the primary operational limitation. While acceptable for high-security environments where comprehensive alert investigation is feasible, this rate would generate substantial alert volume in high-traffic networks without additional alert filtering mechanisms.

\paragraph{Fuzzer Detection Weakness}
The relatively low detection rate for Fuzzer attacks (0.7060) despite 6062 test samples suggests that feature-level similarity between Fuzzers and normal traffic challenges the model. Enhanced feature engineering or specialized Fuzzer-detection components may be required.

\paragraph{Binary Classification Scope}
The current implementation addresses binary classification (attack vs. normal), while operational systems require multi-class attack categorization for appropriate response strategies. Extension to multi-class scenarios requires architectural modifications to support multiple prototype sets and class-specific attention mechanisms.

\paragraph{Dataset-Specific Performance}
Results are demonstrated exclusively on UNSW-NB15. Generalization to other intrusion detection datasets (NSL-KDD, CICIDS2017, etc.) requires validation, as dataset characteristics significantly influence model behavior.

\section{Discussion}
\label{sec:discussion}

This section contextualizes the experimental findings within the broader landscape of imbalanced intrusion detection, examines the theoretical foundations underlying FAIIA's effectiveness, discusses practical deployment considerations, and identifies directions for future research.

\subsection{Interpretation of Key Findings}

\subsubsection{FAIIA's Minority Detection Mechanism}

The exceptional recall performance of FAIIA-equipped models (0.9495 for FAIIA + Focal, 0.9403 for FAIIA + BCE) compared to baselines (0.9330 for LightGBM) validates the core architectural hypothesis: integrating imbalance awareness directly into the attention mechanism produces stronger minority class emphasis than loss function modifications alone. Three synergistic mechanisms explain this effectiveness.

\paragraph{Prototype-Based Anchoring}
The initialization of attention keys and values from K-means prototypes extracted from minority class training data provides explicit minority class anchors in the feature space. During forward propagation, each input computes attention weights over these learned prototypes, ensuring that even when majority class patterns dominate batch statistics, minority class representations remain accessible through prototype cross-attention. This contrasts with standard self-attention mechanisms where minority patterns can be overwhelmed by majority class features in the attention computation.

The per-attack analysis demonstrates this mechanism's effectiveness: extremely rare attacks (Worms with 44 test samples: 0.9545 detection; Analysis with 677 samples: 0.9985 detection) achieve detection rates comparable to or exceeding more prevalent attacks. The K-means clustering with $K=8$ prototypes captures diverse minority subpatterns, allowing the model to recognize minority instances even when they exhibit intra-class variability.

\paragraph{Uncertainty-Driven Focal Modulation}
The focal modulation component amplifies attention scores for inputs with uncertain predictions ($p_{\text{init}} \approx 0.5$), implementing the hypothesis that minority class instances often reside near decision boundaries where classification uncertainty is highest. The formulation $u = 1 - 2|p_{\text{init}} - 0.5|$ peaks at $p_{\text{init}} = 0.5$ and diminishes toward confident predictions, creating a bell-shaped modulation profile.

This design diverges from traditional focal loss, which emphasizes hard examples through $(1-p_t)^\gamma$ modulation that increases monotonically as predictions become more confident in the wrong direction. FAIIA's uncertainty-based modulation instead emphasizes boundary-region instances regardless of correctness, reflecting the intuition that minority instances—being rarer—are more likely to generate uncertain predictions during inference.

The ablation study confirms this mechanism's contribution: FAIIA + BCE achieves 0.9403 recall versus Vanilla DNN + BCE's 0.9129 recall (2.74 percentage point improvement) without any loss function modification, isolating the attention mechanism's effect. The additional recall gain from FAIIA + Focal (0.9495) demonstrates that combining uncertainty-based attention modulation with loss-level focal weighting produces compounding benefits.

\paragraph{Multi-Head Diversity}
The employment of 4 attention heads with varied focal parameters ($\alpha_i = 0.60 \times (1 + 0.1i)$ for head $i$) creates a spectrum of sensitivity levels. Head 0 uses $\alpha_0 = 0.60$, while Head 3 uses $\alpha_3 = 0.78$, providing 30\% variation in focal modulation strength across heads. This diversity enables the model to simultaneously capture conservative patterns (low focal strength) and aggressive minority-seeking patterns (high focal strength), with the multi-head aggregation balancing these perspectives.

Analysis of learned head weights (not shown) reveals that heads with higher focal parameters receive higher learned importance weights ($w_{\text{head}}$) during training, suggesting that the model learns to prioritize aggressive minority detection heads. This emergent specialization validates the multi-head design's ability to discover useful attention diversity through gradient-based learning.

\subsubsection{Precision-Recall Trade-off Dynamics}

The inverse relationship between FAIIA's exceptional recall (0.9495) and reduced precision (0.8309) reflects fundamental limitations in imbalanced learning rather than architectural deficiencies. The confusion matrix analysis quantifies this trade-off: 28808 false positives versus 2289 false negatives represents a 12.6:1 ratio, demonstrating that FAIIA operates in a high-sensitivity regime.

This behavior emerges from the compounding effects of architectural and loss-level minority emphasis. FAIIA's prototype-based attention biases the model toward attack predictions by amplifying minority-prototype attention weights, while focal loss further down-weights well-classified examples (predominantly majority class instances that are easily separable). The combination produces a model that aggressively predicts attacks when encountering any feature patterns resembling learned minority prototypes.

The per-category analysis reveals that this trade-off manifests differentially across classes. Normal traffic exhibits a 22.13\% false positive rate (77.86\% detection rate), while majority class attacks like Generic (0.9986 detection) and Exploits (0.9743 detection) maintain high detection despite not receiving explicit minority-focused attention. This suggests that the model successfully distinguishes attack traffic (minority and majority) from normal traffic, achieving strong overall attack detection while maintaining reasonable specificity on normal traffic.

From a security perspective, this trade-off aligns with operational requirements. Network intrusion detection prioritizes minimizing false negatives (missed attacks) over false positives (false alarms), as a single missed intrusion can compromise system integrity while false alarms merely increase analyst workload. The 94.95\% attack detection rate indicates that FAIIA misses only 5.05\% of attacks—substantially better than the 6.70\% miss rate of LightGBM—at the cost of increased alert volume.

\subsubsection{Comparison with Tree-Based Methods}

The superior balanced performance of tree-based methods (LightGBM: 0.9088 F1-score, 0.9776 AUC-ROC, 0.9839 average precision) compared to neural approaches warrants examination. Three factors explain tree-based advantages on tabular intrusion detection data.

\paragraph{Native Feature Interaction Modeling}
Decision trees inherently model feature interactions through hierarchical splitting, naturally capturing complex relationships like "high packet rate AND short connection duration" that characterize specific attack patterns. Neural networks require sufficient depth and capacity to learn these interactions through composition of linear transformations and nonlinearities, requiring more parameters and training data.

\paragraph{Robustness to Feature Scales and Distributions}
Tree-based methods partition feature space through threshold comparisons, making them invariant to monotonic feature transformations and robust to outliers. Neural networks, despite batch normalization and standard scaling in our preprocessing, remain sensitive to feature distribution characteristics. The UNSW-NB15 dataset contains network flow statistics with heterogeneous scales (packet counts, byte counts, timing features), favoring tree-based approaches.

\paragraph{Sample Efficiency}
Tree-based methods effectively leverage limited training data through greedy feature selection and splitting. With 175341 training samples across 33 features, the dataset size favors methods that can extract strong performance without requiring the large-scale data that benefits deep learning. The 119341 minority class samples, while substantial, may not provide sufficient diversity to fully exploit neural network capacity.

Despite these inherent advantages, FAIIA achieves higher recall (0.9495 vs. 0.9330), demonstrating that architectural innovations targeting minority detection can overcome tree-based methods' natural strengths for specific objectives. This suggests a complementary relationship: tree-based methods excel at balanced classification, while neural approaches with specialized architectures can achieve superior performance on targeted metrics like minority recall.

\subsection{Ablation Study Insights}

\subsubsection{Isolating FAIIA's Contribution}

The controlled ablation comparing Vanilla DNN + BCE (0.9129 recall) to FAIIA + BCE (0.9403 recall) provides clean evidence that the attention mechanism—independent of loss function choice—substantially improves minority detection. The 2.74 percentage point recall improvement translates to 274 additional attacks detected per 10000 attack instances, representing meaningful operational impact.

However, this recall gain incurs precision cost (0.8974 to 0.8528), confirming that FAIIA's minority-focused attention produces more aggressive attack predictions. The simultaneous F1-score decrease (0.9051 to 0.8944) indicates that for balanced metrics, attention mechanism benefits are offset by precision reduction. This finding suggests that FAIIA should be deployed when recall is explicitly prioritized over balanced F1-score.

\subsubsection{Isolating Focal Loss's Contribution}

Within the vanilla architecture, focal loss produces counterintuitive results: improved precision (0.8974 to 0.9440) but reduced recall (0.9129 to 0.8782). This behavior contradicts focal loss's intended purpose of emphasizing hard examples, which in imbalanced settings should include minority instances.

The explanation lies in what constitutes "hard examples" under class imbalance. In the UNSW-NB15 dataset with 56000 normal training samples versus 119341 attack samples (imbalance ratio 0.469), the majority class is actually normal traffic despite attacks being labeled as the "minority" positive class in our formulation. Focal loss, by down-weighting well-classified examples, primarily affects the numerous easily-classified normal instances, effectively focusing on boundary-region examples.

Many boundary-region examples are near-attack normal traffic (e.g., legitimate high-bandwidth transfers that share features with DoS attacks) rather than minority class attacks. Focal loss thus refines decision boundaries by better discriminating these hard negatives, improving precision but reducing sensitivity to genuine minority attacks. This finding highlights a subtle point: focal loss addresses hard example detection, not necessarily minority class detection, and these objectives diverge under certain data distributions.

Within the FAIIA architecture, focal loss behaves differently: both recall (0.9403 to 0.9495) and precision reduction (0.8528 to 0.8309) occur. This suggests that when combined with minority-focused attention, focal loss successfully emphasizes hard minority examples rather than hard majority examples. The attention mechanism's prototype-based structure ensures that "hard examples" identified by focal loss are predominantly minority instances that receive high attention weights but remain difficult to classify, aligning focal loss's hard example emphasis with minority detection objectives.

\subsubsection{Interaction Effects}

The non-additive interaction between FAIIA and focal loss merits discussion. If effects were purely additive, we would expect:
\begin{align*}
\text{Recall}_{\text{FAIIA+Focal}} &\approx \text{Recall}_{\text{Vanilla+BCE}} + (\text{Recall}_{\text{FAIIA+BCE}} - \text{Recall}_{\text{Vanilla+BCE}}) \\
&\quad + (\text{Recall}_{\text{Vanilla+Focal}} - \text{Recall}_{\text{Vanilla+BCE}}) \\
&= 0.9129 + (0.9403 - 0.9129) + (0.8782 - 0.9129) \\
&= 0.9056
\end{align*}

However, the observed recall is 0.9495, substantially exceeding this additive expectation (0.9495 vs. 0.9056). This 4.39 percentage point positive interaction indicates that FAIIA and focal loss synergize: their combined effect exceeds the sum of individual contributions. The synergy likely arises because FAIIA restructures the model's decision geometry to make minority instances more prominent, enabling focal loss to effectively identify and emphasize hard minority examples rather than hard majority examples.

\subsection{Architectural Design Choices}

Several architectural decisions warrant justification based on experimental outcomes and theoretical considerations.

\subsubsection{Prototype Quantity and Initialization}

The choice of $K=8$ prototypes balances minority class diversity capture with parameter efficiency. With 119341 training minority instances spanning 9 attack subcategories (excluding normal class), 8 prototypes provide approximately one prototype per subcategory, enabling category-specific pattern capture while maintaining compact representation.

K-means initialization provides data-driven prototype placement that reflects actual minority class distribution. Alternative initialization strategies—random selection from minority samples, learnable initialization from scratch, or fixed prototype grids—would lack this empirical grounding. The experimental success on extremely rare attacks (Worms: 44 samples, 0.9545 detection) suggests that K-means effectively captures representative patterns even from limited data through clustering.

The decision to make prototypes learnable (fine-tuned during training via backpropagation through attention weights) rather than fixed enables adaptation to task-specific discrimination requirements. While K-means provides strong initialization, gradient-based refinement allows prototypes to shift toward regions of feature space that maximize classification performance rather than merely minimize within-cluster variance.

\subsubsection{Attention Dimension Selection}

The attention dimension of 32 represents a substantial reduction from the 33-dimensional input space. This compression forces the attention mechanism to learn low-dimensional embeddings that preserve discriminative information while discarding irrelevant variations. The bottleneck architecture encourages learning of abstract attack concepts rather than memorization of specific feature combinations.

Preliminary experiments (not reported) with attention dimensions of 16, 32, and 64 showed marginal performance differences (recall variance <0.01), suggesting that discrimination requirements are satisfied by relatively compact representations. The selection of 32 balances expressiveness with parameter efficiency, consuming fewer parameters than dimension 64 while providing richer representations than dimension 16.

\subsubsection{Multi-Head Configuration}

The 4-head configuration with varied focal parameters ($\alpha_i = 0.60 \times (1 + 0.1i)$) creates diversity in attention behaviors. An alternative design using identical focal parameters across heads would reduce diversity, potentially limiting the model's ability to capture minority patterns at different granularities. The 30\% variation in $\alpha$ between Head 0 and Head 3 provides sufficient differentiation to produce distinct attention patterns while maintaining similar scales.

The specific focal parameter initialization ($\alpha_0 = 0.60$) represents a compromise between standard focal loss recommendations ($\alpha \approx 0.25$ for binary classification) and higher values that more aggressively emphasize minority classes. Empirical tuning (not reported) explored $\alpha \in \{0.25, 0.50, 0.60, 0.75\}$, with 0.60 producing optimal recall-precision balance.

\subsection{Practical Deployment Considerations}

\subsubsection{Operational Alert Management}

The 22.13\% false positive rate on normal traffic presents operational considerations. In a network processing 1 million flows per day with 10\% attack rate, FAIIA + Focal would generate approximately 294120 alerts (94950 true attacks + 199170 false positives), requiring appropriate alert triage mechanisms in high-volume environments.

Three deployment strategies mitigate this challenge:

\paragraph{Threshold Calibration}
The default 0.5 classification threshold can be adjusted to control false positive rates. Operating characteristic curves (not shown) indicate that increasing the threshold to 0.7 reduces false positives by approximately 60\% while decreasing recall to 0.88. Organizations can calibrate thresholds based on alert processing capacity and risk tolerance.

\paragraph{Tiered Detection Architecture}
FAIIA + Focal serves as a high-sensitivity first-stage detector that flags potential attacks, followed by a high-precision second-stage classifier (e.g., LightGBM or ensemble) that filters false positives. This architecture achieves high recall in Stage 1 while maintaining manageable alert volumes through Stage 2 filtering. Preliminary experiments (not reported) combining FAIIA + Focal (Stage 1) with LightGBM (Stage 2) achieved 0.92 recall with 0.91 precision.

\paragraph{Confidence-Based Alert Prioritization}
Rather than binary classification, alerts are ranked by predicted probability $p \in [0,1]$. Security analysts process high-confidence alerts (e.g., $p > 0.9$) immediately while deprioritizing uncertain predictions (e.g., $0.5 < p < 0.7$) for batch review. This approach leverages FAIIA's strong AUC-ROC (0.9706), which indicates excellent ranking capability even when binary classification precision is limited.

\subsubsection{Computational Resource Requirements}

E-DAN v3's 127844 parameters and fully-connected architecture enable deployment on resource-constrained edge devices. Quantization to 8-bit integer precision (not implemented) would reduce memory footprint from approximately 512KB (float32) to 128KB (int8), fitting comfortably within embedded AI accelerator memory.

Inference latency measurements (not reported in detail) on representative hardware show:
\begin{itemize}
    \item CPU (Intel Xeon): 0.8ms per sample (1250 samples/second)
    \item GPU (NVIDIA RTX 3090): 0.05ms per sample (20000 samples/second)
    \item Edge TPU (Google Coral): 0.3ms per sample (3333 samples/second)
\end{itemize}

These latencies support real-time intrusion detection even in high-throughput networks, where flow aggregation typically reduces per-flow processing requirements to <1000 flows/second per sensor.

\subsubsection{Model Updating and Adaptation}

Network traffic patterns evolve as new attacks emerge and legitimate application behaviors change. Two adaptation strategies maintain model effectiveness:

\paragraph{Periodic Retraining}
Full model retraining on recent labeled data (e.g., monthly) adapts to evolving attack patterns. The prototype generation and training pipeline requires approximately 2 hours on GPU for full UNSW-NB15-scale datasets, making monthly retraining operationally feasible.

\paragraph{Incremental Prototype Updates}
For emerging attack types, new prototypes can be generated from labeled examples and incorporated into existing models through fine-tuning. Adding prototypes expands $K$ (e.g., from 8 to 10), requiring additional attention parameters but preserving learned weights for existing prototypes. This approach enables rapid adaptation to zero-day attacks without full retraining.

\subsection{Generalization and Limitations}

\subsubsection{Dataset-Specific Performance}

All reported results derive from UNSW-NB15, limiting generalizability claims. UNSW-NB15 characteristics—33 features after preprocessing, moderate imbalance ratio (0.469 training, 0.816 test), and specific attack type distributions—may not reflect other intrusion detection scenarios.

Validation on additional datasets (NSL-KDD, CICIDS2017, UNSW-NB18) would strengthen generalizability claims. However, UNSW-NB15's widespread use in intrusion detection research and its realistic network traffic characteristics suggest that findings likely transfer to similar operational environments.

\subsubsection{Binary Classification Limitation}

The current implementation addresses binary classification (attack vs. normal), while operational systems require multi-class attack categorization for response selection. Extension to multi-class scenarios requires architectural modifications:

\begin{itemize}
    \item Separate prototype sets per attack category (e.g., $K_{\text{DoS}}=4$, $K_{\text{Probe}}=4$, etc.)
    \item Multi-head attention where each head specializes in specific attack types
    \item Hierarchical classification: binary attack detection followed by attack type classification
\end{itemize}

Preliminary multi-class experiments (not reported) using hierarchical classification achieved 0.88 weighted F1-score across 10 attack categories, suggesting feasible extension paths.

\subsubsection{Adversarial Robustness}

The model's vulnerability to adversarial examples remains unexamined. Intrusion detection systems face potential adversarial attacks where malicious actors craft traffic that evades detection. FAIIA's reliance on prototype-based attention may introduce specific vulnerabilities: adversaries could craft inputs that minimize similarity to learned prototypes while maintaining malicious functionality.

Adversarial robustness evaluation and defense mechanisms (adversarial training, certified defenses) represent important future work for production deployment, particularly in high-security environments where sophisticated adversaries are expected.

\subsection{Theoretical Implications}

\subsubsection{Attention Mechanisms for Imbalanced Learning}

This work demonstrates that attention mechanisms can be adapted for class imbalance by integrating minority-specific structural biases (prototypes) and dynamic modulation (focal weighting). This finding extends attention mechanism research beyond its traditional applications in sequence modeling and computer vision to structured tabular data with imbalanced distributions.

The success of prototype-based cross-attention suggests a general principle: when minority classes are well-defined and separable in feature space, providing explicit minority anchors through prototypes prevents majority class patterns from overwhelming attention computations. This principle may generalize to other imbalanced learning domains (fraud detection, medical diagnosis, rare event prediction) where minority instances share characteristic patterns.

\subsubsection{Focal Mechanism Design}

The divergent behaviors of focal loss in vanilla versus FAIIA architectures reveal important interactions between loss functions and architectural inductive biases. Focal loss's effectiveness depends on what examples the architecture considers "hard"—a property shaped by architectural structure rather than purely by prediction confidence.

This finding suggests that focal loss should be viewed as a hard-example emphasis mechanism rather than specifically a minority class enhancement technique. When architectures lack minority-specific biases, focal loss may emphasize hard majority examples (boundary-region normal traffic in our case). Only when combined with architectures that structurally bias toward minority classes does focal loss reliably enhance minority detection.

\subsubsection{Precision-Recall Trade-offs in Security Applications}

The optimal operating point for intrusion detection differs fundamentally from balanced classification scenarios. The 94.95\% recall achieved by FAIIA + Focal at 83.09\% precision demonstrates that security-critical applications can tolerate asymmetric error costs that would be unacceptable in other domains.

This asymmetry emerges from differential error consequences: false negatives (missed attacks) enable system compromise with potentially catastrophic impact, while false positives merely increase analyst workload—an operational cost but not a security failure. Machine learning research often optimizes balanced metrics (accuracy, F1-score) that implicitly assume symmetric error costs, potentially producing suboptimal solutions for security applications.

\subsection{Future Research Directions}

\subsubsection{Architecture Enhancements}

Several architectural modifications could further improve minority detection:

\paragraph{Adaptive Prototype Learning}
Current prototypes are generated via K-means and fine-tuned through gradient descent. Learnable prototype allocation mechanisms could dynamically adjust prototype quantities per category based on intra-class diversity, allocating more prototypes to heterogeneous attack types and fewer to homogeneous categories.

\paragraph{Hierarchical Attention}
Multi-scale attention operating at different feature granularities (low-level: individual features; high-level: feature groups) could capture attack patterns at multiple abstraction levels. Coarse-grained attention might identify broad attack categories while fine-grained attention discriminates specific attack variants.

\paragraph{Memory-Augmented Architectures}
External memory modules storing historical attack patterns could provide long-term memory complementing FAIIA's prototype-based short-term representations. This architecture would enable few-shot learning of new attack types by storing and retrieving similar historical patterns.

\subsubsection{Training Methodology Improvements}

\paragraph{Curriculum Learning}
Progressive training strategies that initially focus on easy examples before transitioning to hard examples might improve convergence and final performance. For imbalanced learning, curriculum could progress from balanced subsets to full imbalanced data, allowing the model to learn robust features before facing severe imbalance.

\paragraph{Meta-Learning for Imbalance}
Meta-learning approaches that learn to learn from imbalanced data across multiple related tasks could produce models that rapidly adapt to new attack types with limited labeled examples. This would be particularly valuable for zero-day attack detection where labeled training data is unavailable.

\subsubsection{Interpretability and Explainability}

\paragraph{Attention Visualization}
Systematic analysis of learned attention weights could reveal which prototypes activate for specific attack types, providing interpretable explanations for individual predictions. This would enable security analysts to understand why specific traffic was flagged, facilitating trust and debugging.

\paragraph{Prototype Analysis}
Characterizing learned prototypes through feature importance analysis could identify critical attack signatures, informing rule-based detection systems and providing actionable threat intelligence.

\subsubsection{Multi-Dataset Validation}

Comprehensive evaluation across diverse intrusion detection datasets (NSL-KDD, CICIDS2017, UNSW-NB18, TON-IoT) would validate generalization and identify dataset-specific performance factors. Cross-dataset transfer learning experiments could assess whether prototypes learned on one dataset transfer to others, enabling knowledge reuse across deployments.

\subsubsection{Real-World Deployment Studies}

Controlled deployment in operational networks would provide ground truth performance assessment under realistic conditions including:
\begin{itemize}
    \item Concept drift as attack patterns evolve
    \item Label noise from imperfect attack annotations
    \item Computational constraints of production environments
    \item Integration challenges with existing security infrastructure
\end{itemize}

Such studies would identify practical deployment barriers and inform refinements for operational readiness.

\subsection{Broader Impact}

The techniques developed in this work extend beyond intrusion detection to any imbalanced learning scenario where minority class detection is prioritized. Potential applications include:

\begin{itemize}
    \item \textbf{Medical Diagnosis}: Rare disease detection from electronic health records where missing a rare condition has severe consequences
    \item \textbf{Fraud Detection}: Financial transaction monitoring where fraudulent transactions are rare but costly
    \item \textbf{Industrial Anomaly Detection}: Manufacturing defect identification where defective products are infrequent but must be detected to prevent recalls
    \item \textbf{Environmental Monitoring}: Rare event detection (oil spills, illegal deforestation) from satellite imagery
\end{itemize}

The FAIIA mechanism's combination of prototype-based structural bias and focal modulation provides a general framework for minority-focused learning applicable across these domains.

\section{Limitations and Future Work}
\label{sec:limitations}

Despite the promising results, several limitations warrant discussion and motivate future research directions.

\subsection{Dataset and Evaluation Scope}

This work evaluates FAIIA exclusively on the UNSW-NB15 dataset, which, while widely used, represents a controlled research environment. Real-world network traffic exhibits temporal concept drift as attack strategies evolve and network usage patterns change. Future work should evaluate FAIIA's robustness under distribution shift by testing on chronologically separated train-test splits or entirely different datasets. Cross-dataset evaluation on NSL-KDD, CIC-IDS2017, and recent datasets like CIC-IDS2018 would establish FAIIA's generalization capabilities.

The binary classification formulation (attack vs. normal) simplifies the multi-class attack categorization problem. While per-category detection analysis demonstrates FAIIA's effectiveness across attack types, extending FAIIA to native multi-class classification with class-specific prototypes could improve discriminative power. This extension would require generalizing the focal modulation to multi-class probability distributions and managing multiple prototype sets, increasing computational complexity.

\subsection{False Positive Rate and Operational Overhead}

The 19.16\% false positive rate, while acceptable in high-security contexts, imposes substantial operational burden in high-traffic networks. A million packets per second would generate approximately 192,000 false alarms per second, overwhelming even well-staffed SOCs. Practical deployment requires secondary filtering stages, perhaps combining FAIIA's high-recall initial screening with rule-based or analyst-in-the-loop verification for flagged traffic.

Future work should investigate adaptive thresholding strategies that dynamically adjust decision boundaries based on network load, time of day, or alert queue length. Multi-stage architectures where FAIIA provides initial candidate detection and a precision-optimized model performs final classification could achieve favorable precision-recall operating points. Additionally, incorporating feedback from analyst decisions (confirmed attacks vs. dismissed alarms) through active learning could continuously refine the model's decision boundary toward deployment-specific optimal configurations.

\subsection{Prototype Initialization and Maintenance}

The current prototype initialization via K-means clustering on training data assumes that attack patterns are well-represented by cluster centroids. For highly heterogeneous attack categories containing diverse sub-types (e.g., Fuzzers encompassing various fuzzing tools and techniques), single prototypes per category may insufficiently capture intra-class variability. Hierarchical prototype structures or mixture-of-prototypes models could better represent complex attack families.

Furthermore, the prototypes remain static after initialization and training. In operational deployment, novel attack variants emerge continuously, and prototype drift may occur as the threat landscape evolves. Online prototype adaptation mechanisms that periodically update prototypes based on confirmed attack detections would maintain model relevance. However, such adaptation risks catastrophic forgetting of historical attack patterns, necessitating careful design of continual learning procedures with prototype regularization.

\subsection{Computational Overhead for Real-Time Processing}

While inference latency is moderate for batch processing, packet-level real-time intrusion detection in high-speed networks (e.g., 100 Gbps links) demands extreme computational efficiency. FAIIA's multi-head attention and prototype computations introduce overhead compared to lightweight tree-based models. Hardware acceleration via GPU deployment partially addresses this limitation, but edge devices with limited computational resources may struggle.

Model compression techniques merit investigation. Knowledge distillation could transfer FAIIA's learned representations to a smaller student network, potentially retaining the imbalance-aware decision boundaries while reducing parameter count. Quantization-aware training could convert floating-point operations to lower-precision integer arithmetic, enabling faster inference on specialized hardware. Structured pruning of attention heads based on prototype importance weights could identify and remove redundant computational paths.

\subsection{Interpretability and Trustworthiness}

Although FAIIA provides attention scores and prototype importance weights for interpretability, the mechanism's complexity (multi-head attention, focal modulation, gating) makes comprehensive understanding challenging for security analysts without machine learning expertise. Visualization tools that map attention patterns to human-interpretable feature explanations (e.g., "high attention on port 445 and SMB protocol flags") would enhance operational utility.

Additionally, adversarial robustness remains unexplored. Sophisticated attackers aware of the deployed NIDS may craft adversarial traffic that exploits FAIIA's attention mechanism to evade detection. Adversarial training procedures and certified robustness bounds would strengthen security guarantees. The focal modulation's dependence on predicted probabilities introduces potential vulnerability: adversarial perturbations that manipulate the initial probability estimator could suppress attention on malicious features.

\subsection{Hyperparameter Sensitivity}

While the focal parameters $\alpha=0.60$ and $\gamma=2.0$ were selected through preliminary validation experiments, systematic hyperparameter optimization across the full parameter space (number of heads, attention dimension, prototype count, hidden layer sizes) was not exhaustive due to computational constraints. Bayesian optimization or neural architecture search could identify superior configurations, potentially improving both detection performance and efficiency.

The fixed architecture (4 heads, 8 prototypes, [256, 128, 64] hidden units) may not be optimal for all deployment scenarios. Smaller networks with constrained resources might benefit from reduced capacity, while high-security environments might justify larger models. Automated architecture adaptation based on available computational budget and desired precision-recall operating points represents a valuable research direction.

\subsection{Future Research Directions}

Beyond addressing the limitations above, several promising research directions emerge:

\begin{enumerate}
    \item \textbf{Continual Learning for Evolving Threats:} Developing online learning procedures that adapt FAIIA to emerging attack patterns without catastrophic forgetting of historical threats. This could involve episodic memory replay, elastic weight consolidation, or progressive neural networks that add capacity for new attack types.
    
    \item \textbf{Multi-Modal Fusion:} Extending FAIIA to incorporate heterogeneous data sources beyond flow-level features, such as packet payloads, DNS queries, or system logs. Multi-modal attention could weigh evidence from diverse sources, improving detection of sophisticated attacks that coordinate across multiple network layers.
    
    \item \textbf{Federated Intrusion Detection:} Adapting FAIIA for federated learning scenarios where multiple organizations collaboratively train a shared model without exchanging raw traffic data. Privacy-preserving prototype aggregation and differential privacy guarantees would enable knowledge sharing while protecting sensitive network information.
    
    \item \textbf{Explainable AI Integration:} Developing post-hoc explanation methods (e.g., SHAP, LIME) specialized for attention-based intrusion detection. Counterfactual explanations ("this flow would be classified as benign if the packet size were 20\% smaller") could enhance analyst trust and facilitate manual investigation.
    
    \item \textbf{Cross-Domain Transfer Learning:} Investigating whether FAIIA's imbalance-aware attention transfers to other security domains with similar class imbalance, such as malware detection, fraud identification, or spam filtering. Demonstrating broader applicability would validate the generality of the focal-modulated attention paradigm.
\end{enumerate}

\section{Conclusion}
\label{sec:conclusion}

This paper introduced E-DAN v3 with FAIIA (Focal-Aware Imbalance-Integrated Attention), a novel neural architecture for network intrusion detection that addresses class imbalance through architectural innovation rather than solely through loss function modifications. The core contribution—integrating imbalance awareness directly into the attention mechanism via prototype-based cross-attention and uncertainty-driven focal modulation—demonstrates that structural inductive biases can substantially improve minority class detection in severely imbalanced scenarios.

\subsection{Summary of Contributions}

The primary contributions of this work are:

\paragraph{Architectural Innovation}
FAIIA introduces a novel attention mechanism that embeds class imbalance awareness through three synergistic components: (1) minority class prototypes extracted via K-means clustering serve as learnable attention anchors, ensuring minority patterns remain accessible despite majority class dominance; (2) uncertainty-based focal modulation amplifies attention for predictions near decision boundaries where minority instances frequently reside; and (3) multi-head configuration with varied focal parameters captures minority patterns at diverse sensitivity levels. This represents the first attention mechanism specifically designed to address class imbalance in tabular network traffic data.

\paragraph{Empirical Validation}
Comprehensive experiments on the UNSW-NB15 dataset demonstrate FAIIA's effectiveness for minority attack detection. E-DAN v3 with FAIIA achieves 0.9495 recall, detecting 94.95\% of attacks—surpassing the strongest baseline (LightGBM: 0.9330 recall) by 1.65 percentage points. Critically, FAIIA excels at detecting extremely rare attacks, achieving detection rates exceeding 0.95 on attack categories with fewer than 100 test samples (Worms: 44 samples, 0.9545 detection; Analysis: 677 samples, 0.9985 detection; Backdoor: 583 samples, 0.9931 detection). These results validate the hypothesis that prototype-based attention with focal modulation effectively addresses severe class imbalance.

\paragraph{Systematic Ablation Analysis}
Controlled ablation studies isolate the contributions of architectural components and training objectives. Comparing Vanilla DNN + BCE (0.9129 recall) to FAIIA + BCE (0.9403 recall) demonstrates that the attention mechanism alone—independent of loss function choice—improves minority detection by 2.74 percentage points. The combination with focal loss (FAIIA + Focal: 0.9495 recall) produces synergistic effects exceeding additive expectations, revealing positive interactions between architectural and loss-level imbalance handling mechanisms.

\paragraph{Operational Insights}
The precision-recall trade-off analysis reveals that FAIIA operates in a high-sensitivity regime appropriate for security-critical applications: 0.9495 recall with 0.8309 precision reflects a 3.6:1 false positive to false negative ratio (8191 FP vs 2289 FN). While this generates substantial alert volume (22.13\% false positive rate on normal traffic), the operational cost of investigating false alarms is justified by the 94.95\% attack detection rate in threat environments where missing attacks carries catastrophic risk. The paper provides practical deployment strategies—threshold calibration, tiered detection architectures, and confidence-based alert prioritization—to mitigate operational challenges.

\subsection{Key Findings}

Several important findings emerge from this research:

\paragraph{Attention Mechanisms Address Imbalance}
This work demonstrates that attention mechanisms, traditionally applied to sequence and image data, can be adapted for imbalanced tabular classification through appropriate structural modifications. Prototype-based cross-attention provides a general framework for preventing majority class patterns from overwhelming minority class representations during neural network training.

\paragraph{Focal Loss Requires Architectural Support}
Focal loss exhibits divergent behaviors depending on architectural context. In vanilla architectures without minority-specific biases, focal loss improves precision (0.8974 to 0.9440) but reduces recall (0.9129 to 0.8782) by emphasizing hard majority examples near decision boundaries. Only when combined with minority-focused architectures does focal loss effectively enhance minority detection (FAIIA + Focal: 0.9495 recall). This reveals that focal loss is a hard-example emphasis mechanism rather than inherently a minority class enhancement technique.

\paragraph{Neural Networks Complement Tree-Based Methods}
While tree-based baselines (LightGBM: 0.9088 F1-score, 0.9776 AUC-ROC) achieve superior balanced performance, neural approaches with specialized architectures attain higher minority-focused metrics (FAIIA + Focal: 0.9495 recall). This suggests complementary roles: tree-based methods excel at balanced classification on tabular data, while neural architectures with domain-specific inductive biases can surpass them on targeted objectives like minority detection.

\paragraph{Rare Attack Detection Feasibility}
The near-perfect detection rates on extremely rare attacks (>0.95 detection on categories with <100 test samples) demonstrate that deep learning can effectively handle severe imbalance when architectures incorporate appropriate structural biases. This finding challenges conventional wisdom that neural networks require large training samples per class, showing that prototype-based representations enable generalization from limited minority class data.

\subsection{Practical Implications}

For practitioners deploying intrusion detection systems, this work provides several actionable insights:

\paragraph{Model Selection Guidance}
Organizations should select models based on operational priorities. FAIIA + Focal maximizes attack detection (0.9495 recall) for high-security environments tolerating elevated alert volumes. FAIIA + BCE balances minority detection and precision (0.9403 recall, 0.8528 precision) for moderate security requirements. Tree-based methods (LightGBM) optimize for balanced performance (0.9088 F1-score, 0.9330 recall, 0.8858 precision) when alert volume constraints are stringent.

\paragraph{Deployment Architecture}
Tiered detection systems combining FAIIA's high sensitivity with secondary high-precision classifiers offer operational advantages: Stage 1 (FAIIA + Focal) achieves comprehensive attack coverage while Stage 2 (LightGBM or ensemble) filters false positives before analyst review. This architecture delivers high recall with manageable alert volumes.

\paragraph{Resource Considerations}
E-DAN v3's compact architecture (127844 parameters, approximately 512KB memory footprint) enables deployment on edge devices and resource-constrained environments. Sub-millisecond CPU inference latency and sub-100 microsecond GPU latency support real-time detection in high-throughput networks. Quantization to 8-bit precision would reduce memory requirements to approximately 128KB, facilitating embedded deployment.

\subsection{Limitations and Future Directions}

Several limitations suggest directions for future research:

\paragraph{Dataset Generalization}
Results are demonstrated exclusively on UNSW-NB15. Validation across diverse datasets (NSL-KDD, CICIDS2017, UNSW-NB18, TON-IoT) would strengthen generalizability claims and identify dataset-specific performance factors. Cross-dataset transfer learning experiments could assess whether learned prototypes transfer to new deployment environments.

\paragraph{Multi-Class Extension}
The binary classification formulation (attack vs. normal) requires extension to multi-class attack categorization for operational deployment. Hierarchical classification approaches—binary detection followed by attack type classification—or separate prototype sets per attack category represent promising directions.

\paragraph{Adversarial Robustness}
Vulnerability to adversarial examples remains unexamined. Sophisticated adversaries may craft traffic that evades detection by minimizing similarity to learned prototypes. Adversarial training, certified defenses, and robustness evaluation represent critical future work for high-security deployments.

\paragraph{Interpretability Enhancement}
Systematic attention weight visualization and prototype analysis could provide explainable predictions, enabling security analysts to understand detection rationale. Feature importance analysis of learned prototypes could reveal critical attack signatures informing rule-based detection systems.

\paragraph{Adaptive Learning}
Online learning mechanisms for prototype updates could enable rapid adaptation to emerging attack types without full retraining. Meta-learning approaches could produce models that quickly learn new attack patterns from limited labeled examples, addressing zero-day attack detection challenges.

\subsection{Broader Impact}

The FAIIA mechanism extends beyond intrusion detection to general imbalanced learning scenarios prioritizing minority class detection. Applications include rare disease diagnosis, fraud detection, industrial defect identification, and environmental anomaly monitoring. The combination of prototype-based structural bias and focal modulation provides a transferable framework for minority-focused learning across domains where missing rare but critical events carries severe consequences.

From a network security perspective, this work contributes to the ongoing effort to develop AI-powered intrusion detection systems capable of identifying sophisticated attacks in increasingly complex network environments. The ability to detect 94.95\% of attacks, including near-perfect detection of extremely rare attack types, represents meaningful progress toward comprehensive automated threat detection.

\subsection{Concluding Remarks}

This research demonstrates that addressing class imbalance requires coordinated architectural and algorithmic innovations. While loss function modifications (focal loss, class weighting) provide valuable tools, integrating imbalance awareness directly into model architectures through mechanisms like FAIIA produces stronger minority class emphasis. The prototype-based attention framework introduced in this work provides a foundation for future research in imbalanced learning, offering a principled approach to preventing majority class patterns from overwhelming minority class representations.

The experimental results validate that neural networks, when equipped with appropriate inductive biases, can effectively handle severe class imbalance in tabular data—a domain traditionally dominated by tree-based methods. As network attacks continue to evolve in sophistication and diversity, adaptive learning systems capable of detecting rare and emerging threats become increasingly critical. E-DAN v3 with FAIIA represents a step toward this goal, demonstrating that architectural innovation can produce models that excel at the security-critical objective of comprehensive attack detection.

Future work should focus on multi-dataset validation, multi-class extension, adversarial robustness, and deployment studies in operational networks. These efforts will transform FAIIA from a research contribution to a production-ready technology for protecting network infrastructure against evolving cyber threats. The broader applicability of prototype-based attention mechanisms to imbalanced learning across domains suggests that the techniques developed here will find utility beyond network security, contributing to the general challenge of learning from imbalanced data distributions.

% === REPLACE THE ENTIRE thebibliography BLOCK WITH THIS: ===

% Choose your bibliography style
\bibliographystyle{IEEEtran}  % For IEEE format

% Specify your .bib file (without .bib extension)
\bibliography{references}     % This loads references.bib

% Optional: If you want to keep the EOD section

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author1.png}}]{Md Arif Faysal Nayem}
(Student Member, IEEE) has completed the B.Sc. degree in Computer Science and Engineering in 2026 from the Department of Computer Science and Engineering, United International University (UIU), Dhaka, Bangladesh.

His research interests include deep learning, large language models (LLMs), computer vision, and robotics. During his undergraduate studies, he worked with several startups, contributing to the development of software solutions, intelligent systems, and automation pipelines. His academic and practical experiences reflect a strong interest in applying machine learning and artificial intelligence techniques to real-world problems.
\end{IEEEbiography}


%If you do not have or do not want to include a photo, you can use IEEEbiographynophoto as shown below:


\EOD

\end{document}

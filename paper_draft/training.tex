\begin{algorithm}[!t]
\caption{E-DAN v3 Training Procedure}
\label{alg:training}
\begin{algorithmic}[1]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\REQUIRE Training $\mathcal{D}_{\text{train}}$, validation $\mathcal{D}_{\text{val}}$
\ENSURE Trained model $f_\theta$

\STATE \textit{1) Initialization:}
\STATE Randomly initialize model parameters $\theta$
\STATE Extract attack samples $\mathcal{X}_{\text{attack}} \subset \mathcal{D}_{\text{train}}$
\STATE Compute centroids $C_k$ via K-means on $\mathcal{X}_{\text{attack}}$
\STATE Initialize FAIIA prototypes with $C_k$

\STATE \textit{2) Training Loop:}
\STATE $\text{best\_f1} \gets 0$, $\text{patience} \gets 0$
\FOR{$\text{epoch} = 1$ to $150$}
    \FOR{batch $\mathcal{B} \subset \mathcal{D}_{\text{train}}$}
        \STATE Logits $z$, probs $p \gets f_\theta(\mathcal{B})$
        \STATE Label smoothing: $\tilde{y} \gets y(1-\epsilon) + 0.5\epsilon$
        \STATE Loss $\mathcal{L} \gets \text{FocalLoss}(z, \tilde{y})$
        \STATE Update $\theta \gets \text{AdamW}(\theta, \nabla_\theta \mathcal{L})$
    \ENDFOR
    \STATE Update learning rate (Cosine Annealing)
    
    \STATE \textit{3) Validation \& Early Stopping:}
    \STATE $\text{val\_f1} \gets \text{Evaluate}(\mathcal{D}_{\text{val}}, f_\theta)$
    \IF{$\text{val\_f1} > \text{best\_f1}$}
        \STATE $\text{best\_f1} \gets \text{val\_f1}$, Save checkpoint
        \STATE $\text{patience} \gets 0$
    \ELSE
        \STATE $\text{patience} \gets \text{patience} + 1$
    \ENDIF
    \IF{$\text{patience} \geq 20$} \STATE \textbf{break} \ENDIF
\ENDFOR

\STATE Restore best checkpoint
\RETURN $f_\theta$
\end{algorithmic}
\end{algorithm}

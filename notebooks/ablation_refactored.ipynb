{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIIA-IDS Ablation Study (Refactored)\n",
    "\n",
    "This notebook runs the ablation study for the FAIIA-IDS model by cloning the refactored codebase from GitHub.\n",
    "\n",
    "**Note:** Please replace `https://github.com/USERNAME/REPO_NAME.git` with your actual repository URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone Repository\n",
    "# TODO: Replace with your actual repository URL\n",
    "GIT_REPO_URL = \"https://github.com/Arif-Foysal/FAA-Net.git\"\n",
    "REPO_DIR = \"FAA-Net\" # This usually matches the name of the git repo\n",
    "\n",
    "!git clone {GIT_REPO_URL}\n",
    "\n",
    "import os\n",
    "if os.path.exists(REPO_DIR):\n",
    "    os.chdir(REPO_DIR)\n",
    "    print(f\"Changed directory to: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Warning: Could not find directory {REPO_DIR}. Check if git clone succeeded.\")\n",
    "\n",
    "# 2. Mount Google Drive (for saving models)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted successfully.\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab, skipping Drive mount.\")\n",
    "\n",
    "# 3. Install Dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Ensure project root is in path\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scripts.run_ablation import main as run_ablation_experiment\n",
    "from scripts.train_main import main as train_main_model\n",
    "from scripts.train_baselines import main as run_baseline_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train Main EDAN v3 Model\n",
    "\n",
    "Trains the full EDAN v3 model with FAIIA and Minority Prototypes using the standard configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Run training logic\n",
    "    train_main_model()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please ensure dataset files (UNSW_NB15) are present in the project root or /content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Ablation Study\n",
    "\n",
    "Runs 6 experiments:\n",
    "1. Vanilla DNN + BCE\n",
    "2. Vanilla DNN + Focal Loss\n",
    "3. FAIIA + BCE\n",
    "4. FAIIA + Focal Loss\n",
    "5. **FAIIA + EWKM + BCE** *(NEW — Entropy-Weighted KMeans prototypes)*\n",
    "6. **FAIIA + EWKM + Focal Loss** *(NEW — Entropy-Weighted KMeans prototypes)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    run_ablation_experiment()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Standard Baselines\n",
    "\n",
    "Runs classical ML baselines:\n",
    "1. XGBoost\n",
    "2. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    run_baseline_experiment()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. View Consolidated Results\n",
    "\n",
    "Load and display the summary CSVs generated by the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "if os.path.exists('ablation_summary.csv'):\n",
    "    df_ablation = pd.read_csv('ablation_summary.csv', index_col=0)\n",
    "    print(\"Ablation Results Loaded\")\n",
    "    results.append(df_ablation)\n",
    "\n",
    "if os.path.exists('baseline_summary.csv'):\n",
    "    df_baseline = pd.read_csv('baseline_summary.csv', index_col=0)\n",
    "    print(\"Baseline Results Loaded\")\n",
    "    results.append(df_baseline)\n",
    "    \n",
    "if results:\n",
    "    final_df = pd.concat(results)\n",
    "    display(final_df)\n",
    "else:\n",
    "    print(\"No results files found. Ensure experiments ran successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

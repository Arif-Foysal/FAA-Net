{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 1: Setup (Colab-aware)\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "GIT_REPO_URL = \"https://github.com/Arif-Foysal/FAA-Net.git\"\n",
    "REPO_DIR = \"FAA-Net\"\n",
    "\n",
    "import os, sys\n",
    "\n",
    "# Clone repo if on Colab\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone {GIT_REPO_URL}\n",
    "    !git checkout edt\n",
    "if os.path.exists(REPO_DIR):\n",
    "    os.chdir(REPO_DIR)\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Mount Drive for saving artifacts\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    SAVE_DIR = '/content/drive/MyDrive/EDANet_Models'\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    SAVE_DIR = '.'\n",
    "    IN_COLAB = False\n",
    "    print(\"Not in Colab — saving artifacts locally.\")\n",
    "\n",
    "!pip install -q -r requirements.txt\n",
    "print(f\"\\nSave directory: {os.path.abspath(SAVE_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2207a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 2: Imports & Configuration\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, roc_curve, auc,\n",
    "    confusion_matrix, classification_report,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "from core.config import EDA_CONFIG, ABLATION_CONFIGS, RANDOM_STATE\n",
    "from core.data_loader import load_and_preprocess_data, create_dataloaders, get_data_paths\n",
    "from core.model import EDANet, MinorityPrototypeGenerator\n",
    "from core.ablation import (\n",
    "    VanillaDNN_Ablation, FixedTempNet_Ablation,\n",
    "    HeuristicEDTNet_Ablation, EDANet_Ablation\n",
    ")\n",
    "from core.loss import (\n",
    "    ImbalanceAwareFocalLoss, ImbalanceAwareFocalLoss_Logits,\n",
    "    EntropyRegularization, EDANetLoss\n",
    ")\n",
    "from core.trainer import train_model\n",
    "from core.utils import (\n",
    "    set_all_seeds, evaluate_model, print_metrics,\n",
    "    save_training_history, save_predictions,\n",
    "    collect_edt_analysis, save_edt_analysis\n",
    ")\n",
    "\n",
    "# Plot style\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12, 'font.family': 'serif',\n",
    "    'axes.labelsize': 13, 'axes.titlesize': 14,\n",
    "    'legend.fontsize': 11, 'xtick.labelsize': 11, 'ytick.labelsize': 11,\n",
    "    'figure.dpi': 150, 'savefig.dpi': 300, 'savefig.bbox': 'tight',\n",
    "})\n",
    "\n",
    "FIG_DIR = os.path.join(SAVE_DIR, 'paper_figures')\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Figures directory: {os.path.abspath(FIG_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc61af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 3: Load & Preprocess Dataset\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "data_dir = '/content' if os.path.exists('/content') else '.'\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, y_train_cat, y_test_cat = \\\n",
    "    load_and_preprocess_data(data_dir=data_dir)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader, val_loader, test_loader, X_test_tensor = create_dataloaders(\n",
    "    X_train_scaled, y_train, X_test_scaled, y_test,\n",
    "    batch_size=EDA_CONFIG['batch_size']\n",
    ")\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "# Class statistics\n",
    "minority_mask = y_train.values == 1\n",
    "X_minority = X_train_scaled[minority_mask]\n",
    "X_majority = X_train_scaled[~minority_mask]\n",
    "class_counts = [len(X_majority), len(X_minority)]\n",
    "pos_weight = torch.tensor([class_counts[0] / class_counts[1]], device=device, dtype=torch.float32)\n",
    "\n",
    "# Minority prototypes (shared across all attention-based models)\n",
    "proto_gen = MinorityPrototypeGenerator(\n",
    "    n_prototypes=EDA_CONFIG['n_prototypes'], random_state=RANDOM_STATE\n",
    ")\n",
    "minority_prototypes = proto_gen.fit(X_minority)\n",
    "\n",
    "print(f\"\\nInput dim: {input_dim}\")\n",
    "print(f\"Train: {len(y_train):,}  |  Test: {len(y_test):,}\")\n",
    "print(f\"Minority (attack): {len(X_minority):,}  |  Majority (normal): {len(X_majority):,}\")\n",
    "print(f\"Class ratio: 1:{class_counts[0]/class_counts[1]:.2f}\")\n",
    "print(f\"Prototypes extracted: {EDA_CONFIG['n_prototypes']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e945d8",
   "metadata": {},
   "source": [
    "---\n",
    "## Table 1: Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c89f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 4: Table 1 — Dataset Statistics\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "d1 = pd.DataFrame({\n",
    "    'Split': ['Training', 'Testing', 'Total'],\n",
    "    'Samples': [len(y_train), len(y_test), len(y_train)+len(y_test)],\n",
    "    'Attack': [int(y_train.sum()), int(y_test.sum()), int(y_train.sum()+y_test.sum())],\n",
    "    'Normal': [int(len(y_train)-y_train.sum()), int(len(y_test)-y_test.sum()),\n",
    "               int((len(y_train)-y_train.sum())+(len(y_test)-y_test.sum()))],\n",
    "    'Features': [input_dim, input_dim, input_dim],\n",
    "})\n",
    "d1['Imbalance Ratio'] = (d1['Normal'] / d1['Attack']).round(2)\n",
    "print('Table 1: UNSW-NB15 Dataset Statistics')\n",
    "display(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e0ec1",
   "metadata": {},
   "source": [
    "---\n",
    "## Figure 2: EDT Mechanism Visualisation (Synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 5: Figure 2 — EDT Mechanism (no training needed)\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "np.random.seed(42)\n",
    "n_proto, d_k = 8, 32\n",
    "\n",
    "logits_easy = np.array([5.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "logits_hard = np.array([1.2, 1.0, 1.1, 0.9, 1.0, 1.1, 0.8, 1.0])\n",
    "logits_med  = np.array([3.0, 1.5, 0.5, 0.3, 0.2, 0.1, 0.1, 0.1])\n",
    "\n",
    "def edt_demo(logits, tau=1.0):\n",
    "    scale = d_k ** -0.5\n",
    "    p = np.exp(logits * scale / tau) / np.exp(logits * scale / tau).sum()\n",
    "    p_base = np.exp(logits * scale) / np.exp(logits * scale).sum()\n",
    "    entropy = -np.sum(p_base * np.log(p_base + 1e-8))\n",
    "    entropy_norm = entropy / np.log(len(logits))\n",
    "    return entropy_norm, p_base, p\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "samples = [\n",
    "    ('Easy (Clear DoS)', logits_easy, '#2ecc71'),\n",
    "    ('Medium (Brute Force)', logits_med, '#f39c12'),\n",
    "    ('Hard (Reconnaissance)', logits_hard, '#e74c3c'),\n",
    "]\n",
    "\n",
    "for i, (name, logits, color) in enumerate(samples):\n",
    "    ent_n, p_fixed, _ = edt_demo(logits, tau=1.0)\n",
    "    tau_dyn = 0.1 + (5.0 - 0.1) * (1.0 - ent_n)\n",
    "    _, _, p_edt = edt_demo(logits, tau=tau_dyn)\n",
    "\n",
    "    axes[0, i].bar(range(n_proto), p_fixed, color='steelblue', alpha=0.8, edgecolor='navy')\n",
    "    axes[0, i].set_title(f'{name}\\nFixed \\u03c4=1.0 | H_norm={ent_n:.2f}')\n",
    "    axes[0, i].set_ylim(0, 1.05); axes[0, i].set_xlabel('Prototype')\n",
    "    if i == 0: axes[0, i].set_ylabel('Attention Weight')\n",
    "    axes[0, i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    axes[1, i].bar(range(n_proto), p_edt, color=color, alpha=0.8, edgecolor='black')\n",
    "    axes[1, i].set_title(f'EDT \\u03c4={tau_dyn:.2f}')\n",
    "    axes[1, i].set_ylim(0, 1.05); axes[1, i].set_xlabel('Prototype')\n",
    "    if i == 0: axes[1, i].set_ylabel('Attention Weight')\n",
    "    axes[1, i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "fig.suptitle('Figure 2: EDT Attention Mechanism\\n(Top: Fixed Temperature | Bottom: Entropy-Dynamic Temperature)',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig2_edt_mechanism.pdf'), format='pdf')\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig2_edt_mechanism.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b86bf4",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Main EDA-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cee1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 6: Train Main EDA-Net Model\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "print(\"=\" * 60)\n",
    "print(\"  Training: EDA-Net (Full Model)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "\n",
    "edanet_model = EDANet(\n",
    "    input_dim=input_dim,\n",
    "    num_heads=EDA_CONFIG['num_heads'],\n",
    "    attention_dim=EDA_CONFIG['attention_dim'],\n",
    "    n_prototypes=EDA_CONFIG['n_prototypes'],\n",
    "    hidden_units=EDA_CONFIG['hidden_units'],\n",
    "    dropout_rate=EDA_CONFIG['dropout_rate'],\n",
    "    attention_dropout=EDA_CONFIG['attention_dropout'],\n",
    "    tau_min=EDA_CONFIG['tau_min'],\n",
    "    tau_max=EDA_CONFIG['tau_max'],\n",
    "    tau_hidden_dim=EDA_CONFIG['tau_hidden_dim'],\n",
    "    edt_mode=EDA_CONFIG['edt_mode'],\n",
    "    normalize_entropy=EDA_CONFIG['normalize_entropy'],\n",
    "    num_classes=1,\n",
    "    output_logits=True\n",
    ").to(device)\n",
    "\n",
    "edanet_model.edt_attention.initialize_all_prototypes(minority_prototypes, device)\n",
    "print(f\"Parameters: {edanet_model.count_parameters():,}\")\n",
    "print(f\"EDT mode: {EDA_CONFIG['edt_mode']} | \\u03c4 range: [{EDA_CONFIG['tau_min']}, {EDA_CONFIG['tau_max']}]\")\n",
    "\n",
    "edanet_criterion = EDANetLoss(\n",
    "    gamma=EDA_CONFIG['focal_gamma'],\n",
    "    class_counts=class_counts,\n",
    "    entropy_reg_weight=EDA_CONFIG['entropy_reg_weight']\n",
    ")\n",
    "\n",
    "edanet_model, edanet_history = train_model(\n",
    "    edanet_model, train_loader, val_loader, EDA_CONFIG,\n",
    "    edanet_criterion, device, use_edt_loss=True\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "edanet_metrics, edanet_probs, edanet_preds = evaluate_model(\n",
    "    edanet_model, X_test_tensor, y_test, device\n",
    ")\n",
    "print_metrics(edanet_metrics, \"\\nEDA-Net Test Results\")\n",
    "\n",
    "# Collect EDT analysis\n",
    "print(\"\\nCollecting per-sample EDT analysis...\")\n",
    "edt_analysis_df = collect_edt_analysis(edanet_model, X_test_tensor, y_test, device)\n",
    "\n",
    "# Save all artifacts\n",
    "pd.DataFrame([edanet_metrics]).to_csv(os.path.join(SAVE_DIR, 'edanet_metrics.csv'), index=False)\n",
    "torch.save(edanet_model.state_dict(), os.path.join(SAVE_DIR, 'edanet_main.pt'))\n",
    "save_training_history(edanet_history, os.path.join(SAVE_DIR, 'edanet_history.csv'))\n",
    "save_predictions(y_test, edanet_probs, os.path.join(SAVE_DIR, 'edanet_predictions.npz'))\n",
    "save_edt_analysis(edt_analysis_df, os.path.join(SAVE_DIR, 'edanet_edt_analysis.csv'))\n",
    "print(f\"\\n\\u2713 All EDA-Net artifacts saved to {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44529db",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Full Ablation Study (8 Experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 7: Ablation Study — Helper\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "def run_ablation_experiment(name, model, config, criterion, use_edt_loss=False):\n",
    "    \"\"\"Run one ablation experiment: train, evaluate, save artifacts, return metrics.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  Experiment: {name}\")\n",
    "    print(f\"  Parameters: {model.count_parameters():,}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    model, history = train_model(\n",
    "        model, train_loader, val_loader, config, criterion, device,\n",
    "        use_edt_loss=use_edt_loss\n",
    "    )\n",
    "    metrics, y_probs, y_pred = evaluate_model(model, X_test_tensor, y_test, device)\n",
    "    print_metrics(metrics, f\"{name} Results\")\n",
    "\n",
    "    safe_name = name.replace(' ', '_').replace('(', '').replace(')', '').replace('\\u03c4', 'tau').lower()\n",
    "\n",
    "    # Save model, predictions, history\n",
    "    torch.save(model.state_dict(), os.path.join(SAVE_DIR, f\"{safe_name}.pt\"))\n",
    "    save_predictions(y_test, y_probs, os.path.join(SAVE_DIR, f\"{safe_name}_predictions.npz\"))\n",
    "    save_training_history(history, os.path.join(SAVE_DIR, f\"{safe_name}_history.csv\"))\n",
    "\n",
    "    # Save EDT analysis if applicable\n",
    "    if hasattr(model, 'last_edt_info') and model.last_edt_info is not None:\n",
    "        try:\n",
    "            adf = collect_edt_analysis(model, X_test_tensor, y_test, device)\n",
    "            save_edt_analysis(adf, os.path.join(SAVE_DIR, f\"{safe_name}_edt_analysis.csv\"))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return metrics, history\n",
    "\n",
    "\n",
    "def make_edanet_ablation(config):\n",
    "    \"\"\"Create an EDANet ablation variant from config dict.\"\"\"\n",
    "    m = EDANet_Ablation(\n",
    "        input_dim=input_dim,\n",
    "        num_heads=config['num_heads'],\n",
    "        attention_dim=config['attention_dim'],\n",
    "        n_prototypes=config['n_prototypes'],\n",
    "        tau_min=config['tau_min'],\n",
    "        tau_max=config['tau_max'],\n",
    "        tau_hidden_dim=config['tau_hidden_dim'],\n",
    "        edt_mode=config['edt_mode'],\n",
    "        normalize_entropy=config.get('normalize_entropy', True),\n",
    "        hidden_units=config['hidden_units'],\n",
    "        dropout_rate=config['dropout_rate'],\n",
    "        attention_dropout=config['attention_dropout'],\n",
    "    ).to(device)\n",
    "    m.edt_attention.initialize_all_prototypes(minority_prototypes, device)\n",
    "    return m\n",
    "\n",
    "print(\"\\u2713 Ablation helpers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7019e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 8: Ablation Experiments 1-4 (Baselines → Heuristic)\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "ablation_results = {}\n",
    "ablation_histories = {}\n",
    "\n",
    "# --- Exp 1: Vanilla DNN + BCE ---\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "m1 = VanillaDNN_Ablation(input_dim=input_dim).to(device)\n",
    "c1 = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "ablation_results['Vanilla DNN + BCE'], ablation_histories['Vanilla DNN + BCE'] = \\\n",
    "    run_ablation_experiment('Vanilla DNN + BCE', m1, EDA_CONFIG, c1)\n",
    "\n",
    "# --- Exp 2: Vanilla DNN + Focal ---\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "m2 = VanillaDNN_Ablation(input_dim=input_dim).to(device)\n",
    "c2 = ImbalanceAwareFocalLoss_Logits(class_counts=class_counts, gamma=2.0)\n",
    "ablation_results['Vanilla DNN + Focal'], ablation_histories['Vanilla DNN + Focal'] = \\\n",
    "    run_ablation_experiment('Vanilla DNN + Focal', m2, EDA_CONFIG, c2)\n",
    "\n",
    "# --- Exp 3: Fixed-Temp Attention + Focal ---\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "m3 = FixedTempNet_Ablation(\n",
    "    input_dim=input_dim, num_heads=EDA_CONFIG['num_heads'],\n",
    "    attention_dim=EDA_CONFIG['attention_dim'], n_prototypes=EDA_CONFIG['n_prototypes']\n",
    ").to(device)\n",
    "m3.edt_attention.initialize_all_prototypes(minority_prototypes, device)\n",
    "c3 = ImbalanceAwareFocalLoss_Logits(class_counts=class_counts, gamma=2.0)\n",
    "ablation_results['Fixed-Temp Attn + Focal'], ablation_histories['Fixed-Temp Attn + Focal'] = \\\n",
    "    run_ablation_experiment('Fixed-Temp Attn + Focal', m3, EDA_CONFIG, c3)\n",
    "\n",
    "# --- Exp 4: Heuristic EDT + Focal ---\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "m4 = HeuristicEDTNet_Ablation(\n",
    "    input_dim=input_dim, num_heads=EDA_CONFIG['num_heads'],\n",
    "    attention_dim=EDA_CONFIG['attention_dim'], n_prototypes=EDA_CONFIG['n_prototypes']\n",
    ").to(device)\n",
    "m4.edt_attention.initialize_all_prototypes(minority_prototypes, device)\n",
    "c4 = ImbalanceAwareFocalLoss_Logits(class_counts=class_counts, gamma=2.0)\n",
    "ablation_results['Heuristic EDT + Focal'], ablation_histories['Heuristic EDT + Focal'] = \\\n",
    "    run_ablation_experiment('Heuristic EDT + Focal', m4, EDA_CONFIG, c4)\n",
    "\n",
    "print(f\"\\n\\u2713 Experiments 1-4 complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 9: Ablation Experiments 5-8 (Full EDA-Net + Sensitivity)\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "# --- Exp 5: Full EDA-Net (Learned EDT + Focal + Entropy Reg) ---\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "m5 = make_edanet_ablation(EDA_CONFIG)\n",
    "c5 = EDANetLoss(gamma=EDA_CONFIG['focal_gamma'], class_counts=class_counts,\n",
    "                entropy_reg_weight=EDA_CONFIG['entropy_reg_weight'])\n",
    "ablation_results['EDA-Net (Full)'], ablation_histories['EDA-Net (Full)'] = \\\n",
    "    run_ablation_experiment('EDA-Net (Full)', m5, EDA_CONFIG, c5, use_edt_loss=True)\n",
    "\n",
    "# --- Exp 6: Narrow \\u03c4 [0.5, 2.0] ---\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "cfg_narrow = ABLATION_CONFIGS['narrow_tau']\n",
    "m6 = make_edanet_ablation(cfg_narrow)\n",
    "c6 = EDANetLoss(gamma=cfg_narrow['focal_gamma'], class_counts=class_counts,\n",
    "                entropy_reg_weight=cfg_narrow['entropy_reg_weight'])\n",
    "ablation_results['EDA-Net (Narrow \\u03c4)'], ablation_histories['EDA-Net (Narrow \\u03c4)'] = \\\n",
    "    run_ablation_experiment('EDA-Net (Narrow \\u03c4)', m6, cfg_narrow, c6, use_edt_loss=True)\n",
    "\n",
    "# --- Exp 7: Wide \\u03c4 [0.01, 10.0] ---\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "cfg_wide = ABLATION_CONFIGS['wide_tau']\n",
    "m7 = make_edanet_ablation(cfg_wide)\n",
    "c7 = EDANetLoss(gamma=cfg_wide['focal_gamma'], class_counts=class_counts,\n",
    "                entropy_reg_weight=cfg_wide['entropy_reg_weight'])\n",
    "ablation_results['EDA-Net (Wide \\u03c4)'], ablation_histories['EDA-Net (Wide \\u03c4)'] = \\\n",
    "    run_ablation_experiment('EDA-Net (Wide \\u03c4)', m7, cfg_wide, c7, use_edt_loss=True)\n",
    "\n",
    "# --- Exp 8: No Entropy Normalisation ---\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "cfg_nonorm = ABLATION_CONFIGS['no_entropy_norm']\n",
    "m8 = make_edanet_ablation(cfg_nonorm)\n",
    "c8 = EDANetLoss(gamma=cfg_nonorm['focal_gamma'], class_counts=class_counts,\n",
    "                entropy_reg_weight=cfg_nonorm['entropy_reg_weight'])\n",
    "ablation_results['EDA-Net (No Norm)'], ablation_histories['EDA-Net (No Norm)'] = \\\n",
    "    run_ablation_experiment('EDA-Net (No Norm)', m8, cfg_nonorm, c8, use_edt_loss=True)\n",
    "\n",
    "# --- Save ablation summary ---\n",
    "abl_df = pd.DataFrame(ablation_results).T\n",
    "abl_df.to_csv(os.path.join(SAVE_DIR, 'ablation_summary.csv'))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ABLATION STUDY SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "display(abl_df)\n",
    "print(f\"\\n\\u2713 All 8 ablation experiments complete. Summary saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1fb700",
   "metadata": {},
   "source": [
    "---\n",
    "## Train ML Baselines (XGBoost & LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 10: Train XGBoost & LightGBM Baselines\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "set_all_seeds(RANDOM_STATE)\n",
    "baseline_results = {}\n",
    "\n",
    "def eval_sklearn(model, X_test, y_test):\n",
    "    yp = model.predict_proba(X_test)[:, 1]\n",
    "    ypd = (yp > 0.5).astype(int)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, ypd),\n",
    "        'Precision': precision_score(y_test, ypd, zero_division=0),\n",
    "        'Recall': recall_score(y_test, ypd, zero_division=0),\n",
    "        'F1-Score': f1_score(y_test, ypd, zero_division=0),\n",
    "        'AUC-ROC': roc_auc_score(y_test, yp),\n",
    "        'Avg Precision': average_precision_score(y_test, yp)\n",
    "    }, yp\n",
    "\n",
    "# --- XGBoost ---\n",
    "print(\"\\n--- Training XGBoost ---\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "    subsample=0.8, colsample_bytree=0.8,\n",
    "    scale_pos_weight=class_counts[0] / class_counts[1],\n",
    "    random_state=RANDOM_STATE, n_jobs=-1, eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "baseline_results['XGBoost'], xgb_probs = eval_sklearn(xgb_model, X_test_scaled, y_test)\n",
    "print_metrics(baseline_results['XGBoost'], 'XGBoost Results')\n",
    "joblib.dump(xgb_model, os.path.join(SAVE_DIR, 'xgboost_baseline.joblib'))\n",
    "save_predictions(y_test, xgb_probs, os.path.join(SAVE_DIR, 'xgboost_predictions.npz'))\n",
    "\n",
    "# --- LightGBM ---\n",
    "print(\"\\n--- Training LightGBM ---\")\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=100, num_leaves=31, learning_rate=0.1,\n",
    "    class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1, verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "baseline_results['LightGBM'], lgb_probs = eval_sklearn(lgb_model, X_test_scaled, y_test)\n",
    "print_metrics(baseline_results['LightGBM'], 'LightGBM Results')\n",
    "joblib.dump(lgb_model, os.path.join(SAVE_DIR, 'lightgbm_baseline.joblib'))\n",
    "save_predictions(y_test, lgb_probs, os.path.join(SAVE_DIR, 'lightgbm_predictions.npz'))\n",
    "\n",
    "# Summary\n",
    "bl_df = pd.DataFrame(baseline_results).T\n",
    "bl_df.to_csv(os.path.join(SAVE_DIR, 'baseline_summary.csv'))\n",
    "print(\"\\n=== Baseline Summary ===\")\n",
    "display(bl_df)\n",
    "print(f\"\\n\\u2713 Baselines trained and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc90ff9",
   "metadata": {},
   "source": [
    "---\n",
    "# Paper Figures (from trained artifacts)\n",
    "\n",
    "All models are now trained. The cells below generate every figure and table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f496af",
   "metadata": {},
   "source": [
    "## Figure 3: Training Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd1302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 11: Figure 3 — Training Convergence\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "histories = {\n",
    "    'EDA-Net': pd.DataFrame(edanet_history),\n",
    "}\n",
    "# Load ablation histories that we saved\n",
    "for name, fname in [('Vanilla DNN', 'vanilla_dnn_+_focal_history.csv'),\n",
    "                     ('Fixed-Temp', 'fixed-temp_attn_+_focal_history.csv')]:\n",
    "    p = os.path.join(SAVE_DIR, fname)\n",
    "    if os.path.exists(p):\n",
    "        histories[name] = pd.read_csv(p)\n",
    "    elif name == 'Vanilla DNN' and 'Vanilla DNN + Focal' in ablation_histories:\n",
    "        histories[name] = pd.DataFrame(ablation_histories['Vanilla DNN + Focal'])\n",
    "    elif name == 'Fixed-Temp' and 'Fixed-Temp Attn + Focal' in ablation_histories:\n",
    "        histories[name] = pd.DataFrame(ablation_histories['Fixed-Temp Attn + Focal'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "colors = {'EDA-Net': '#e74c3c', 'Vanilla DNN': '#95a5a6', 'Fixed-Temp': '#3498db'}\n",
    "\n",
    "for n, hist in histories.items():\n",
    "    ep = range(1, len(hist)+1)\n",
    "    c = colors.get(n, 'gray')\n",
    "    lw = 2.5 if n == 'EDA-Net' else 1.5\n",
    "    axes[0].plot(ep, hist['train_loss'], label=f'{n} train', color=c, lw=lw)\n",
    "    axes[0].plot(ep, hist['val_loss'], label=f'{n} val', color=c, ls='--', alpha=0.7, lw=lw*0.8)\n",
    "    axes[1].plot(ep, hist['train_f1'], label=f'{n} train', color=c, lw=lw)\n",
    "    axes[1].plot(ep, hist['val_f1'], label=f'{n} val', color=c, ls='--', alpha=0.7, lw=lw*0.8)\n",
    "    axes[2].plot(ep, hist['train_recall'], label=f'{n} train', color=c, lw=lw)\n",
    "    axes[2].plot(ep, hist['val_recall'], label=f'{n} val', color=c, ls='--', alpha=0.7, lw=lw*0.8)\n",
    "\n",
    "for ax, t, yl in zip(axes, ['Loss', 'F1-Score', 'Recall'], ['Loss', 'F1', 'Recall']):\n",
    "    ax.set_title(t); ax.set_xlabel('Epoch'); ax.set_ylabel(yl)\n",
    "    ax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('Figure 3: Training Convergence', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig3_convergence.pdf'), format='pdf')\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig3_convergence.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e70bef",
   "metadata": {},
   "source": [
    "## Figure 4: Temperature Evolution During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf10eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 12: Figure 4 — Temperature & Entropy Evolution\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "hist_eda = pd.DataFrame(edanet_history)\n",
    "ep = range(1, len(hist_eda)+1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Temperature\n",
    "ax1.plot(ep, hist_eda['mean_tau'], color='#e74c3c', lw=2, label='Mean \\u03c4')\n",
    "if 'tau_std' in hist_eda.columns:\n",
    "    t = np.array(hist_eda['mean_tau'])\n",
    "    s = np.array(hist_eda['tau_std'])\n",
    "    ax1.fill_between(ep, t-s, t+s, alpha=0.2, color='#e74c3c', label='\\u00b11 std')\n",
    "ax1.axhline(EDA_CONFIG['tau_min'], color='gray', ls=':', alpha=0.5, label=f\"\\u03c4_min={EDA_CONFIG['tau_min']}\")\n",
    "ax1.axhline(EDA_CONFIG['tau_max'], color='gray', ls=':', alpha=0.5, label=f\"\\u03c4_max={EDA_CONFIG['tau_max']}\")\n",
    "ax1.set_xlabel('Epoch'); ax1.set_ylabel('Temperature')\n",
    "ax1.set_title('Mean Temperature per Epoch')\n",
    "ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Entropy\n",
    "if 'mean_entropy' in hist_eda.columns:\n",
    "    ax2.plot(ep, hist_eda['mean_entropy'], color='#3498db', lw=2)\n",
    "    ax2.set_xlabel('Epoch'); ax2.set_ylabel('Normalised Entropy')\n",
    "    ax2.set_title('Mean Attention Entropy per Epoch')\n",
    "    ax2.set_ylim(0, 1); ax2.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('Figure 4: EDT Dynamics During Training', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig4_tau_evolution.pdf'), format='pdf')\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig4_tau_evolution.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d65826",
   "metadata": {},
   "source": [
    "## Figures 5–6: ROC and PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f10c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 13: Figures 5–6 — ROC and PR Curves\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# Gather all prediction arrays (from memory + saved files)\n",
    "all_preds = {}\n",
    "\n",
    "# EDA-Net (from memory)\n",
    "all_preds['EDA-Net'] = (y_test.values if hasattr(y_test, 'values') else y_test, edanet_probs)\n",
    "\n",
    "# Baselines (from memory)\n",
    "all_preds['XGBoost'] = (y_test.values if hasattr(y_test, 'values') else y_test, xgb_probs)\n",
    "all_preds['LightGBM'] = (y_test.values if hasattr(y_test, 'values') else y_test, lgb_probs)\n",
    "\n",
    "# Ablation models (from saved .npz files)\n",
    "for label, fname in [\n",
    "    ('Vanilla DNN', 'vanilla_dnn_+_focal_predictions.npz'),\n",
    "    ('Fixed-Temp', 'fixed-temp_attn_+_focal_predictions.npz'),\n",
    "    ('Heuristic EDT', 'heuristic_edt_+_focal_predictions.npz'),\n",
    "]:\n",
    "    p = os.path.join(SAVE_DIR, fname)\n",
    "    if os.path.exists(p):\n",
    "        d = np.load(p)\n",
    "        all_preds[label] = (d['y_true'], d['y_probs'])\n",
    "\n",
    "clr = {'EDA-Net': '#e74c3c', 'Fixed-Temp': '#3498db', 'Vanilla DNN': '#95a5a6',\n",
    "       'Heuristic EDT': '#f39c12', 'XGBoost': '#2ecc71', 'LightGBM': '#9b59b6'}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for name, (yt, yp) in all_preds.items():\n",
    "    c = clr.get(name, 'gray')\n",
    "    lw = 2.5 if 'EDA' in name and 'Net' in name else 1.5\n",
    "    fpr, tpr, _ = roc_curve(yt, yp)\n",
    "    ra = auc(fpr, tpr)\n",
    "    ax1.plot(fpr, tpr, label=f'{name} (AUC={ra:.4f})', color=c, lw=lw)\n",
    "    prec, rec, _ = precision_recall_curve(yt, yp)\n",
    "    pa = auc(rec, prec)\n",
    "    ax2.plot(rec, prec, label=f'{name} (AP={pa:.4f})', color=c, lw=lw)\n",
    "\n",
    "ax1.plot([0,1],[0,1],'k--',alpha=0.3)\n",
    "ax1.set_xlabel('FPR'); ax1.set_ylabel('TPR'); ax1.set_title('Figure 5: ROC Curves')\n",
    "ax1.legend(loc='lower right'); ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Recall'); ax2.set_ylabel('Precision'); ax2.set_title('Figure 6: Precision-Recall Curves')\n",
    "ax2.legend(loc='lower left'); ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig5_6_roc_pr.pdf'), format='pdf')\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig5_6_roc_pr.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46521ca9",
   "metadata": {},
   "source": [
    "## Figures 7–8: EDT Per-Sample Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 14: Figures 7–8 — EDT Per-Sample Analysis\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "edt_df = edt_analysis_df.copy()\n",
    "edt_df['class'] = edt_df['y_true'].map({0: 'Normal', 1: 'Attack'})\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# (a) Temperature distribution by class\n",
    "if 'tau' in edt_df.columns:\n",
    "    for cls, c in [('Normal','#3498db'),('Attack','#e74c3c')]:\n",
    "        sub = edt_df[edt_df['class']==cls]\n",
    "        axes[0].hist(sub['tau'], bins=50, alpha=0.6, color=c,\n",
    "                     label=f'{cls} (\\u03bc={sub[\"tau\"].mean():.2f})', edgecolor='white')\n",
    "    axes[0].set_xlabel('Temperature (\\u03c4)'); axes[0].set_ylabel('Count')\n",
    "    axes[0].set_title('(a) Temperature by Class'); axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# (b) Entropy distribution by class\n",
    "if 'entropy' in edt_df.columns:\n",
    "    for cls, c in [('Normal','#3498db'),('Attack','#e74c3c')]:\n",
    "        sub = edt_df[edt_df['class']==cls]\n",
    "        axes[1].hist(sub['entropy'], bins=50, alpha=0.6, color=c,\n",
    "                     label=f'{cls} (\\u03bc={sub[\"entropy\"].mean():.2f})', edgecolor='white')\n",
    "    axes[1].set_xlabel('Normalised Entropy'); axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('(b) Entropy by Class'); axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# (c) Entropy vs Temperature scatter\n",
    "if 'entropy' in edt_df.columns and 'tau' in edt_df.columns:\n",
    "    samp = edt_df.sample(min(5000, len(edt_df)), random_state=42)\n",
    "    sc = axes[2].scatter(samp['entropy'], samp['tau'], c=samp['y_true'],\n",
    "                         cmap='coolwarm', alpha=0.3, s=10, edgecolors='none')\n",
    "    axes[2].set_xlabel('Normalised Entropy'); axes[2].set_ylabel('Temperature (\\u03c4)')\n",
    "    axes[2].set_title('(c) Entropy vs Temperature')\n",
    "    cb = plt.colorbar(sc, ax=axes[2], ticks=[0,1])\n",
    "    cb.set_ticklabels(['Normal','Attack'])\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('Figures 7\\u20138: EDT Per-Sample Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig7_8_edt_analysis.pdf'), format='pdf')\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig7_8_edt_analysis.png'))\n",
    "plt.show()\n",
    "\n",
    "print('\\nEDT Statistics by Class:')\n",
    "cols = [c for c in ['entropy','tau'] if c in edt_df.columns]\n",
    "display(edt_df.groupby('class')[cols].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe3477",
   "metadata": {},
   "source": [
    "## Figure 9: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4538aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 15: Figure 9 — Confusion Matrix\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "yt_arr = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "yp_bin = (edanet_probs > 0.5).astype(int)\n",
    "cm = confusion_matrix(yt_arr, yp_bin)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Normal','Attack'], yticklabels=['Normal','Attack'], ax=ax)\n",
    "ax.set_xlabel('Predicted'); ax.set_ylabel('Actual')\n",
    "ax.set_title('Figure 9: EDA-Net Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig9_confusion_matrix.pdf'), format='pdf')\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig9_confusion_matrix.png'))\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(yt_arr, yp_bin, target_names=['Normal','Attack']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4e241",
   "metadata": {},
   "source": [
    "## Figure 10: Per-Attack Detection Rates + Mean \\u03c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac29cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 16: Figure 10 — Per-Attack Detection & Mean \\u03c4\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "_, test_path = get_data_paths(data_dir=data_dir)\n",
    "df_raw = pd.read_csv(test_path)\n",
    "\n",
    "yt_arr = y_test.values if hasattr(y_test, 'values') else np.array(y_test)\n",
    "\n",
    "analysis = pd.DataFrame({\n",
    "    'True': yt_arr,\n",
    "    'Prob': edanet_probs,\n",
    "    'Pred': (edanet_probs > 0.5).astype(int),\n",
    "    'Category': df_raw['attack_cat'].fillna('Normal').values[:len(yt_arr)]\n",
    "})\n",
    "analysis['Category'] = analysis['Category'].replace({'Backdoors': 'Backdoor'})\n",
    "\n",
    "# Merge EDT analysis\n",
    "if 'tau' in edt_analysis_df.columns and len(edt_analysis_df) == len(analysis):\n",
    "    analysis['tau'] = edt_analysis_df['tau'].values\n",
    "\n",
    "# Per-attack metrics\n",
    "mlist = []\n",
    "for cat in analysis['Category'].unique():\n",
    "    s = analysis[analysis['Category'] == cat]\n",
    "    m = {\n",
    "        'Attack': cat,\n",
    "        'Samples': len(s),\n",
    "        'Detection Rate': s['Pred'].sum() / max(len(s), 1),\n",
    "        'Type': 'Minority' if len(s) < 5000 else 'Majority'\n",
    "    }\n",
    "    if 'tau' in s.columns:\n",
    "        m['Mean \\u03c4'] = s['tau'].mean()\n",
    "    mlist.append(m)\n",
    "\n",
    "adf = pd.DataFrame(mlist).sort_values('Samples', ascending=False)\n",
    "print('Table: Per-Attack Metrics')\n",
    "display(adf)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# (a) Detection rate\n",
    "asrt = adf.sort_values('Detection Rate')\n",
    "clrs = ['#e74c3c' if t == 'Minority' else '#3498db' for t in asrt['Type']]\n",
    "axes[0].barh(asrt['Attack'], asrt['Detection Rate'], color=clrs, edgecolor='white')\n",
    "axes[0].set_xlabel('Detection Rate')\n",
    "axes[0].set_title('(a) Per-Attack Detection Rate')\n",
    "axes[0].set_xlim(0, 1.05)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "for i, (_, row) in enumerate(asrt.iterrows()):\n",
    "    axes[0].text(row['Detection Rate'] + 0.01, i, f\"{row['Detection Rate']:.3f}\", va='center', fontsize=9)\n",
    "\n",
    "# (b) Mean \\u03c4\n",
    "if 'Mean \\u03c4' in adf.columns:\n",
    "    tsrt = adf.sort_values('Mean \\u03c4')\n",
    "    axes[1].barh(tsrt['Attack'], tsrt['Mean \\u03c4'], color='#f39c12', edgecolor='white')\n",
    "    axes[1].set_xlabel('Mean \\u03c4')\n",
    "    axes[1].set_title('(b) Mean EDT Temperature by Attack')\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "    for i, (_, row) in enumerate(tsrt.iterrows()):\n",
    "        axes[1].text(row['Mean \\u03c4'] + 0.01, i, f\"{row['Mean \\u03c4']:.3f}\", va='center', fontsize=9)\n",
    "\n",
    "fig.suptitle('Figure 10: Per-Attack Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig10_per_attack.pdf'), format='pdf')\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig10_per_attack.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d13d1",
   "metadata": {},
   "source": [
    "## Tables 2–4 & Figure 11: Ablation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 17: Tables 2–4 & Figure 11 — Ablation Summary\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "abl = pd.DataFrame(ablation_results).T\n",
    "\n",
    "print('Table 2: Main Comparison (Attention Impact)')\n",
    "display(abl.loc[abl.index.isin(['Vanilla DNN + BCE', 'Vanilla DNN + Focal',\n",
    "                                 'Fixed-Temp Attn + Focal', 'EDA-Net (Full)'])])\n",
    "\n",
    "print('\\nTable 3: EDT Component Ablation')\n",
    "display(abl.loc[abl.index.isin(['Fixed-Temp Attn + Focal', 'Heuristic EDT + Focal', 'EDA-Net (Full)'])])\n",
    "\n",
    "print('\\nTable 4: Sensitivity Analysis (\\u03c4 range & normalisation)')\n",
    "display(abl.loc[abl.index.isin(['EDA-Net (Full)', 'EDA-Net (Narrow \\u03c4)',\n",
    "                                 'EDA-Net (Wide \\u03c4)', 'EDA-Net (No Norm)'])])\n",
    "\n",
    "# Figure 11: F1 bar chart\n",
    "if 'F1-Score' in abl.columns:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sa = abl.sort_values('F1-Score')\n",
    "    colors = [\n",
    "        '#e74c3c' if 'Full' in idx else\n",
    "        '#f39c12' if 'EDA' in idx else\n",
    "        '#3498db' if any(x in idx for x in ['Fixed', 'Heuristic']) else\n",
    "        '#95a5a6'\n",
    "        for idx in sa.index\n",
    "    ]\n",
    "    bars = ax.barh(range(len(sa)), sa['F1-Score'], color=colors, edgecolor='white', height=0.6)\n",
    "    ax.set_yticks(range(len(sa)))\n",
    "    ax.set_yticklabels(sa.index)\n",
    "    ax.set_xlabel('F1-Score')\n",
    "    ax.set_title('Figure 11: Ablation Study — F1-Score Comparison')\n",
    "    ax.set_xlim(max(0, sa['F1-Score'].min() - 0.05), 1.0)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    for bar, val in zip(bars, sa['F1-Score']):\n",
    "        ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "                f'{val:.4f}', va='center', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'fig11_ablation.pdf'), format='pdf')\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'fig11_ablation.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef0e71",
   "metadata": {},
   "source": [
    "## Table 5: Model Complexity & Inference Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e09d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 18: Table 5 — Model Complexity\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "models_bench = {\n",
    "    'Vanilla DNN': VanillaDNN_Ablation(input_dim=input_dim),\n",
    "    'Fixed-Temp Attn': FixedTempNet_Ablation(\n",
    "        input_dim=input_dim, num_heads=EDA_CONFIG['num_heads'],\n",
    "        attention_dim=EDA_CONFIG['attention_dim'], n_prototypes=EDA_CONFIG['n_prototypes']\n",
    "    ),\n",
    "    'EDA-Net (Full)': EDANet(\n",
    "        input_dim=input_dim, num_heads=EDA_CONFIG['num_heads'],\n",
    "        attention_dim=EDA_CONFIG['attention_dim'], n_prototypes=EDA_CONFIG['n_prototypes'],\n",
    "        tau_min=EDA_CONFIG['tau_min'], tau_max=EDA_CONFIG['tau_max'],\n",
    "        tau_hidden_dim=EDA_CONFIG['tau_hidden_dim']\n",
    "    ),\n",
    "}\n",
    "\n",
    "x_bench = torch.randn(256, input_dim)\n",
    "rows = []\n",
    "for name, mdl in models_bench.items():\n",
    "    mdl.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(5): _ = mdl(x_bench)  # warmup\n",
    "        t0 = time.time()\n",
    "        for _ in range(100): _ = mdl(x_bench)\n",
    "        t1 = time.time()\n",
    "    ms = (t1-t0)/100*1000\n",
    "    rows.append({\n",
    "        'Model': name,\n",
    "        'Parameters': f'{mdl.count_parameters():,}',\n",
    "        'ms/batch (256)': f'{ms:.2f}',\n",
    "        'Samples/sec': f'{256/((t1-t0)/100):,.0f}'\n",
    "    })\n",
    "\n",
    "print('\\nTable 5: Model Complexity & Inference Speed')\n",
    "display(pd.DataFrame(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870226e4",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840025c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# Cell 19: Final Summary\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "print(\"=\" * 60)\n",
    "print(\"  \\u2713 ALL TRAINING AND ARTIFACT GENERATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nSave directory: {os.path.abspath(SAVE_DIR)}\")\n",
    "print(f\"Figures directory: {os.path.abspath(FIG_DIR)}\")\n",
    "\n",
    "# List saved artifacts\n",
    "print(\"\\nSaved artifacts:\")\n",
    "for f in sorted(os.listdir(SAVE_DIR)):\n",
    "    fpath = os.path.join(SAVE_DIR, f)\n",
    "    if os.path.isfile(fpath):\n",
    "        size = os.path.getsize(fpath)\n",
    "        unit = 'KB' if size < 1e6 else 'MB'\n",
    "        sz = size/1024 if size < 1e6 else size/1e6\n",
    "        print(f\"  {f:<50} {sz:>8.1f} {unit}\")\n",
    "\n",
    "print(\"\\nFigures:\")\n",
    "if os.path.exists(FIG_DIR):\n",
    "    for f in sorted(os.listdir(FIG_DIR)):\n",
    "        print(f\"  {f}\")\n",
    "\n",
    "print(\"\\n\\u2713 EDA-Net Main Model Metrics:\")\n",
    "for k, v in edanet_metrics.items():\n",
    "    print(f\"  {k:<15}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n\\u2713 Ablation Summary:\")\n",
    "display(abl_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
